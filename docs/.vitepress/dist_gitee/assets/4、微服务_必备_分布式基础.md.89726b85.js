import{_ as s,o as a,c as n,S as l}from"./chunks/framework.b12503b9.js";const A=JSON.parse('{"title":"大型互联网项目架构目标","description":"","frontmatter":{},"headers":[],"relativePath":"4、微服务/必备/分布式基础.md","filePath":"4、微服务/必备/分布式基础.md"}'),p={name:"4、微服务/必备/分布式基础.md"},e=l(`<h1 id="大型互联网项目架构目标" tabindex="-1">大型互联网项目架构目标 <a class="header-anchor" href="#大型互联网项目架构目标" aria-label="Permalink to &quot;大型互联网项目架构目标&quot;">​</a></h1><h2 id="传统项目和互联网项目" tabindex="-1">传统项目和互联网项目 <a class="header-anchor" href="#传统项目和互联网项目" aria-label="Permalink to &quot;传统项目和互联网项目&quot;">​</a></h2><img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305201505216.png" alt="image-20230520150550106" style="zoom:80%;"><p>衡量一个网站速度是否快：</p><blockquote><p>打开一个新页面一瞬间完成；页面内跳转，一刹那间完成。根据佛经《僧祇律》记载：一刹那者为一念，二十念为一瞬，二十瞬为一弹指，二十弹指为一罗预，二十罗预为一须臾，一日一夜有三十须臾。</p></blockquote><blockquote><p>经过周密的计算，一瞬间为0.36 秒,一刹那有 0.018 秒</p></blockquote><h2 id="架构目标" tabindex="-1">架构目标 <a class="header-anchor" href="#架构目标" aria-label="Permalink to &quot;架构目标&quot;">​</a></h2><p>互联网项目特点：</p><blockquote><p>用户多、流量大，并发高、海量数据、易受攻击、功能繁琐、变更快</p></blockquote><h3 id="衡量网站的性能指标" tabindex="-1">衡量网站的性能指标 <a class="header-anchor" href="#衡量网站的性能指标" aria-label="Permalink to &quot;衡量网站的性能指标&quot;">​</a></h3><blockquote><p><strong>响应时间</strong>：指执行一个请求从开始到最后收到响应数据所花费的总体时间。</p><p><strong>并发数</strong>：指系统同时能处理的请求数量。</p><p><strong>并发连接数</strong>：指的是客户端向服务器发起请求，并建立了TCP连接。每秒钟服务器连接的总TCP数量</p><p><strong>请求数</strong>：也称为QPS(Query Per Second) 指每秒多少请求.</p><p><strong>并发用户数</strong>：单位时间内有多少用户</p><p><strong>吞吐量</strong>：指单位时间内系统能处理的请求数量。</p><p><strong>QPS</strong>：Query Per Second 每秒查询数。</p><p><strong>TPS</strong>：Transactions Per Second 每秒事务数。 QPS &gt;= 并发连接数 &gt;= TPS</p></blockquote><blockquote><p>一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。</p></blockquote><blockquote><p>一个页面的一次访问，只会形成一个TPS；但一次页面请求，可能产生多次对服务器的请求，就会有多个QPS</p></blockquote><h3 id="架构目标-1" tabindex="-1">架构目标 <a class="header-anchor" href="#架构目标-1" aria-label="Permalink to &quot;架构目标&quot;">​</a></h3><blockquote><ul><li><strong>高性能</strong>：提供快速的访问体验。</li><li><strong>高可用</strong>：网站服务一直可以正常访问。</li><li><strong>可伸缩</strong>：通过硬件增加/减少，提高/降低处理能力。</li><li><strong>高可扩展</strong>：系统间耦合低，方便的通过新增/移除方式，增加/减少新的功能/模块。</li><li><strong>安全性</strong>：提供网站安全访问和数据加密，安全存储等策略。</li><li><strong>敏捷性</strong>：随需应变，快速响应。</li></ul></blockquote><h2 id="集群和分布式" tabindex="-1">集群和分布式 <a class="header-anchor" href="#集群和分布式" aria-label="Permalink to &quot;集群和分布式&quot;">​</a></h2><blockquote><p>集群：很多“人”一起 ，干一样的事。 一个业务模块，部署在多台服务器上。</p><p>分布式：很多“人”一起，干不一样的事。这些不一样的事，合起来是一件大事。一个大的业务系统，拆分为小的业务模块，分别部署在不同的机器上。</p></blockquote><blockquote><p>高性能、高可用、可伸缩、高可扩展</p></blockquote><h2 id="系统架构演变" tabindex="-1">系统架构演变 <a class="header-anchor" href="#系统架构演变" aria-label="Permalink to &quot;系统架构演变&quot;">​</a></h2><blockquote><p>随着互联网的发展，网站应用的规模也在不断的扩大，进而导致系统架构也在不断的进行变化。从互联网早起到现在，系统架构大体经历了下面几个过程: 单体应用架构---&gt;垂直应用架构---&gt;分布式架构---&gt;SOA架构---&gt;微服务架构，当然还有悄然兴起的Service Mesh(服务网格化)。接下来我们就来了解一下每种系统架构是什么样子的， 以及各有什么优缺点。</p></blockquote><h3 id="单体架构" tabindex="-1">单体架构 <a class="header-anchor" href="#单体架构" aria-label="Permalink to &quot;单体架构&quot;">​</a></h3><blockquote><p>互联网早期，<strong>一般的网站应用流量较小，只需一个应用，将所有功能代码都部署在一起就可以，这样可以减少开发、部署和维护的成本</strong>。比如说一个电商系统，里面会包含很多用户管理，商品管理，订单管理，物流管理等等很多模块，我们会把它们做成一个web项目，然后部署到一台tomcat服务器上。</p></blockquote><img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305090852850.png" alt="image-20230509085242788" style="zoom:67%;"><p>优点：</p><blockquote><ul><li><strong>项目架构简单，小型项目的话， 开发成本低</strong></li><li><strong>项目部署在一个节点上， 维护方便</strong></li></ul></blockquote><p>缺点：</p><blockquote><ul><li><strong>全部功能集成在一个工程中，对于大型项目来讲不易开发和维护</strong></li><li><strong>项目模块之间紧密耦合，单点容错率低</strong></li><li><strong>无法针对不同模块进行针对性优化和水平扩展</strong></li></ul></blockquote><h3 id="垂直架构" tabindex="-1">垂直架构 <a class="header-anchor" href="#垂直架构" aria-label="Permalink to &quot;垂直架构&quot;">​</a></h3><blockquote><p><strong>随着访问量的逐渐增大，单一应用只能依靠增加节点来应对，但是这时候会发现并不是所有的模块都会有比较大的访问量</strong>。还是以上面的电商为例子， 用户访问量的增加可能影响的只是用户和订单模块， 但是对消息模块的影响就比较小。那么此时我们希望只多增加几个订单模块， 而不增加消息模块. 此时单体应用就做不到了， 垂直应用就应运而生了。<strong>所谓的垂直应用架构，就是将原来的一个应用拆成互不相干的几个应用，以提升效率。比如我们可以将上面电商的单体应用拆分成</strong>:</p></blockquote><blockquote><ul><li><strong>电商系统(用户管理 商品管理 订单管理)</strong></li><li><strong>后台系统(用户管理 订单管理 客户管理)</strong></li><li><strong>CMS系统(广告管理 营销管理)</strong></li></ul></blockquote><blockquote><p>这样拆分完毕之后，一旦用户访问量变大，只需要增加电商系统的节点就可以了，而无需增加后台和CMS的节点</p></blockquote><img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305091115357.png" alt="image-20230509111524284" style="zoom:67%;"><p>优点：</p><blockquote><ul><li><strong>系统拆分实现了流量分担，解决了并发问题，而且可以针对不同模块进行优化和水平扩展</strong></li><li><strong>一个系统的问题不会影响到其他系统，提高容错率</strong></li></ul></blockquote><p>缺点：</p><blockquote><ul><li><strong>系统之间相互独立， 无法进行相互调用</strong></li><li><strong>系统之间相互独立， 会有重复的开发任务</strong></li></ul></blockquote><h3 id="分布式架构" tabindex="-1">分布式架构 <a class="header-anchor" href="#分布式架构" aria-label="Permalink to &quot;分布式架构&quot;">​</a></h3><blockquote><p><strong>当垂直应用越来越多，重复的业务代码就会越来越多。这时候，我们就思考可不可以将重复的代码抽取出来，做成统一的业务层作为独立的服务</strong>，然后由前端控制层调用不同的业务层服务呢？这就产生了新的分布式系统架构。它将把工程拆分成表现层和服务层两个部分，服务层中包含业务逻辑。表现层只需要处理和页面的交互，业务逻辑都是调用服务层的服务来实现。</p></blockquote><img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305090855395.png" alt="image-20230509085532317" style="zoom:67%;"><blockquote><p>优点：<strong>抽取公共的功能为服务层，提高代码复用性</strong></p><p>缺点：<strong>系统间耦合度变高，调用关系错综复杂，难以维护</strong></p></blockquote><h3 id="soa架构" tabindex="-1">SOA架构 <a class="header-anchor" href="#soa架构" aria-label="Permalink to &quot;SOA架构&quot;">​</a></h3><blockquote><p>在分布式架构下，当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心对集群进行实时管理。此时，用于资源调度和治理中心(SOA Service Oriented Architecture，面向服务的架构)是关键。</p></blockquote><img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305090856569.png" alt="image-20230509085641494" style="zoom:67%;"><blockquote><p>优点:<strong>使用注册中心解决了服务间调用关系的自动调节</strong></p><p>缺点:<strong>服务间会有依赖关系，一旦某个环节出错会影响较大( 服务雪崩 )，服务关心复杂，运维、测试部署困难</strong></p></blockquote><h3 id="微服务架构" tabindex="-1">微服务架构 <a class="header-anchor" href="#微服务架构" aria-label="Permalink to &quot;微服务架构&quot;">​</a></h3><blockquote><p>微服务架构在某种程度上是面向服务的架构SOA继续发展的下一步，<strong>它更加强调服务的&quot;彻底拆分&quot;</strong>。</p></blockquote><img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2023.3.30/202305090857060.png" alt="image-20230509085737995" style="zoom:80%;"><blockquote><p>优点：服务原子化拆分，独立打包、部署和升级，保证每个微服务清晰的任务划分，利于扩展</p><p>微服务之间采用Restful等轻量级http协议相互调用</p><p>缺点：分布式系统开发的技术成本高（容错、分布式事务等）</p></blockquote><h1 id="微服务的灰度发布" tabindex="-1">微服务的灰度发布 <a class="header-anchor" href="#微服务的灰度发布" aria-label="Permalink to &quot;微服务的灰度发布&quot;">​</a></h1><p>实际生产中如有需求变更，并不会直接更新线上服务，最通常的做法便是：切出线上的小部分流量进行体验测试，经过测试后无问题则全面的上线。</p><p>这样做的好处也是非常明显，一旦出现了BUG，能够保证大部分的客户端正常使用。</p><p>要实现这种平滑过渡的方式就需要用到本篇文章介绍到的<strong>全链路灰度发布</strong>。</p><img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212061025065.png" alt="image-20221206102534977" style="zoom:67%;"><h2 id="什么是灰度发布" tabindex="-1">什么是灰度发布？ <a class="header-anchor" href="#什么是灰度发布" aria-label="Permalink to &quot;什么是灰度发布？&quot;">​</a></h2><p>灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。</p><h2 id="为什么是全链路灰度发布" tabindex="-1">为什么是全链路灰度发布？ <a class="header-anchor" href="#为什么是全链路灰度发布" aria-label="Permalink to &quot;为什么是全链路灰度发布？&quot;">​</a></h2><p>在陈某前面一篇文章有介绍到<strong>网关的灰度发布</strong>实现，仅仅是实现了<strong>网关路由转发</strong>的灰度发布，如下图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/19cc2hfD2rA5Dic4WYODDd06bUxKsWicmS1QXTwpLCHjSvhXMNnmQOUs6sGEfnkiaTB7vI96vj5Qgxm5f9XQ4d7sg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>如上图，网关灰度发布实现的是网关通过<strong>灰度标记</strong>路由到<strong>文章服务B</strong>（灰度服务），至于从文章服务B到评论服务是通过<strong>openFeign</strong>内部调用的，默认无法实现灰度标记<strong>grayTag</strong>的透传，因此文章服务B最终调用的是评论服务A，并不是评论服务B。</p><p>全链路灰度发布需要实现的是：</p><ol><li>网关通过灰度标记将部分流量转发给<strong>文章服务B</strong></li><li>文章服务B能够实现灰度标记<strong>grayTag</strong>的透传，最终调用<strong>评论服务B</strong></li></ol><p>经过以上分析，全链路灰度发布需要实现两个点：</p><ol><li><strong>网关</strong>路由转发实现灰度发布</li><li>服务内部通过<strong>openFeign</strong>调用实现灰度发布（透传灰度标记<strong>grayTag</strong>）。</li></ol><p>下面将以陈某的<a href="https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&amp;mid=2247506948&amp;idx=1&amp;sn=34e282405b10d075bb3e05cfb69663c5&amp;chksm=fcf703c9cb808adf321e465da578dc7dcf97aa90bd97639532af56dd8d619e96c34aef7c4b97&amp;token=581489813&amp;lang=zh_CN&amp;scene=21#wechat_redirect" target="_blank" rel="noreferrer">《Spring Cloud Alibaba实战》</a>专栏中的服务为例进行灰度发布配置。</p><h2 id="网关层的灰度路由转发" tabindex="-1">网关层的灰度路由转发 <a class="header-anchor" href="#网关层的灰度路由转发" aria-label="Permalink to &quot;网关层的灰度路由转发&quot;">​</a></h2><p>本篇文章将使用<strong>Ribbon+Spring Cloud Gateway</strong> 进行改造负载均衡策略实现灰度发布。</p><p>实现思路如下：</p><ol><li>在网关的全局过滤器中根据业务规则给流量打上灰度标记</li><li>将灰度标记放入请求头中，传递给下游服务</li><li>改造Ribbon负载均衡策略，根据流量标记从注册中心获取灰度服务</li><li>请求路由转发</li></ol><p><strong>第一个问题：根据什么条件打上灰度标记？</strong></p><p>这个需要根据实际的业务需要，比如根据用户所在的地区、使用客户端类型、随机截取流量.....</p><p>这里我将直接使用一个标记<strong>grayTag</strong>，只要客户端请求头中携带了这个参数，并且设置为true，则走灰度发布逻辑。</p><blockquote><p>“</p><p>请求头中携带：grayTag=true</p><p>”</p></blockquote><p><strong>第二个问题：为什么要在请求头中添加灰度标记传递给下游服务？</strong></p><p>这一步非常关键，实现灰度标记透传给下游服务的关键，将灰度标记放在请求头中，下游服务只需要从请求头中获取灰度标记便知道是否是灰度发布，这个和令牌中继一个原理。</p><p><strong>第三个问题：灰度标记如何请求隔离？</strong></p><p>Spring MVC中的每个请求都是开启一个线程进行处理，因此可以将灰度标记放置在<strong>ThreadLocal</strong>中进行线程隔离。</p><p><strong>第四个问题：如何知道注册中心的服务哪个是灰度服务？</strong></p><p>Nacos支持在服务中配置一些元数据，可以将灰度标记配置在元数据中，这样就能区分哪些是灰度服务，哪些是正常服务。</p><p><strong>第五个问题：如何针对特定的服务进行灰度发布？</strong></p><p>比如我的<a href="https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&amp;mid=2247506948&amp;idx=1&amp;sn=34e282405b10d075bb3e05cfb69663c5&amp;chksm=fcf703c9cb808adf321e465da578dc7dcf97aa90bd97639532af56dd8d619e96c34aef7c4b97&amp;token=581489813&amp;lang=zh_CN&amp;scene=21#wechat_redirect" target="_blank" rel="noreferrer">《Spring Cloud Alibaba实战》</a>中涉及的一条调用链路如下图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/19cc2hfD2rA5Dic4WYODDd06bUxKsWicmSUFxIxbOgdCHKewyfYseggJJnMbusl6cQiao4ZN0MPKZFMTxW9bKbmIg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><blockquote><p>“</p><p><strong>需求</strong>：现在只对<strong>文章服务</strong>、<strong>评论服务</strong>进行灰度发布，其他服务依然使用线上正在运行的服务</p><p>”</p></blockquote><p>此时的调用关系就变成了下图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/19cc2hfD2rA5Dic4WYODDd06bUxKsWicmS4wtYS3EnrhVyibYO3MA3XC5g1UYXoCHQMD3JyGO5NTJZcwDj0MnhYDA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p><strong>我们知道网关路由中配置的服务很多，如何只针对文章服务进行灰度发布呢？</strong></p><blockquote><p>“</p><p>很简单：只需要将自定义的Ribbon灰度发布规则只对文章服务生效。</p><p>”</p></blockquote><p>这里涉及到Ribbon中的一个注解：<strong>@RibbonClients</strong> ，只需要在其中的value属性指定需要生效的服务名称，那么此时网关中的配置如下：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">@RibbonClients(value ={</span></span>
<span class="line"><span style="color:#A6ACCD;">        //只对文章服务进行灰度发布</span></span>
<span class="line"><span style="color:#A6ACCD;">        @RibbonClient(value = &quot;article-server&quot;,configuration = GrayRuleConfig.class)</span></span>
<span class="line"><span style="color:#A6ACCD;">} )</span></span>
<span class="line"><span style="color:#A6ACCD;">@SpringBootApplication</span></span>
<span class="line"><span style="color:#A6ACCD;">public class GatewayApplication {</span></span>
<span class="line"><span style="color:#A6ACCD;">   </span></span>
<span class="line"><span style="color:#A6ACCD;">}</span></span></code></pre></div><p><strong>@RibbonClient</strong>可以指定多个，这个注解有如下两个属性：</p><ul><li><strong>value</strong>：指定服务的名称，在注册中心配置的服务名称</li><li><strong>configuration</strong>：自定义的负载均衡策略，这里是灰度发布的策略</li></ul><p><strong>@RibbonClients</strong>其中有一个属性<strong>defaultConfiguration</strong>，一旦使用这个属性，那么灰度发布的策略对网关路由中配置的所有服务都将生效。</p><p><strong>第六个问题：说了这么多，具体如何实现？</strong></p><p>网关中首先需要定义一个<strong>全局过滤器</strong>，伪代码如下：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">public class GlobalGrayFilter implements GlobalFilter{</span></span>
<span class="line"><span style="color:#A6ACCD;">    @Override</span></span>
<span class="line"><span style="color:#A6ACCD;">    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {</span></span>
<span class="line"><span style="color:#A6ACCD;">         //① 解析请求头，查看是否存在灰度发布的请求头信息，如果存在则将其放置在ThreadLocal中</span></span>
<span class="line"><span style="color:#A6ACCD;">        HttpHeaders headers = exchange.getRequest().getHeaders();</span></span>
<span class="line"><span style="color:#A6ACCD;">        if (headers.containsKey(GrayConstant.GRAY_HEADER)){</span></span>
<span class="line"><span style="color:#A6ACCD;">            String gray = headers.getFirst(GrayConstant.GRAY_HEADER);</span></span>
<span class="line"><span style="color:#A6ACCD;">            if (StrUtil.equals(gray,GrayConstant.GRAY_VALUE)){</span></span>
<span class="line"><span style="color:#A6ACCD;">                //②设置灰度标记</span></span>
<span class="line"><span style="color:#A6ACCD;">                GrayRequestContextHolder.setGrayTag(true);</span></span>
<span class="line"><span style="color:#A6ACCD;">            }</span></span>
<span class="line"><span style="color:#A6ACCD;">        }</span></span>
<span class="line"><span style="color:#A6ACCD;">       //③ 将灰度标记放入请求头中</span></span>
<span class="line"><span style="color:#A6ACCD;">   ServerHttpRequest tokenRequest = exchange.getRequest().mutate()</span></span>
<span class="line"><span style="color:#A6ACCD;">    //将灰度标记传递过去</span></span>
<span class="line"><span style="color:#A6ACCD;">    .header(GrayConstant.GRAY_HEADER,GrayRequestContextHolder.getGrayTag().toString())</span></span>
<span class="line"><span style="color:#A6ACCD;">    .build();</span></span>
<span class="line"><span style="color:#A6ACCD;">            ServerWebExchange build = exchange.mutate().request(tokenRequest).build();</span></span>
<span class="line"><span style="color:#A6ACCD;">            return chain.filter(build);</span></span>
<span class="line"><span style="color:#A6ACCD;">    }</span></span>
<span class="line"><span style="color:#A6ACCD;">}</span></span></code></pre></div><p><strong>①处的代码</strong>：从请求头中获取客户端传递过来的灰度标记（这里根据自己业务需要自行更改），判断是否是灰度发布</p><p><strong>②处的代码</strong>：<strong>GrayRequestContextHolder</strong>则是自定义的ThreadLocal实现的线程隔离工具，用来存放灰度标记</p><p><strong>③处的代码</strong>：将灰度标记放置在请求头中，传递给下游微服务，这里是和令牌一个逻辑。</p><blockquote><p>“</p><p>注意：这个全局过滤器一定要放在<strong>OAuth2.0</strong>鉴权过滤器之前，优先级要调高</p><p>”</p></blockquote><p>全局过滤器中已经将灰度标记打上了，放置在<strong>GrayRequestContextHolder</strong>中，下面只需要改造Ribbon的负载均衡的策略去注册中心选择灰度服务。</p><p>创建<strong>GrayRule</strong>，代码如下：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">/**</span></span>
<span class="line"><span style="color:#A6ACCD;"> * 灰度发布的规则</span></span>
<span class="line"><span style="color:#A6ACCD;"> */</span></span>
<span class="line"><span style="color:#A6ACCD;">public class GrayRule extends ZoneAvoidanceRule {</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">    @Override</span></span>
<span class="line"><span style="color:#A6ACCD;">    public void initWithNiwsConfig(IClientConfig clientConfig) {</span></span>
<span class="line"><span style="color:#A6ACCD;">    }</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">    @Override</span></span>
<span class="line"><span style="color:#A6ACCD;">    public Server choose(Object key) {</span></span>
<span class="line"><span style="color:#A6ACCD;">        try {</span></span>
<span class="line"><span style="color:#A6ACCD;">            //从ThreadLocal中获取灰度标记</span></span>
<span class="line"><span style="color:#A6ACCD;">            boolean grayTag = GrayRequestContextHolder.getGrayTag().get();</span></span>
<span class="line"><span style="color:#A6ACCD;">            //获取所有可用服务</span></span>
<span class="line"><span style="color:#A6ACCD;">            List&lt;Server&gt; serverList = this.getLoadBalancer().getReachableServers();</span></span>
<span class="line"><span style="color:#A6ACCD;">            //灰度发布的服务</span></span>
<span class="line"><span style="color:#A6ACCD;">            List&lt;Server&gt; grayServerList = new ArrayList&lt;&gt;();</span></span>
<span class="line"><span style="color:#A6ACCD;">            //正常的服务</span></span>
<span class="line"><span style="color:#A6ACCD;">            List&lt;Server&gt; normalServerList = new ArrayList&lt;&gt;();</span></span>
<span class="line"><span style="color:#A6ACCD;">            for(Server server : serverList) {</span></span>
<span class="line"><span style="color:#A6ACCD;">                NacosServer nacosServer = (NacosServer) server;</span></span>
<span class="line"><span style="color:#A6ACCD;">                //从nacos中获取元素剧进行匹配</span></span>
<span class="line"><span style="color:#A6ACCD;">                if(nacosServer.getMetadata().containsKey(GrayConstant.GRAY_HEADER)</span></span>
<span class="line"><span style="color:#A6ACCD;">                        &amp;&amp; nacosServer.getMetadata().get(GrayConstant.GRAY_HEADER).equals(GrayConstant.GRAY_VALUE)) {</span></span>
<span class="line"><span style="color:#A6ACCD;">                    grayServerList.add(server);</span></span>
<span class="line"><span style="color:#A6ACCD;">                } else {</span></span>
<span class="line"><span style="color:#A6ACCD;">                    normalServerList.add(server);</span></span>
<span class="line"><span style="color:#A6ACCD;">                }</span></span>
<span class="line"><span style="color:#A6ACCD;">            }</span></span>
<span class="line"><span style="color:#A6ACCD;">            //如果被标记为灰度发布，则调用灰度发布的服务</span></span>
<span class="line"><span style="color:#A6ACCD;">            if(grayTag) {</span></span>
<span class="line"><span style="color:#A6ACCD;">                return originChoose(grayServerList,key);</span></span>
<span class="line"><span style="color:#A6ACCD;">            } else {</span></span>
<span class="line"><span style="color:#A6ACCD;">                return originChoose(normalServerList,key);</span></span>
<span class="line"><span style="color:#A6ACCD;">            }</span></span>
<span class="line"><span style="color:#A6ACCD;">        } finally {</span></span>
<span class="line"><span style="color:#A6ACCD;">            //清除灰度标记</span></span>
<span class="line"><span style="color:#A6ACCD;">            GrayRequestContextHolder.remove();</span></span>
<span class="line"><span style="color:#A6ACCD;">        }</span></span>
<span class="line"><span style="color:#A6ACCD;">    }</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">    private Server originChoose(List&lt;Server&gt; noMetaServerList, Object key) {</span></span>
<span class="line"><span style="color:#A6ACCD;">        Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(noMetaServerList, key);</span></span>
<span class="line"><span style="color:#A6ACCD;">        if (server.isPresent()) {</span></span>
<span class="line"><span style="color:#A6ACCD;">            return server.get();</span></span>
<span class="line"><span style="color:#A6ACCD;">        } else {</span></span>
<span class="line"><span style="color:#A6ACCD;">            return null;</span></span>
<span class="line"><span style="color:#A6ACCD;">        }</span></span>
<span class="line"><span style="color:#A6ACCD;">    }</span></span>
<span class="line"><span style="color:#A6ACCD;">}</span></span></code></pre></div><p>逻辑很简单，如下：</p><ol><li>获取灰度标记</li><li>从Nacos注册中心获取灰度服务和正常服务</li><li>根据灰度标记去判断，如果灰度发布则选择特定的灰度服务进行转发</li></ol><p>定义一个配置类，注入改造的灰度策略<strong>GrayRule</strong>，如下：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">/**</span></span>
<span class="line"><span style="color:#A6ACCD;"> * 灰度部署的负载规则配置类</span></span>
<span class="line"><span style="color:#A6ACCD;"> * 注意：这个类一定不要被Spring Boot 扫描进入IOC容器中，一旦扫描进入则对全部的服务都将生效</span></span>
<span class="line"><span style="color:#A6ACCD;"> */</span></span>
<span class="line"><span style="color:#A6ACCD;">public class GrayRuleConfig {</span></span>
<span class="line"><span style="color:#A6ACCD;">    @Bean</span></span>
<span class="line"><span style="color:#A6ACCD;">    public GrayRule grayRule(){</span></span>
<span class="line"><span style="color:#A6ACCD;">        return new GrayRule();</span></span>
<span class="line"><span style="color:#A6ACCD;">    }</span></span>
<span class="line"><span style="color:#A6ACCD;">}</span></span></code></pre></div><blockquote><p>“</p><p>注意：这个GrayRuleConfig不能被扫描进入IOC容器，一旦扫描进入则全局生效</p><p>”</p></blockquote><p>因为不仅仅网关需要用到这个灰度发布策略，凡是涉及到OpenFeign调用的微服务如果需要配置灰度发布都需要用到，因此这里陈某定义了一个公用的<strong>gray-starter</strong>。</p><p>经过上述步骤网关的灰度发布则已经配置完成，此时只需要通过**@RibbonClients**指定对应哪个服务灰度发布。</p><h2 id="openfeign透传灰度标记" tabindex="-1">openFeign透传灰度标记 <a class="header-anchor" href="#openfeign透传灰度标记" aria-label="Permalink to &quot;openFeign透传灰度标记&quot;">​</a></h2><p>上面在介绍网关的灰度发布配置时，是将灰度标记（<strong>grayTag=true</strong>）放在了请求头中，因此在下游服务中需要做的就只是从请求头中将灰度标记取出来，然后将其存入<strong>GrayRequestContextHolder</strong>上下文中。</p><p>这样一来下游服务中的<strong>GrayRule</strong>则能从<strong>GrayRequestContextHolder</strong>获取到灰度标记，从注册中心获取灰度服务进行调用了。</p><p><strong>问题来了：如何从请求头中取出灰度标记？</strong></p><p>在介绍OAuth2.0相关知识时，曾经出过一篇文章：<a href="https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&amp;mid=2247504759&amp;idx=1&amp;sn=e50d5b44eb64debf43c6d644f55c68b5&amp;chksm=fcf70cbacb8085aca5cd88688973ed45cd8bd9a4642ae97727f3684b431f80316e5c073d6946&amp;scene=21&amp;cur_album_id=2042874937312346114#wechat_redirect" target="_blank" rel="noreferrer">实战！openFeign如何实现全链路JWT令牌信息不丢失？</a></p><p>其中介绍了令牌中继的解决方案，使用的是openFeign的请求拦截器去配置请求头信息。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/19cc2hfD2rA5Dic4WYODDd06bUxKsWicmSHmicfib1hCNTYA5jPNYvKQF38wMDey4iczG6qjcJJB1DnhEY3Woj7YZFg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>如上图：openFeign在调用时并不是用的原先的Request，而是内部新建了一个Request，其中复制了请求的URL、请求参数一些信息，但是请求头并没有复制过去，因此openFeign调用会丢失请求头中的信息。</p><p>但是可以通过实现<strong>RequestInterceptor</strong>将原先的请求头给复制过去，代码如下：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">@Component</span></span>
<span class="line"><span style="color:#A6ACCD;">@Slf4j</span></span>
<span class="line"><span style="color:#A6ACCD;">public class FeignRequestInterceptor implements RequestInterceptor {</span></span>
<span class="line"><span style="color:#A6ACCD;">    @Override</span></span>
<span class="line"><span style="color:#A6ACCD;">    public void apply(RequestTemplate template) {</span></span>
<span class="line"><span style="color:#A6ACCD;">        HttpServletRequest httpServletRequest = RequestContextUtils.getRequest();</span></span>
<span class="line"><span style="color:#A6ACCD;">        Map&lt;String, String&gt; headers = getHeaders(httpServletRequest);</span></span>
<span class="line"><span style="color:#A6ACCD;">        for (Map.Entry&lt;String, String&gt; entry : headers.entrySet()) {</span></span>
<span class="line"><span style="color:#A6ACCD;">            //② 设置请求头到新的Request中</span></span>
<span class="line"><span style="color:#A6ACCD;">            template.header(entry.getKey(), entry.getValue());</span></span>
<span class="line"><span style="color:#A6ACCD;">        }</span></span>
<span class="line"><span style="color:#A6ACCD;">    }</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span>
<span class="line"><span style="color:#A6ACCD;">    /**</span></span>
<span class="line"><span style="color:#A6ACCD;">     * 获取原请求头</span></span>
<span class="line"><span style="color:#A6ACCD;">     */</span></span>
<span class="line"><span style="color:#A6ACCD;">    private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) {</span></span>
<span class="line"><span style="color:#A6ACCD;">        Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;();</span></span>
<span class="line"><span style="color:#A6ACCD;">        Enumeration&lt;String&gt; enumeration = request.getHeaderNames();</span></span>
<span class="line"><span style="color:#A6ACCD;">        if (enumeration != null) {</span></span>
<span class="line"><span style="color:#A6ACCD;">            while (enumeration.hasMoreElements()) {</span></span>
<span class="line"><span style="color:#A6ACCD;">                String key = enumeration.nextElement();</span></span>
<span class="line"><span style="color:#A6ACCD;">                String value = request.getHeader(key);</span></span>
<span class="line"><span style="color:#A6ACCD;">                //将灰度标记的请求头透传给下个服务</span></span>
<span class="line"><span style="color:#A6ACCD;">                if (StrUtil.equals(GrayConstant.GRAY_HEADER,key)&amp;&amp;Boolean.TRUE.toString().equals(value)){</span></span>
<span class="line"><span style="color:#A6ACCD;">                    //① 保存灰度发布的标记</span></span>
<span class="line"><span style="color:#A6ACCD;">                    GrayRequestContextHolder.setGrayTag(true);</span></span>
<span class="line"><span style="color:#A6ACCD;">                    map.put(key, value);</span></span>
<span class="line"><span style="color:#A6ACCD;">                }</span></span>
<span class="line"><span style="color:#A6ACCD;">            }</span></span>
<span class="line"><span style="color:#A6ACCD;">        }</span></span>
<span class="line"><span style="color:#A6ACCD;">        return map;</span></span>
<span class="line"><span style="color:#A6ACCD;">    }</span></span>
<span class="line"><span style="color:#A6ACCD;">}</span></span></code></pre></div><p><strong>①处的代码</strong>：从请求头中获取灰度发布的标记，设置到<strong>GrayRequestContextHolder</strong>上下文中</p><p><strong>②处的代码</strong>：将这个请求头设置到新的Request中，继续向下游服务传递。</p><p>其实配置一下<strong>RequestInterceptor</strong>就已经完成了，关于灰度发布策略只需要复用网关的<strong>GrayRule</strong></p><blockquote><p>“</p><p>注意：也需要使用@RibbonClients注解去标注文章服务调用的哪些服务需要灰度发布。</p><p>”</p></blockquote><p>代码如下：</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">@RibbonClients(value = {</span></span>
<span class="line"><span style="color:#A6ACCD;">        //指定对comments这个服务开启灰度部署</span></span>
<span class="line"><span style="color:#A6ACCD;">        @RibbonClient(value = &quot;comments&quot;,configuration = GrayRuleConfig.class)</span></span>
<span class="line"><span style="color:#A6ACCD;">})</span></span>
<span class="line"><span style="color:#A6ACCD;">public class ArticleApplication {}</span></span></code></pre></div><h2 id="nacos中服务如何做灰度标记" tabindex="-1">Nacos中服务如何做灰度标记 <a class="header-anchor" href="#nacos中服务如何做灰度标记" aria-label="Permalink to &quot;Nacos中服务如何做灰度标记&quot;">​</a></h2><p>其实很简单，分为两种：</p><p><strong>1、在配置文件中指定，如下：</strong></p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">spring:</span></span>
<span class="line"><span style="color:#A6ACCD;">  cloud:</span></span>
<span class="line"><span style="color:#A6ACCD;">    nacos:</span></span>
<span class="line"><span style="color:#A6ACCD;">      discovery:</span></span>
<span class="line"><span style="color:#A6ACCD;">        metadata:</span></span>
<span class="line"><span style="color:#A6ACCD;">          ## 灰度标记</span></span>
<span class="line"><span style="color:#A6ACCD;">          grayTag: true</span></span></code></pre></div><p><strong>2、在Nacos中动态的指定灰度标记</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/19cc2hfD2rA5Dic4WYODDd06bUxKsWicmSibvzChbtVJ3o9sLIyThCibDlFxWYbiauFhYSGqnuhDpe8SChMspm3I8Cw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>配置完成之后，在客户端请求的时候只需要携带<strong>grayTag=true</strong>这个请求头即可调用灰度服务。</p><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2><p>微服务中全链路灰度发布方案其实很简单，重要的就是灰度打标，整体流程如下：</p><ol><li>网关中通过全局过滤器实现灰度打标，将灰度标记放入请求头中传递给下游服务</li><li>网关通过自定义的负载均衡策略，从注册中心获取灰度服务，进行转发</li><li>在openFeign调用时需要从请求头中获取灰度标记，放入上下文中</li><li>openFeign调用同样是根据自定义的负载均衡策略从注册中心获取灰度服务，进行调用</li></ol><h1 id="详解微服务分布式架构" tabindex="-1">详解微服务分布式架构 <a class="header-anchor" href="#详解微服务分布式架构" aria-label="Permalink to &quot;详解微服务分布式架构&quot;">​</a></h1><p>本文将介绍微服务架构和相关的组件，介绍它们是什么以及为什么要使用微服务架构和这些组件。本文侧重于简明地表达微服务架构的全局图景，因此不会涉及具体如何使用组件等细节。</p><p>要理解微服务，首先要先理解不是微服务的那些。通常跟微服务相对的是单体应用，即将所有功能都打包成在一个独立单元的应用程序。从单体应用到微服务并不是一蹴而就的，这是一个逐渐演变的过程。本文将以一个网上超市应用为例来说明这一过程。</p><h2 id="最初的需求" tabindex="-1">最初的需求 <a class="header-anchor" href="#最初的需求" aria-label="Permalink to &quot;最初的需求&quot;">​</a></h2><p>几年前，小明和小皮一起创业做网上超市。小明负责程序开发，小皮负责其他事宜。当时互联网还不发达，网上超市还是蓝海。只要功能实现了就能随便赚钱。所以他们的需求很简单，只需要一个网站挂在公网，用户能够在这个网站上浏览商品、购买商品；另外还需一个管理后台，可以管理商品、用户、以及订单数据。</p><p>我们整理一下功能清单：</p><ul><li><p>网站</p></li><li><ul><li>用户注册、登录功能</li><li>商品展示</li><li>下单</li></ul></li><li><p>管理后台</p></li><li><ul><li>用户管理</li><li>商品管理</li><li>订单管理</li></ul></li></ul><p>由于需求简单，小明左手右手一个慢动作，网站就做好了。管理后台出于安全考虑，不和网站做在一起，小明右手左手慢动作重播，管理网站也做好了。总体架构图如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4MQl612rtDJrxKiaLADdYvRFXiaiau6ky3ibibUiciaHDB7GI4oyfVFdKARuAQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>小明挥一挥手，找了家云服务部署上去，网站就上线了。上线后好评如潮，深受各类肥宅喜爱。小明小皮美滋滋地开始躺着收钱。</p><h2 id="随着业务发展" tabindex="-1">随着业务发展…… <a class="header-anchor" href="#随着业务发展" aria-label="Permalink to &quot;随着业务发展……&quot;">​</a></h2><p>好景不长，没过几天，各类网上超市紧跟着拔地而起，对小明小皮造成了强烈的冲击。</p><p>在竞争的压力下，小明小皮决定开展一些营销手段：</p><ul><li>开展促销活动。比如元旦全场打折，春节买二送一，情人节狗粮优惠券等等。</li><li>拓展渠道，新增移动端营销。除了网站外，还需要开发移动端 APP，微信小程序等。</li><li>精准营销。利用历史数据对用户进行分析，提供个性化服务。</li><li>……</li></ul><p>这些活动都需要程序开发的支持。小明拉了同学小红加入团队。小红负责数据分析以及移动端相关开发。小明负责促销活动相关功能的开发。</p><p>因为开发任务比较紧迫，小明小红没有好好规划整个系统的架构，随便拍了拍脑袋，决定把促销管理和数据分析放在管理后台里，微信和移动端 APP 另外搭建。通宵了几天后，新功能和新应用基本完工。这时架构图如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4hFzwUIASMpTP6iaEsmIQUiaN89LbpichITiaibzyUmiasZrYsPPxxNN1Ja5g/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>这一阶段存在很多不合理的地方：</p><ul><li>网站和移动端应用有很多相同业务逻辑的重复代码。</li><li>数据有时候通过数据库共享，有时候通过接口调用传输。接口调用关系杂乱。</li><li>单个应用为了给其他应用提供接口，渐渐地越改越大，包含了很多本来就不属于它的逻辑。应用边界模糊，功能归属混乱。</li><li>管理后台在一开始的设计中保障级别较低。加入数据分析和促销管理相关功能后出现性能瓶颈，影响了其他应用。</li><li>数据库表结构被多个应用依赖，无法重构和优化。</li><li>所有应用都在一个数据库上操作，数据库出现性能瓶颈。特别是数据分析跑起来的时候，数据库性能急剧下降。</li><li>开发、测试、部署、维护愈发困难。即使只改动一个小功能，也需要整个应用一起发布。有时候发布会不小心带上了一些未经测试的代码，或者修改了一个功能后，另一个意想不到的地方出错了。为了减轻发布可能产生的问题的影响和线上业务停顿的影响，所有应用都要在凌晨三四点执行发布。发布后为了验证应用正常运行，还得盯到第二天白天的用户高峰期……</li><li>团队出现推诿扯皮现象。关于一些公用的功能应该建设在哪个应用上的问题常常要争论很久，最后要么干脆各做各的，或者随便放个地方但是都不维护。</li></ul><p>尽管有着诸多问题，但也不能否认这一阶段的成果：快速地根据业务变化建设了系统。不过<strong>紧迫且繁重的任务容易使人陷入局部、短浅的思维方式，从而做出妥协式的决策</strong>。在这种架构中，每个人都只关注在自己的一亩三分地，缺乏全局的、长远的设计。长此以往，系统建设将会越来越困难，甚至陷入不断推翻、重建的循环。</p><h2 id="是时候做出改变了" tabindex="-1">是时候做出改变了 <a class="header-anchor" href="#是时候做出改变了" aria-label="Permalink to &quot;是时候做出改变了&quot;">​</a></h2><p>幸好小明和小红是有追求有理想的好青年。意识到问题后，小明和小红从琐碎的业务需求中腾出了一部分精力，开始梳理整体架构，针对问题准备着手改造。</p><blockquote><p>要做改造，首先你需要有足够的精力和资源。如果你的需求方（业务人员、项目经理、上司等）很强势地一心追求需求进度，以致于你无法挪出额外的精力和资源的话，那么你可能无法做任何事……</p></blockquote><p>在编程的世界中，最重要的便是<strong>抽象能力</strong>。微服务改造的过程实际上也是个抽象的过程。小明和小红整理了网上超市的业务逻辑，抽象出公用的业务能力，做成几个公共服务：</p><ul><li>用户服务</li><li>商品服务</li><li>促销服务</li><li>订单服务</li><li>数据分析服务</li></ul><p>各个应用后台只需从这些服务获取所需的数据，从而删去了大量冗余的代码，就剩个轻薄的控制层和前端。这一阶段的架构如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4TFOiaLFeI8KoV4M3RJ3SMcvjYtQyeRfhibjvYGUic7iaW1EN0qfFadSb6w/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>这个阶段只是将服务分开了，数据库依然是共用的，所以一些烟囱式系统的缺点仍然存在：</p><ol><li>数据库成为性能瓶颈，并且有单点故障的风险。</li><li>数据管理趋向混乱。即使一开始有良好的模块化设计，随着时间推移，总会有一个服务直接从数据库取另一个服务的数据的现象。</li><li>数据库表结构可能被多个服务依赖，牵一发而动全身，很难调整。</li></ol><p>如果一直保持共用数据库的模式，则整个架构会越来越僵化，失去了微服务架构的意义。因此小明和小红一鼓作气，把数据库也拆分了。所有持久化层相互隔离，由各个服务自己负责。另外，为了提高系统的实时性，加入了消息队列机制。架构如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4Xra99bFPXQjyv0kYdthT5ZicQj87mTQEb2y3zURCUzDKtVbKgs3k09g/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>完全拆分后各个服务可以采用异构的技术。比如数据分析服务可以使用数据仓库作为持久化层，以便于高效地做一些统计计算；商品服务和促销服务访问频率比较大，因此加入了缓存机制等。</p><blockquote><p>还有一种抽象出公共逻辑的方法是把这些公共逻辑做成公共的框架库。这种方法可以减少服务调用的性能损耗。但是这种方法的管理成本非常高昂，很难保证所有应用版本的一致性。</p></blockquote><blockquote><p>数据库拆分也有一些问题和挑战：比如说跨库级联的需求，通过服务查询数据颗粒度的粗细问题等。但是这些问题可以通过合理的设计来解决。总体来说，数据库拆分是一个利大于弊的。</p></blockquote><p>微服务架构还有一个技术外的好处，它使整个系统的分工更加明确，责任更加清晰，每个人专心负责为其他人提供更好的服务。在单体应用的时代，公共的业务功能经常没有明确的归属。最后要么各做各的，每个人都重新实现了一遍；要么是随机一个人（一般是能力比较强或者比较热心的人）做到他负责的应用里面。在后者的情况下，这个人在负责自己应用之外，还要额外负责给别人提供这些公共的功能——而这个功能本来是无人负责的，仅仅因为他能力较强/比较热心，就莫名地背锅（这种情况还被美其名曰能者多劳）。结果最后大家都不愿意提供公共的功能。长此以往，团队里的人渐渐变得各自为政，不再关心全局的架构设计。</p><p>从这个角度上看，使用微服务架构同时也需要组织结构做相应的调整。所以说做微服务改造需要管理者的支持。</p><p>改造完成后，小明和小红分清楚各自的锅。两人十分满意，一切就像是麦克斯韦方程组一样漂亮完美。</p><p>然而……</p><h2 id="没有银弹" tabindex="-1">没有银弹 <a class="header-anchor" href="#没有银弹" aria-label="Permalink to &quot;没有银弹&quot;">​</a></h2><p>春天来了，万物复苏，又到了一年一度的购物狂欢节。眼看着日订单数量蹭蹭地上涨，小皮小明小红喜笑颜开。可惜好景不长，乐极生悲，突然嘣的一下，系统挂了。</p><p>以往单体应用，排查问题通常是看一下日志，研究错误信息和调用堆栈。而<strong>微服务架构整个应用分散成多个服务，定位故障点非常困难</strong>。小明一个台机器一台机器地查看日志，一个服务一个服务地手工调用。经过十几分钟的查找，小明终于定位到故障点：促销服务由于接收的请求量太大而停止响应了。其他服务都直接或间接地会调用促销服务，于是也跟着宕机了。<strong>在微服务架构中，一个服务故障可能会产生雪崩效用，导致整个系统故障</strong>。其实在节前，小明和小红是有做过请求量评估的。按照预计，服务器资源是足以支持节日的请求量的，所以肯定是哪里出了问题。不过形势紧急，随着每一分每一秒流逝的都是白花花的银子，因此小明也没时间排查问题，当机立断在云上新建了几台虚拟机，然后一台一台地部署新的促销服务节点。几分钟的操作后，系统总算是勉强恢复正常了。整个故障时间内估计损失了几十万的销售额，三人的心在滴血……</p><p>事后，小明简单写了个日志分析工具（量太大了，文本编辑器几乎打不开，打开了肉眼也看不过来），统计了促销服务的访问日志，发现在故障期间，商品服务由于代码问题，在某些场景下会对促销服务发起大量请求。这个问题并不复杂，小明手指抖一抖，修复了这个价值几十万的 Bug。</p><p>问题是解决了，但谁也无法保证不会再发生类似的其他问题。微服务架构虽然逻辑设计上看是完美的，但就像积木搭建的华丽宫殿一样，经不起风吹草动。微服务架构虽然解决了旧问题，也引入了新的问题：</p><ul><li>微服务架构整个应用分散成多个服务，定位故障点非常困难。</li><li>稳定性下降。服务数量变多导致其中一个服务出现故障的概率增大，并且一个服务故障可能导致整个系统挂掉。事实上，在大访问量的生产场景下，故障总是会出现的。</li><li>服务数量非常多，部署、管理的工作量很大。</li><li>开发方面：如何保证各个服务在持续开发的情况下仍然保持协同合作。</li><li>测试方面：服务拆分后，几乎所有功能都会涉及多个服务。原本单个程序的测试变为服务间调用的测试。测试变得更加复杂。</li></ul><p>小明小红痛定思痛，决心好好解决这些问题。对故障的处理一般从两方面入手，一方面尽量减少故障发生的概率，另一方面降低故障造成的影响。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4cn3kGqsJ7tqRegDibGUsicw1wH3QkYdBI7LKNeCr1lyLC23OK970IfCg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><h2 id="监控-发现故障的征兆" tabindex="-1">监控 - 发现故障的征兆 <a class="header-anchor" href="#监控-发现故障的征兆" aria-label="Permalink to &quot;监控 - 发现故障的征兆&quot;">​</a></h2><p>在高并发分布式的场景下，故障经常是突然间就雪崩式爆发。所以必须建立完善的监控体系，尽可能发现故障的征兆。</p><p>微服务架构中组件繁多，各个组件所需要监控的指标不同。比如 Redis 缓存一般监控占用内存值、网络流量，数据库监控连接数、磁盘空间，业务服务监控并发数、响应延迟、错误率等。因此如果做一个大而全的监控系统来监控各个组件是不大现实的，而且扩展性会很差。一般的做法是让各个组件提供报告自己当前状态的接口（metrics 接口），这个接口输出的数据格式应该是一致的。然后部署一个指标采集器组件，定时从这些接口获取并保持组件状态，同时提供查询服务。最后还需要一个 UI，从指标采集器查询各项指标，绘制监控界面或者根据阈值发出告警。</p><p>大部分组件都不需要自己动手开发，网络上有开源组件。小明下载了 RedisExporter 和 MySQLExporter，这两个组件分别提供了 Redis 缓存和 MySQL 数据库的指标接口。微服务则根据各个服务的业务逻辑实现自定义的指标接口。然后小明采用 Prometheus 作为指标采集器，Grafana 配置监控界面和邮件告警。这样一套微服务监控系统就搭建起来了：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4MAfOibWdHRBEicTW6P2VvrtWiaHQibglWAicTF9LERs83liacCW41Jy4hqfA/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><h2 id="定位问题-链路跟踪" tabindex="-1">定位问题 - 链路跟踪 <a class="header-anchor" href="#定位问题-链路跟踪" aria-label="Permalink to &quot;定位问题 - 链路跟踪&quot;">​</a></h2><p>在微服务架构下，一个用户的请求往往涉及多个内部服务调用。为了方便定位问题，需要能够记录每个用户请求时，微服务内部产生了多少服务调用，及其调用关系。这个叫做链路跟踪。</p><p>我们用一个 Istio 文档里的链路跟踪例子来看看效果：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4toKG7tjbibLVml1P4wlUlibZKPiapuI10mNMA43MACoOoTtEILiaLoD1OA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><blockquote><p>图片来自<strong>Istio 文档</strong>[1]</p></blockquote><p>从图中可以看到，这是一个用户访问 productpage 页面的请求。在请求过程中，productpage 服务顺序调用了 details 和 reviews 服务的接口。而 reviews 服务在响应过程中又调用了 ratings 的接口。整个链路跟踪的记录是一棵树：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4lkJBZpRia0icDiazeNyUibHVZytCO0KC7gCGmUuSGCPDv3Nq5ZvCJ5qd9w/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>要实现链路跟踪，每次服务调用会在 HTTP 的 HEADERS 中记录至少记录四项数据：</p><ul><li>traceId：traceId 标识一个用户请求的调用链路。具有相同 traceId 的调用属于同一条链路。</li><li>spanId：标识一次服务调用的 ID，即链路跟踪的节点 ID。</li><li>parentId：父节点的 spanId。</li><li>requestTime &amp; responseTime：请求时间和响应时间。</li></ul><p>另外，还需要调用日志收集与存储的组件，以及展示链路调用的 UI 组件。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4hsJYZVF2cY4blIPUPCNpf5DaDoUVgjBueHUUI8mUkUMia7weE7yWNibA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>以上只是一个极简的说明，关于链路跟踪的理论依据可详见 Google 的<strong>Dapper</strong>[2]</p><p>了解了理论基础后，小明选用了 Dapper 的一个开源实现 Zipkin。然后手指一抖，写了个 HTTP 请求的拦截器，在每次 HTTP 请求时生成这些数据注入到 HEADERS，同时异步发送调用日志到 Zipkin 的日志收集器中。这里额外提一下，HTTP 请求的拦截器，可以在微服务的代码中实现，也可以使用一个网络代理组件来实现（不过这样子每个微服务都需要加一层代理）。</p><p>链路跟踪只能定位到哪个服务出现问题，不能提供具体的错误信息。查找具体的错误信息的能力则需要由日志分析组件来提供。</p><h2 id="分析问题-日志分析" tabindex="-1">分析问题 - 日志分析 <a class="header-anchor" href="#分析问题-日志分析" aria-label="Permalink to &quot;分析问题 - 日志分析&quot;">​</a></h2><p>日志分析组件应该在微服务兴起之前就被广泛使用了。即使单体应用架构，当访问数变大、或服务器规模增多时，日志文件的大小会膨胀到难以用文本编辑器进行访问，更糟的是它们分散在多台服务器上面。排查一个问题，需要登录到各台服务器去获取日志文件，一个一个地查找（而且打开、查找都很慢）想要的日志信息。</p><p>因此，在应用规模变大时，我们需要一个日志的“<strong>搜索引擎</strong>”。以便于能准确的找到想要的日志。另外，数据源一侧还需要收集日志的组件和展示结果的 UI 组件：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4Rey2eUdicFXQU1MNicWgwI4y6KC08G9hH8zC6qXZVfVRiar631JbxibfPQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>小明调查了一下，使用了大名鼎鼎地 ELK 日志分析组件。ELK 是 Elasticsearch、Logstash 和 Kibana 三个组件的缩写。</p><ul><li>Elasticsearch：搜索引擎，同时也是日志的存储。</li><li>Logstash：日志采集器，它接收日志输入，对日志进行一些预处理，然后输出到 Elasticsearch。</li><li>Kibana：UI 组件，通过 Elasticsearch 的 API 查找数据并展示给用户。</li></ul><p>最后还有一个小问题是如何将日志发送到 Logstash。一种方案是在日志输出的时候直接调用 Logstash 接口将日志发送过去。这样一来又（咦，为啥要用“又”）要修改代码……于是小明选用了另一种方案：日志仍然输出到文件，每个服务里再部署个 Agent 扫描日志文件然后输出给 Logstash。</p><h2 id="网关-权限控制-服务治理" tabindex="-1">网关 - 权限控制，服务治理 <a class="header-anchor" href="#网关-权限控制-服务治理" aria-label="Permalink to &quot;网关 - 权限控制，服务治理&quot;">​</a></h2><p>拆分成微服务后，出现大量的服务，大量的接口，使得整个调用关系乱糟糟的。经常在开发过程中，写着写着，忽然想不起某个数据应该调用哪个服务。或者写歪了，调用了不该调用的服务，本来一个只读的功能结果修改了数据……</p><p>为了应对这些情况，微服务的调用需要一个把关的东西，也就是网关。在调用者和被调用者中间加一层网关，每次调用时进行权限校验。另外，网关也可以作为一个提供服务接口文档的平台。</p><p>使用网关有一个问题就是要决定在多大粒度上使用：最粗粒度的方案是整个微服务一个网关，微服务外部通过网关访问微服务，微服务内部则直接调用；最细粒度则是所有调用，不管是微服务内部调用或者来自外部的调用，都必须通过网关。折中的方案是按照业务领域将微服务分成几个区，区内直接调用，区间通过网关调用。</p><p>由于整个网上超市的服务数量还不算特别多，小明采用的最粗粒度的方案：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4yCzu7qaDKW3BAzdSmtAhactbUkibhhx4WUVC7F9c3ZqfbZG8Nh3FicfA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><h2 id="服务注册于发现-动态扩容" tabindex="-1">服务注册于发现 - 动态扩容 <a class="header-anchor" href="#服务注册于发现-动态扩容" aria-label="Permalink to &quot;服务注册于发现 - 动态扩容&quot;">​</a></h2><p>前面的组件，都是旨在降低故障发生的可能性。然而故障总是会发生的，所以另一个需要研究的是如何降低故障产生的影响。</p><p>最粗暴的（也是最常用的）故障处理策略就是冗余。一般来说，一个服务都会部署多个实例，这样一来能够分担压力提高性能，二来即使一个实例挂了其他实例还能响应。</p><p>冗余的一个问题是使用几个冗余？这个问题在时间轴上并没有一个切确的答案。根据服务功能、时间段的不同，需要不同数量的实例。比如在平日里，可能 4 个实例已经够用；而在促销活动时，流量大增，可能需要 40 个实例。因此冗余数量并不是一个固定的值，而是根据需要实时调整的。</p><p>一般来说新增实例的操作为：</p><ol><li>部署新实例</li><li>将新实例注册到负载均衡或 DNS 上</li></ol><p>操作只有两步，但如果注册到负载均衡或 DNS 的操作为人工操作的话，那事情就不简单了。想想新增 40 个实例后，要手工输入 40 个 IP 的感觉……</p><p>解决这个问题的方案是服务自动注册与发现。首先，需要部署一个服务发现服务，它提供所有已注册服务的地址信息的服务。DNS 也算是一种服务发现服务。然后各个应用服务在启动时自动将自己注册到服务发现服务上。并且应用服务启动后会实时（定期）从服务发现服务同步各个应用服务的地址列表到本地。服务发现服务也会定期检查应用服务的健康状态，去掉不健康的实例地址。这样新增实例时只需要部署新实例，实例下线时直接关停服务即可，服务发现会自动检查服务实例的增减。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4uukpIyAoib5gjeQOrK9Ynrkz0vRQW2mSYtCibcbLUhvlkhJhqmTB5zrQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>服务发现还会跟客户端负载均衡配合使用。由于应用服务已经同步服务地址列表在本地了，所以访问微服务时，可以自己决定负载策略。甚至可以在服务注册时加入一些元数据（服务版本等信息），客户端负载则根据这些元数据进行流量控制，实现 A/B 测试、蓝绿发布等功能。</p><p>服务发现有很多组件可以选择，比如说 Zookeeper 、Eureka、Consul、Etcd 等。不过小明觉得自己水平不错，想炫技，于是基于 Redis 自己写了一个……</p><h2 id="熔断、服务降级、限流" tabindex="-1">熔断、服务降级、限流 <a class="header-anchor" href="#熔断、服务降级、限流" aria-label="Permalink to &quot;熔断、服务降级、限流&quot;">​</a></h2><h3 id="熔断" tabindex="-1">熔断 <a class="header-anchor" href="#熔断" aria-label="Permalink to &quot;熔断&quot;">​</a></h3><p>当一个服务因为各种原因停止响应时，调用方通常会等待一段时间，然后超时或者收到错误返回。如果调用链路比较长，可能会导致请求堆积，整条链路占用大量资源一直在等待下游响应。所以当多次访问一个服务失败时，应熔断，标记该服务已停止工作，直接返回错误。直至该服务恢复正常后再重新建立连接。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4aerfNicibUpN5w6qJibl6ft2hMjLYt6ia98ndrgTCk6C0d0Cp7YkS6G8Pg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><blockquote><p>图片来自《<strong>微服务设计</strong>[3]》</p></blockquote><h3 id="服务降级" tabindex="-1">服务降级 <a class="header-anchor" href="#服务降级" aria-label="Permalink to &quot;服务降级&quot;">​</a></h3><p>当下游服务停止工作后，如果该服务并非核心业务，则上游服务应该降级，以保证核心业务不中断。比如网上超市下单界面有一个推荐商品凑单的功能，当推荐模块挂了后，下单功能不能一起挂掉，只需要暂时关闭推荐功能即可。</p><h3 id="限流" tabindex="-1">限流 <a class="header-anchor" href="#限流" aria-label="Permalink to &quot;限流&quot;">​</a></h3><p>一个服务挂掉后，上游服务或者用户一般会习惯性地重试访问。这导致一旦服务恢复正常，很可能因为瞬间网络流量过大又立刻挂掉，在棺材里重复着仰卧起坐。因此服务需要能够自我保护——限流。限流策略有很多，最简单的比如当单位时间内请求数过多时，丢弃多余的请求。另外，也可以考虑分区限流。仅拒绝来自产生大量请求的服务的请求。例如商品服务和订单服务都需要访问促销服务，商品服务由于代码问题发起了大量请求，促销服务则只限制来自商品服务的请求，来自订单服务的请求则正常响应。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4dWdVEXCwGFictYa3Ipv6kCiahHQqib0xsyAYuAfeZQOr8KR5F7kqnKmAg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><h2 id="测试" tabindex="-1">测试 <a class="header-anchor" href="#测试" aria-label="Permalink to &quot;测试&quot;">​</a></h2><p>微服务架构下，测试分为三个层次：</p><ol><li>端到端测试：覆盖整个系统，一般在用户界面机型测试。</li><li>服务测试：针对服务接口进行测试。</li><li>单元测试：针对代码单元进行测试。</li></ol><p>三种测试从上到下实施的容易程度递增，但是测试效果递减。端到端测试最费时费力，但是通过测试后我们对系统最有信心。单元测试最容易实施，效率也最高，但是测试后不能保证整个系统没有问题。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4REymDVR6yEdXibgmnTsLyWAPjJJKwP8pXSgaavvbyu7FZsa0SPZUWZw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>由于端到端测试实施难度较大，一般只对核心功能做端到端测试。一旦端到端测试失败，则需要将其分解到单元测试：则分析失败原因，然后编写单元测试来重现这个问题，这样未来我们便可以更快地捕获同样的错误。</p><p>服务测试的难度在于服务会经常依赖一些其他服务。这个问题可以通过 Mock Server 解决：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4I5DGkQyyDicQQh6ichkp2xc0nyd6qkX28JgvX3yEg7DG5wOCBoeWJh9A/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>单元测试大家都很熟悉了。我们一般会编写大量的单元测试（包括回归测试）尽量覆盖所有代码。</p><h2 id="微服务框架" tabindex="-1">微服务框架 <a class="header-anchor" href="#微服务框架" aria-label="Permalink to &quot;微服务框架&quot;">​</a></h2><p>指标接口、链路跟踪注入、日志引流、服务注册发现、路由规则等组件以及熔断、限流等功能都需要在应用服务上添加一些对接代码。如果让每个应用服务自己实现是非常耗时耗力的。基于 DRY 的原则，小明开发了一套微服务框架，将与各个组件对接的代码和另外一些公共代码抽离到框架中，所有的应用服务都统一使用这套框架进行开发。</p><p>使用微服务框架可以实现很多自定义的功能。甚至可以将程序调用堆栈信息注入到链路跟踪，实现代码级别的链路跟踪。或者输出线程池、连接池的状态信息，实时监控服务底层状态。</p><p>使用统一的微服务框架有一个比较严重的问题：框架更新成本很高。每次框架升级，都需要所有应用服务配合升级。当然，一般会使用兼容方案，留出一段并行时间等待所有应用服务升级。但是如果应用服务非常多时，升级时间可能会非常漫长。并且有一些很稳定几乎不更新的应用服务，其负责人可能会拒绝升级……因此，使用统一微服务框架需要完善的版本管理方法和开发管理规范。</p><h2 id="另一条路-service-mesh" tabindex="-1">另一条路 - Service Mesh <a class="header-anchor" href="#另一条路-service-mesh" aria-label="Permalink to &quot;另一条路 - Service Mesh&quot;">​</a></h2><p>另一种抽象公共代码的方法是直接将这些代码抽象到一个反向代理组件。每个服务都额外部署这个代理组件，所有出站入站的流量都通过该组件进行处理和转发。这个组件被称为 Sidecar。</p><blockquote><p>Sidecar 不会产生额外网络成本。Sidecar 会和微服务节点部署在同一台主机上并且共用相同的虚拟网卡。所以 sidecar 和微服务节点的通信实际上都只是通过内存拷贝实现的。</p></blockquote><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4sZXnZ5bjZzu5hxYwAh53vKGibiaCq42ev5En7B28gNicIPscrK1nsaegw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><blockquote><p>图片来自：<strong>Pattern: Service Mesh</strong>[4]</p></blockquote><p>Sidecar 只负责网络通信。还需要有个组件来统一管理所有 sidecar 的配置。在 Service Mesh 中，负责网络通信的部分叫数据平面（data plane），负责配置管理的部分叫控制平面（control plane）。数据平面和控制平面构成了 Service Mesh 的基本架构。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TzabXJ214ELHJAKHnKLibQE4nR6TGncxHIUdtMKpye2plU6BwlpibCic1WWjlCgF9TXGhUCiaGFiaicibUpA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><blockquote><p>图片来自：<strong>Pattern: Service Mesh</strong>[5]</p></blockquote><p>Sevice Mesh 相比于微服务框架的优点在于它不侵入代码，升级和维护更方便。它经常被诟病的则是性能问题。即使回环网络不会产生实际的网络请求，但仍然有内存拷贝的额外成本。另外有一些集中式的流量处理也会影响性能。</p><h2 id="结束、也是开始" tabindex="-1">结束、也是开始 <a class="header-anchor" href="#结束、也是开始" aria-label="Permalink to &quot;结束、也是开始&quot;">​</a></h2><p>微服务不是架构演变的终点。往细走还有 Serverless、FaaS 等方向。另一方面也有人在唱合久必分分久必合，重新发现单体架构……不管怎样，微服务架构的改造暂时告一段落了。小明满足地摸了摸日益光滑的脑袋，打算这个周末休息一下约小红喝杯咖啡。原文地址：www.cnblogs.com/skabyy/p/11396571.html</p><h1 id="spring-cloud-优雅下线-灰度发布" tabindex="-1">Spring Cloud 优雅下线 + 灰度发布 <a class="header-anchor" href="#spring-cloud-优雅下线-灰度发布" aria-label="Permalink to &quot;Spring Cloud 优雅下线 + 灰度发布&quot;">​</a></h1><p>在生产环境中，如何保证在服务升级的时候，不影响用户的体验，这个是一个非常重要的问题。如果在我们升级服务的时候，会造成一段时间内的服务不可用，这就是不够优雅的。</p><p>那什么是优雅的呢？主要就是指在服务升级的时候，不中断整个服务，让用户无感知，进而不会影响用户的体验，这就是优雅的。</p><p>实际上，优雅下线是目标，而不是手段，它是一个相对的概念，例如<code>kill PID</code>和<code>kill -9 PID</code>都是暴力杀死服务，相对于<code>kill -9 PID</code>来说，<code>kill PID</code>就是优雅的。但如果单独拿<code>kill PID</code>出来说，我们能说它是优雅的下线策略吗？肯定不是啊，就是这个道理。</p><p>因此，本文讲述的优雅下线仅能称之为“相对的优雅下线”，但相对于暴力的杀死服务，已经足够优雅了。常见的优雅解决方案，主要包括优雅下线和灰度发布。而实际上，灰度发布的范围就已经包含优雅下线了。</p><p>最后，在本文中，我们主要讲述基于 Spring Cloud 和 Euraka 的优雅下线以及灰度发布。</p><h2 id="优雅下线" tabindex="-1">优雅下线 <a class="header-anchor" href="#优雅下线" aria-label="Permalink to &quot;优雅下线&quot;">​</a></h2><h3 id="常见的下线方式" tabindex="-1">常见的下线方式 <a class="header-anchor" href="#常见的下线方式" aria-label="Permalink to &quot;常见的下线方式&quot;">​</a></h3><h4 id="_1-kill-pid" tabindex="-1">1 kill PID <a class="header-anchor" href="#_1-kill-pid" aria-label="Permalink to &quot;1 kill PID&quot;">​</a></h4><p>使用方式：kill java进程ID</p><blockquote><p>该方式借助的是 Spring Boot 应用的 <code>Shutdown hook</code>，应用本身的下线也是优雅的，但如果你的服务发现组件使用的是 Eureka，那么默认最长会有 90 秒的延迟，其他应用才会感知到该服务下线，这意味着：该实例下线后的 90 秒内，其他服务仍然可能调用到这个已下线的实例。因此，该方式是不够优雅的 。</p></blockquote><h4 id="_2-shutdown端点" tabindex="-1">2 /shutdown端点 <a class="header-anchor" href="#_2-shutdown端点" aria-label="Permalink to &quot;2 /shutdown端点&quot;">​</a></h4><p>Spring Boot 提供了<code>/shutdown</code>端点，可以借助它实现优雅停机。</p><p>使用方式：在想下线应用的application.yml中添加如下配置，从而启用并暴露<code>/shutdown</code>端点：</p><div class="language-yml"><button title="Copy Code" class="copy"></button><span class="lang">yml</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#F07178;">management</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#F07178;">endpoint</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#F07178;">shutdown</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#F07178;">enabled</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#FF9CAC;">true</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#F07178;">endpoints</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#F07178;">web</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#F07178;">exposure</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#F07178;">include</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">shutdown</span></span></code></pre></div><p>发送 POST 请求到/shutdown端点</p><div class="language-sh"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">curl</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">-X</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">http://你想停止的服务地址/actuator/shutdown</span></span></code></pre></div><p>该方式本质和方式一是一样的，也是借助 Spring Boot 应用的 Shutdown hook 去实现的。</p><h4 id="_3-pause端点" tabindex="-1">3 /pause端点 <a class="header-anchor" href="#_3-pause端点" aria-label="Permalink to &quot;3 /pause端点&quot;">​</a></h4><p>Spring Boot 应用提供了<code>/pause</code>端点，利用该端点可实现优雅下线。</p><p>使用方式：在想下线应用的application.yml中添加配置，从而启用并暴露<code>/pause</code>端点：</p><div class="language-yml"><button title="Copy Code" class="copy"></button><span class="lang">yml</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#F07178;">management</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#F07178;">endpoint</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#89DDFF;">    </span><span style="color:#676E95;font-style:italic;"># 启用pause端点</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#F07178;">pause</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#F07178;">enabled</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#FF9CAC;">true</span></span>
<span class="line"><span style="color:#89DDFF;">    </span><span style="color:#676E95;font-style:italic;"># 启用restart端点，之所以要启用restart端点，是因为pause端点的启用依赖restart端点的启用</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#F07178;">restart</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#F07178;">enabled</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#FF9CAC;">true</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#F07178;">endpoints</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#F07178;">web</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#F07178;">exposure</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#F07178;">include</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">pause,restart</span></span></code></pre></div><p>发送 POST 请求到<code>/actuator/pause</code>端点：</p><div class="language-apl"><button title="Copy Code" class="copy"></button><span class="lang">apl</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">curl </span><span style="color:#89DDFF;">-</span><span style="color:#A6ACCD;">X POST http:</span><span style="color:#89DDFF;">//</span><span style="color:#A6ACCD;">你想停止的服务实例地址</span><span style="color:#89DDFF;">/</span><span style="color:#A6ACCD;">actuator</span><span style="color:#89DDFF;">/</span><span style="color:#A6ACCD;">pause</span></span></code></pre></div><p>执行后的效果类似下图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/TNUwKhV0JpRtYTVrnGSDO3J0fGl4K5erQeWtaoBStmsZEtYdicxDLtcHefFQaJ4iaicIeCibMXrb1n8kc3TSliakQtg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><p>如图所示，该应用在 Eureka Server 上的状已被标记为DOWN，但是应用本身其实依然是可以正常对外服务的。在 Spring Cloud 中，Ribbon 做负载均衡时，只会负载到标记为UP的实例上。</p><p>利用这两点，你可以：先用<code>/pause</code>端点，将要下线的应用标记为DOWN，但不去真正停止应用；然后过一定的时间（例如 90 秒，或者自己做个监控，看当前实例的流量变成 0 后）再去停止应用，例如<code>kill</code>应用。</p><p><strong>缺点 &amp; 局限</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/TNUwKhV0JpRtYTVrnGSDO3J0fGl4K5erlHa8Za6LdbkHKtKjowj9Ne5nsdXGA4kFnxDfYMUraEoPYgcjoD8Ficw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><h4 id="_4-service-registry端点" tabindex="-1">4 /service-registry端点 <a class="header-anchor" href="#_4-service-registry端点" aria-label="Permalink to &quot;4 /service-registry端点&quot;">​</a></h4><p>使用方式：在想下线应用的application.yml中添加配置，从而暴露<code>/service-registry</code>端点：</p><div class="language-yml"><button title="Copy Code" class="copy"></button><span class="lang">yml</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#F07178;">management</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#F07178;">endpoints</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#F07178;">web</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#F07178;">exposure</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#F07178;">include</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">service-registry</span></span></code></pre></div><p>发送 POST 请求到<code>/actuator/service-registry</code>端点：</p><div class="language-sh"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">curl</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">-X</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">POST</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">:8000/actuator/service-registry?status=DOWN</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;"> \\</span></span>
<span class="line"><span style="color:#A6ACCD;">   </span><span style="color:#C3E88D;">-H</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Content-Type: application/vnd.spring-boot.actuator.v2+json;charset=UTF-8</span><span style="color:#89DDFF;">&quot;</span></span></code></pre></div><p>实行后的效果类似如下图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/TNUwKhV0JpRtYTVrnGSDO3J0fGl4K5erQeWtaoBStmsZEtYdicxDLtcHefFQaJ4iaicIeCibMXrb1n8kc3TSliakQtg/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p><h3 id="优雅的下线方式" tabindex="-1">优雅的下线方式 <a class="header-anchor" href="#优雅的下线方式" aria-label="Permalink to &quot;优雅的下线方式&quot;">​</a></h3><p>在上文中，我们讲述了四种常见的下线方式，对比来看，方式四 是一种比较优雅的下线方式。</p><p>在实际项目中，我们可以先使用<code>/service-registry</code>端点，将服务标记为DOWN，然后监控服务的流量，当流量为 0 时，即可升级该服务。当然，这里假设我们部署了多个服务实例，当一个服务实例DOWN掉之后，其他服务实例仍然是可以提供服务的，如果就部署一台服务的话，那么讨论优不优雅就没那么重要了。</p><p>除了上述的下线方式之外，还有一种利用<code>EurekaAutoServiceRegistration</code>对象达到优雅下线的目标。</p><ul><li>执行<code>eurekaAutoServiceRegistration.start()</code>方法时，当前服务向 Eureka 注册中心注册服务；</li><li>执行<code>eurekaAutoServiceRegistration.stop()</code>方法时，当前服务会向 Eureka 注册中心进行反注册，注册中心收到请求后，会将此服务从注册列表中删除。</li></ul><p>示例代码如下：</p><div class="language-java"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#89DDFF;">@</span><span style="color:#C792EA;">RestController</span></span>
<span class="line"><span style="color:#89DDFF;">@</span><span style="color:#C792EA;">RequestMapping</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">value</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">/graceful/registry-service</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#C792EA;">public</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">class</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">GracefulOffline</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">@</span><span style="color:#C792EA;">Autowired</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">private</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">EurekaAutoServiceRegistration</span><span style="color:#A6ACCD;"> eurekaAutoServiceRegistration</span><span style="color:#89DDFF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">@</span><span style="color:#C792EA;">RequestMapping</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">/online</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">public</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">String</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">online</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">this.</span><span style="color:#A6ACCD;">eurekaAutoServiceRegistration</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">start</span><span style="color:#89DDFF;">();</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">execute online method, online success.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">@</span><span style="color:#C792EA;">RequestMapping</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">/offline</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">public</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">String</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">offline</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">this.</span><span style="color:#A6ACCD;">eurekaAutoServiceRegistration</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">stop</span><span style="color:#89DDFF;">();</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">execute offline method, offline success.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#89DDFF;">}</span></span></code></pre></div><p>到这里，我们已经介绍了两种相对优雅的下线方式了。具体如何操作，我们可以根据实际上情况进行包装，或者利用自动化的脚本来实现更加优雅的下线方式。</p><h2 id="灰度发布" tabindex="-1">灰度发布 <a class="header-anchor" href="#灰度发布" aria-label="Permalink to &quot;灰度发布&quot;">​</a></h2><h3 id="蓝绿部署" tabindex="-1">蓝绿部署 <a class="header-anchor" href="#蓝绿部署" aria-label="Permalink to &quot;蓝绿部署&quot;">​</a></h3><p>蓝绿部署，英文名为 Blue Green Deployment，<strong>是一种可以保证系统在不间断提供服务的情况下上线的部署方式。</strong></p><p>如何保证系统不间断提供服务呢？那就是同时部署两个集群，但仅对外提供一个集群的服务，当需要升级时，切换集群进行升级。蓝绿部署无需停机，并且风险较小。其大致步骤为：</p><blockquote><ul><li>部署集群 1 的应用（初始状态），将所有外部请求的流量都打到这个集群上</li><li>部署集群 2 的应用，集群 2 的代码与集群 1 不同，如新功能或者 Bug 修复等</li><li>将流量从集群 1 切换到集群 2</li><li>如集群 2 测试正常，就删除集群 1 正在使用的资源（例如实例），使用集群 2 对外提供服务</li></ul></blockquote><p>因为在使用蓝绿部署的方式时，我们需要控制流量，所以我们需要借助路由服务，如 Nginx 等。</p><h3 id="滚动部署" tabindex="-1">滚动部署 <a class="header-anchor" href="#滚动部署" aria-label="Permalink to &quot;滚动部署&quot;">​</a></h3><blockquote><p>滚动部署，英文名为 Rolling Update，同样是一种可以保证系统在不间断提供服务的情况下上线的部署方式。和蓝绿部署不同的是，滚动部署对外提供服务的版本并不是非此即彼，而是在更细的粒度下平滑完成版本的升级。</p></blockquote><blockquote><p>如何做到细粒度平滑升级版本呢？滚动部署只需要一个集群，集群下的不同节点可以独立进行版本升级。比如在一个 12 节点的集群中，我们每次升级 4 个节点，并将升级后的节点重新投入使用，周而复始，直到集群中所有的节点都更新为新版本。</p></blockquote><p>**这种部署方式相对于蓝绿部署，更加节约资源，因为它不需要运行两个集群。**但这种方式也有很多缺点，例如：</p><blockquote><ul><li>**没有一个确定 OK 的环境。**使用蓝绿部署，我们能够清晰地知道老版本是 OK 的，而使用滚动发布，无法确定</li><li><strong>修改了现有的环境</strong></li><li>**如果需要回滚，很困难。**举个例子，在某一次发布中，我们需要更新 100 个实例，每次更新 10 个实例，每次部署需要 5 分钟。当滚动发布到第 80 个实例时，发现了问题，需要回滚。这时，我们估计就要疯了。</li><li>有的时候，我们还可能对系统进行动态伸缩，如果部署期间，**系统自动扩容/缩容了，我们还需判断到底哪个节点使用的是哪个代码。**尽管有一些自动化的运维工具，但是依然令人心惊胆战。</li></ul></blockquote><p>并不是说滚动发布不好，滚动发布也有它非常合适的场景。</p><h3 id="金丝雀部署" tabindex="-1">金丝雀部署 <a class="header-anchor" href="#金丝雀部署" aria-label="Permalink to &quot;金丝雀部署&quot;">​</a></h3><blockquote><p>金丝雀部署又称灰度部署（或者，灰度发布），英文名为 Canary Deployment，<strong>是指在黑与白之间，能够平滑过渡的一种发布方式</strong>。</p></blockquote><blockquote><p>金丝雀的名称来源于「矿井中的金丝雀」，早在 17 世纪，英国矿井工人发现，金丝雀对瓦斯这种气体十分敏感，空气中哪怕有极其微量的瓦斯，金丝雀也会停止歌唱；而当瓦斯含量超过一定限度时，虽然鲁钝的人类毫无察觉，金丝雀却早已毒发身亡。当时在采矿设备相对简陋的条件下，工人们每次下井都会带上一只金丝雀作为“瓦斯检测指标”，以便在危险状况下紧急撤离。</p></blockquote><p>我们来看一下金丝雀部署的步骤：</p><blockquote><ul><li>准备好部署各个阶段的工件，包括：<strong>构建工件，测试脚本，配置文件和部署清单文件</strong></li><li>从负载均衡列表中移除掉“金丝雀”服务器</li><li>升级“金丝雀”应用（切断原有流量并进行部署）</li><li>对应用进行自动化测试</li><li>将“金丝雀”服务器重新添加到负载均衡列表中（连通性和健康检查）</li><li>如果“金丝雀”在线使用测试成功，升级剩余的其他服务器（否则就回滚）</li></ul></blockquote><blockquote><p>在金丝雀部署中，常常按照用户量设置路由权重，例如 90% 的用户维持使用老版本，10% 的用户尝鲜新版本。不同版本应用共存，经常与 A/B 测试一起使用，用于测试选择多种方案。</p></blockquote><blockquote><p>金丝雀部署比较典型的例子，就是我们在使用某个应用的时候，该应用邀请我们进行“内测”或者“新版本体验”，如果我们同意了，那么我们就成了金丝雀。</p></blockquote>`,321),o=[e];function t(r,i,c,g,C,y){return a(),n("div",null,o)}const m=s(p,[["render",t]]);export{A as __pageData,m as default};
