



# 秒杀思路

## 前言

最近心血来潮，想起前段时间公司举办的线下秒杀活动不理想，想研究一下秒杀系统的优化。当时活动现场有 200+ 会员，由于我们先前没有经验，各种原因导致用户在秒杀的时候 APP 页面白屏、卡死。业务部门想把手机甩我们开发脸上......当时我刚毕业也刚入职不久，不敢发表意见。现在逐渐膨胀，是时候重新设计一套秒杀系统了......



## 问题分析

有经验的同学看到 200+ 会员都出现白屏、卡死，可能会觉得公司技术太 low 。其实不然，公司系统架构还是很好的，大佬搭建了一套 SpringCloud 组件，都是比较新的版本。这次秒杀活动失利的确是之前没有这样的经验，很多代码考虑没到位，访问数据库的次数太多。虽然会员数是 200 ，但是会员从进入秒杀页面，点击秒杀商品，再到秒杀下单，这中间夸了几个微服务，对于数据库的访问远远不止 200 。

对代码分析之后，我们公司秒杀其实是和普通订单是同一个流程，只是加了一个秒杀 ID 字段。下单流程在一个事务里面各种校验、跨服务调用、加锁扣减库存、插入订单商品信息、物流配送信息......等。这样跨服务和多次访问数据库很明显无法满足秒杀业务瞬间流量巨大的特性。就像下面的图

![image-20220628175623778](https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.23/202206281756833.png)

上面就是我们下单的粗略流程，其实具体比这个要复杂，在每个微服务里面又调用了其他服务访问数据库。。。因为一个用户至少就是一个线程，当用户量过大线程数就很多，服务资源是有限的。当资源不够用的时候，后来的用户请求就会等待服务器释放资源处理，用户就会觉得卡。用户一旦觉得卡，就很可能会回退页面刷新，或者再次点击提交订单，然后请求又过来，又访问数据库，就会更卡。一次请求每多访问一次数据库，就需要更多的时间来处理，所以请求太多最终服务器处理不过来，前端得不到响应，用户屏幕会卡在那白屏。

还有一个关键原因是秒杀商品的查询，也是走的数据库，而且由于公司业务特殊性，不同地区的会员看到的商品不同等其他业务，导致秒杀商品的查询也比较慢，系统吞吐量低，最后可能导致用户白屏，流程和上面下单的差不多。说到底就是要提高系统吞吐量，让服务器尽快释放资源。

针对上述问题：在应对秒杀系统这样一瞬间的巨大流量，现在系统架构存在的核心问题：

- 没有遵循服务单一原则，把秒杀功能做在订单服务里面，万一秒杀系统压力过大还会影响到正常的订单业务
- 和普通订单一样巨大流量蜂拥而至加锁扣减库存，导致很多无效请求占用资源
- 秒杀订单链接没有加密，给专业团队可趁之机
- 大量操作直接操作数据库，频繁磁盘 IO，系统吞吐量很低，甚至有可能数据库挂掉

以上是几大核心问题，解决了这几个问题，基本上就可以实现较好的秒杀系统了。下面全面分析、解决秒杀系统问题：

## 服务单一职责

> 我们都知道秒杀的特性，瞬间流量巨大。如果将秒杀功能做在订单服务里面，万一秒杀占用的资源过多，或者秒杀功能直接把服务搞挂，正常订单业务也会受影响。所以秒杀要单独部署微服务
>

## 巨大流量处理(限流)

秒杀一瞬间的巨大流量不仅仅有广大用户正常请求，还有用户不必要的频繁点击、恶意用户、恶意攻击等。如果不做好处理很有可能请求还没到库存扣减那里，微服务集群就顶不住了。对于巨大的流量，采取适当的限流措施是很有必要的。常用限流方式有下面几种：

### 前端限流

我们要在巨大流量的基础上去尽可能减少一些不必要的流量，活动未开始的时候前端按钮就置灰，不让点击，活动开始之后限制用户点击按钮的频率。这样可以去除正常用户的大量不必要请求。

### Nginx 限流

前端限流只能防止正常用户，但是有些恶意用户有点开发知识，通过网页获取 URL 来模拟请求，这里可以通过 Nginx 对同一 IP 做出每秒访问次数限制。

```apl
limit_req_zone $binary_remote_addr zone=one:10m rate=20r/s; #限制同一IP 允许访问20次/S
```

### 网关限流

根据现有的网关集群、秒杀服务集群，估算集群能够支撑的最大请求，然后限制流量。网关限流以 GateWay 为例，可以对 IP、用户、接口限流，这里可以选择对秒杀接口限流。常用的网关限流算法有，漏桶算法 和 令牌桶算法，我们选择使用令牌桶算法限流，因为这个算法可允许突发的瞬间流量处理，GateWay 内置了一个过滤器工厂配置 RequestRateLimiterGatewayFilterFactory 使用它即可，它需要依赖 Redis

```scala
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifatId>spring-boot-starter-data-redis-reactive</artifactId>
</dependency>
```

配置：

```yml
server:
  port: 40000
spring:
  cloud:
    gateway:
      routes:
        - id: sec_kill_route
          uri: lb://hosjoy-b2b-seckill
          predicates:
            - Path=/seckill/**
          filters:
            - name: RequestRateLimiter
              args:
                key-resolver: '#{@apiKeyResolver}'  #从Spring容器中获取限流的Bean
                redis-rate-limiter.replenishRate: 100 #令牌填充速率（每秒处理的请求）
                redis-rate-limiter.burstCapacity: 3000 #令牌总容量（1秒内能允许的最大请求数）
  application:
    name: hosjoy-b2b-gateway
  redis:
    host: localhost
    port: 6379
    database: 0
```

代码：

```java
@Bean
public KeyResolver apiKeyResolver() {
    return exchange -> Mono.just(exchange.getRequest().getPath().value());
}
```

如果公司有使用阿里的 Sentinel 组件，这里也可以在网关层使用 Sentinel 做限流，功能强大，方便监控、熔断、降级，使用非常方便！

### 集群实例扩充

没有什么流量是服务实例个数解决不了的，如果有，那么就继续加服务实例......这样通过增加服务实例来对应大流量也可以变相的达到限流效果 。



## 应对恶意请求

相信大家都有所耳闻，有些 “专业团队” ，专门通过代别人抢茅台等商品牟利。对于这种团队，他们不仅有多 IP ，甚至还有可能有多账户！就是通过各种渠道低价购买正常用户的账号来逃避风控系统。对于这样的 “专业团队”，单纯的限流不能完全解决这个问题，你想一下，有可能发生这种情况，这些恶意的请求被处理了，抢到了商品，但是广大用户没有抢到，这个问题就很严重。对于这种情况，我们可以采取两种方案:

### **秒杀链接加密**

在秒杀控制器的传参中，我们一般会接受场次 ID、商品 ID，可以再多加一个和商品匹配的密码参数，只有密码正确才能继续流程，否则记录密码错误次数自增。这个密码是在秒杀场次和商品上架的时候随机生成，就连开发这个功能的人都不知道！

```java
@PostMapping("/sec-kill")
public void secKill(@RequestParam("secId") Long secId,
                    @RequestParam("productId") Long productId,
                    @RequestParam("password") String password){
    SecProductResponse secProduct = (SecProductResponse) redisTemplate.opsForValue()
                                    .get("secId:productId");//场次商品信息
    if(secProduct.getPassword().equals(password)) { //校验秒杀商品密码
        //...
    } else {
        stringRedisTemplate.opsForValue().increment("black:secId:productId:userId");
    }
}
```

### 黑名单过滤

在网关层校验这个用户是不是黑名单，如果是，直接结束。

```java
String s = stringRedisTemplate.opsForValue().get("secId:black:userId");
if(s != null && Integer.parseInt(s) >= maxCount){
    return;
}
```



## 防止用户重复购买

一般来说秒杀活动对于同一个用户的购买是有限制的，如果已经购买过，那么这个用户就不应该继续购买。虽然前端已经做了限制，但是为了防止专业人士，这里在后端也要进行限制。我们可以使用 Redis 来实现

```java
Boolean flag = stringRedisTemplate.opsForValue()
               .setIfAbsent("secId:productId:userId", 1, time, TimeUnit.SECONDS);
if(flag){
  //...
}
```



## 超卖控制、库存扣减

秒杀商品发生超卖是个很可怕的事情，因为秒杀商品本身就很优惠。为了吸引流量以极低的秒杀价格售卖，甚至亏本。如果一旦超卖，公司或者商家可能亏的血本无归。为了控制超卖，我们可以在扣除库存的时候加锁。但是这里必须要加分布式锁，使用本地锁不能控制住。使用分布式锁避免并发造成库存扣减超卖。但是如此一来系统吞吐量会有所下降。我们原来就是跨服务扣减库存，加分布式锁，还访问的数据库，拿大腿都能想到这个对于秒杀的请求量肯定不合适。现在我们在秒杀接口里面虽然可以优化到不跨服务访问数据库了，所以使用分布式锁也能解决这个问题。但是既然是锁，就有资源消耗。有没有不使用分布式锁的方案呢？所以我们可以换个角度考虑这个问题，秒杀商品库存一般都是有一定数量限制的，并且秒杀库存远小于商品可售卖库存。我们可以把这个秒杀库存的数量提前保存在 Redis 里面，然后用 Redis 来预先扣减库存，库存一旦扣减完，就返回秒杀结束，已抢完。如此一来，我们在这里有多少库存就会放进来多少请求，剩余的无效请求全部返回。不但防止了超卖，还做了流量限制，相对于原来的蜂拥而至排队扣减库存模式，这样吞吐量极高。我们可以采用 Redis 的分布式信号量实现，这里可以使用 Redisson 来做具体代码实现

```java
RSemaphore semaphore = redissonClient.getSemaphore("secId:productId");
boolean success=false;
try {
    success = semaphore.tryAcquire(1,50,TimeUnit.MILLISECONDS);
} catch (InterruptedException e) {
    log.error(e);
    return;
}
 if(success){
    //生成订单号
    //发送消息到MQ
}
```

其实分布式信号量也可以算是一种分布式锁，但是它的性能极高，获取一次信号量几乎是 0 - 1 ms，基本不会影响系统吞吐量。



## 流量削峰

经过上面重重关卡，最后调用订单服务的请求数和秒杀商品的库存数量一样。假设 100 万人抢 400 茅台，那么就有 400 请求要调用订单服务，400 并发下单的话，由于还有一系列业务处理，并发访问数据库，其实又回到了最初的模式。在秒杀接口里面访问数据库，这样吞吐量是很低的，还有可能打挂数据库。我们应该让秒杀接口的操作全部走 Redis 。这里我们可以使用消息队列来做 [为什么使用消息队列？](http://mp.weixin.qq.com/s?__biz=MzA5ODExOTI5OA==&mid=2247483667&idx=1&sn=7564c8b2513766225191004e1bafa928&chksm=90973afea7e0b3e8ff23c3eefe44c0e6507561bfb7d8bfe2ce293f2d2610bb34d6b12735c640&scene=21#wechat_redirect)使用 MQ 来削峰，平缓消费创建订单，将峰值流量散开。由于消息队列在强大并发下可能会造成消息丢失等问题，具体可参考 [RabbitMQ 可靠性、重复消费、顺序性、消息积压解决方案](http://mp.weixin.qq.com/s?__biz=MzA5ODExOTI5OA==&mid=2247483690&idx=1&sn=11b7498dd737c42da93eb3437d3792ed&chksm=90973ac7a7e0b3d1a6ede4a3716a6e57031703791a652c98a3c06a2b81b03db585206c231c92&scene=21#wechat_redirect)



## 数据库分表分库

一般来说以上就能实现较好的秒杀系统效果了，如果公司数据量很大，业务很复杂。甚至 MQ 异步消费访问数据库也不能解决的话，那么就用读写分离，读库和写库分开，有效降低数据库压力。还可以去对数据库分表、分库来提升单表并发能力和磁盘 IO 读写性能。

解决以上问题，秒杀流程基本就 OK 了，其实上面的伪代码都很简单，真实实现的话，代码也不复杂，只是要合理的设计方案，该屏蔽过滤的请求就屏蔽过滤，不该访问数据库的不访问即可。下面具体看下这几个环节的流程图



## 商品上架/库存回退

商品上架其实很简单，我们只需要把需要的信息存入 Redis 即可。不过不同公司有不同的业务，比如我公司的业务 B → b → c 的模式，秒杀商品、活动是有区域的，就是说一场活动可能会发生，经营区域在 A、B、C 三个市的会员店可以参与，其他区域的会员店不可以参与。所以针对这种情况，我们需要把秒杀场次信息在所有可允许的区域都要存储一份，就像下面这样

```java
//场次信息
redisTemplate.opsForValue().set("province:cityId:secId","data");
//商品信息
redisTemplate.opsForValue().set("secId:productId","data");
//库存信息
redisTemplate.opsForValue().set("stock:secId:productId:password","data");
```

那么你可能会说，这得存多少 Redis 的 Key 啊......的确，如果场次多一点，选择的区域多一点，是要存不少 key 。计算一下，据 2016 年统计，中国总共好像是 293 个市，按 300 算。假设最近三天有 30 场秒杀活动， 每场活动有 10 个商品 。那么总共需要的 key 数量的计算方法为 城市场次 + 场次商品 + 场次商品库存 = 300 * 30 + 30 * 10 + 30 * 10 = 9600

再按照三天内扫描前后三天再乘个三好了，也就 30000 不到的 key。你觉得这个数量多吗？我们来看看官方对于 Redis 存储 key 数量给的描述：

> Redis can handle up to 2^32 keys, and was tested in practice to handle at least 250 million >keys per instance. Every hash, list, set, and sorted set, can hold 2^32 elements. In other words your limit is likely the available memory in your system.
>
> 来源于 Redis 官网

官方说 Redis 理论上能存储 2^32 个 key ，实际测试中一个实例至少存储 2.5 亿的 key 。最后一句：你的限制其实是你系统的可用内存而已......而且这还只是一个 Redis 实例的数据。所以说不要太小看 Redis ，人家官网声称性能极高，读的速度是110000次/s，写的速度是81000次/s 。而且，如果一个互联网公司在当今缓存界对于 Redis 这么牛逼的缓存中间件的使用量很少，那么一般来说，业务用户量是有限的。不过有一点需要注意，一旦业务大量使用 Redis 作为缓存中间件，必须至少要防止三件事 [Redis 实战应用篇 — 缓存雪崩、缓存击穿、缓存穿透和数据一致性](http://mp.weixin.qq.com/s?__biz=MzA5ODExOTI5OA==&mid=2247483720&idx=1&sn=b7aa67e65e2d926b19ef43c5400285ee&chksm=90973aa5a7e0b3b3946fff99f1e3e1021e0aa1410af11bab823a3712aabf292e703af6c4e1fc&scene=21#wechat_redirect)

因为秒杀活动有一种业务场景是没卖完，虽然这有些尴尬......但是不得不考虑，这里需要在场次结束之后，把没有卖完的库存从 Redis 回退到库存表里面。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.23/202206281806784.png" alt="image-20220628180603721" style="zoom: 67%;" />

如上图，配置定时任务定期扫描近三天要秒杀的场次，然后上架，注意不要重复上架。上架主要是将上图的信息保存到 Redis，然后对于每个场次结束的商品发送延迟消息，在消费者里面判断如果信号量不为 0，就说明秒杀活动没有卖完，需要把库存回退，然后删除 Redis 中的信号量。



## 秒杀商品查询

由于秒杀活动查询频繁、巨大流量，千万不能去数据库查询商品信息。所有查询操作走 Redis ，注意在活动开始之前不要返回商品密码字段。

这里有一点需要注意的地方，因为页面上活动开始之前购买按钮是置灰的，所以在秒杀开始的前一秒，需要去请求一次服务器获取商品密码。假设有十万人准备抢购，那就有十万次请求发到服务器。其实十万次请求到是没什么问题，因为你既然有十万人准备抢购，就得有十万请求要到服务器，如果你在这里觉得十万次请求到服务器不太好，那么你的秒杀接口不是一样要放十万请求到服务器吗？所以关键的问题不是请求数量，而是请求的错峰。就是说你前端不能让十万客户端在真正相同毫秒级别的时间把请求发过来，比如 2021-05-01 00:00:00 有一场秒杀活动，那么前端在 2021-04-30 23:59:58 或者 59 的时候就可以发请求了，但是这里要精确到毫秒去发，1 s = 1000 ms ，前端可以在这 1000-2000 毫秒内错开十万的请求量，这样十万的请求量不在同一个毫秒级别的时间，服务器压力会小一些，而且服务器是走 Redis 查询的，响应时间应该 10 - 20 ms 就可以。拿到商品密码之后判断当前时间是否到达秒杀开始时间，如果到了就恢复按钮状态，如果没到就等时间到了再恢复按钮就行了。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.23/202206281806970.png" alt="image-20220628180635926" style="zoom:67%;" />

## 秒杀流程

下面就是具体的秒杀流程详细图，按顺序描述每一节点要考虑的问题以及解决方案

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.23/202206281809289.png" alt="image-20220628180949215" style="zoom:67%;" />

秒杀流程的伪代码：

```java
@Autowired
private RedisTemplate<String,Object> redisTemplate;
/**
 * 秒杀流程
 * */
@PostMapping("/sec-kill")
public void secKill(@RequestParam("secId") Long secId,
                    @RequestParam("productId") Long productId,
                    @RequestParam("password") String password){
    SecResponse sec = (SecResponse) redisTemplate.opsForValue().get("secId");//场次信息
    LocalDateTime now = LocalDateTime.now();
    if(now.isAfter(sec.getStartTime()) && now.isBefore(sec.getEndTime())){ //校验已开始
        SecProductResponse secProduct = (SecProductResponse) redisTemplate.opsForValue()
                                                   .get("secId:productId");//场次商品信息
        if(secProduct.getPassword().equals(password)){ //校验秒杀商品密码
            Duration duration = Duration.between(sec.getStartTime(), sec.getEndTime());
            int random = (int)(Math.random() * 100);
            long period = duration.getSeconds() + random;
            Boolean flag = stringRedisTemplate.opsForValue()
                           .setIfAbsent("secId:productId:userId", "1", period
                                                                     , TimeUnit.SECONDS);
            if(flag != null && flag){ //校验已购买
                RSemaphore semaphore = redissonClient
                                       .getSemaphore("secId:productId:password" );
                try {
                    //尝试在50ms内获取信号量
                    boolean acquire = semaphore.tryAcquire(num,50, TimeUnit.MILLISECONDS);
                    if(acquire){ //抢到库存
                        String orderNo = generateOrderNo();//生成订单号
                        rabbitTemplate.convertAndSend("hosjoy-b2b-secKill",
                                                      "routingKey",
                                                      "data");//发送消息
                    } else{
                        //如果没抢到，删除已购买的标识(其实不删也没什么问题)
                        stringRedisTemplate.delete("secId:productId:userId");
                    }
                } catch (InterruptedException e) {}
            }
        } else {
            stringRedisTemplate.opsForValue().increment("black:secId:productId:userId");
        }
    }
}
```

以上就是大致的秒杀流程代码，也是我觉得比较好的秒杀流程，设计完之后请同事大佬指点（咳咳，其实我是想装个 X，嘘！）了一下。我与他的想法或者说设计思路有主要两点不同

- 实现 Redis 库存的数据结构
- 什么时候算秒杀成功

他使用的是 Redis 的 List 数据结构来存放库存，比如有 100 个库存就 leftPush 100 个商品 id。然后通过 pop 的方式去扣减库存。我对比了一下分布式信号量 Semaphore 和 List 结构，两者都可以实现，用起来也都很方便，还有个 incr 和 decr 自增自减其实也可以，但是这都是默认针对秒杀商品只能秒杀一件的 。如果说业务允许秒杀可以购买多件商品，那么 List 和 decr 就必须要加分布式锁来控制了，如此一来会让系统的吞吐量就相对被降低了。因为 List 一次只能弹出一个元素，decr 虽然可以传参数扣减，但是可以减到负数的。假设 A 用户秒杀 5 件，库存现在只有 4 件，B 用户秒杀 2 件，理论上 A 是秒杀失败，但是 B 应该秒杀成功，如果不加分布式锁，A 把库存减到 -1 ，发现不对，要把库存加回去，此时 B 秒杀 2 件，发现库存已经是 -1 了，也秒杀失败，这就有问题了。所以......分布式信号量牛逼啊！

还有个区别是他有个用户购买之后排队的概念来校验重复购买，我这直接 setIfAbsent 来校验，这个区别其实无关紧要，重要的是什么时候算秒杀成功。

## 我的设计思路

> 以我的设计方案，只要用户尝试获取信号量成功，就算秒杀成功，但是这里其实可以不用立即返回告诉用户，最好让用户手机继续转圈 1-2 秒之后告诉他秒杀成功，因为 MQ 发送消息到消费成功有一定时间，如果立即告诉用户秒杀成功，而订单还在生成中，可能会给用户带来不好的用户体验。等 1-2 秒之后 MQ 消息消费完成订单也生成成功，此时正好用户收到秒杀成功，订单也生成成功就很 NICE！

> 那么你可能会有疑问，如果消费者生成订单报错了怎么办？不得不说，这是个必须考虑的问题，毕竟 MQ 的消费说不准。这里当然我也考虑到了这种情况，如果消费失败首先采取重试，如果重试 3 次仍然失败，那说明这里产生了代码问题导致订单生成失败，记录下来报错消息，然后人工查询错误，恢复用户订单即可。毕竟这是个小概率的事情，也不会有一堆订单消费失败吧？更何况人家本来就是在秒杀服务抢到了库存，既然抢到了我就算他秒杀成功了，订单由于其他原因生成失败，我给他手动生成订单，保证最终一致性即可，不然怎么跟用户交代？



## 同事的设计思路

而同事他说不应该这么设计，应该设计为用户抢到信号量只是有一个秒杀机会，具体秒杀成功与否要看订单服务消费的结果。如果订单服务消费失败，就回滚秒杀库存到 Redis ，让其他用户来抢，因为可能会存在业务校验不通过，用户没有购买资格。不得不说，他考虑问题一向很周到，我从跟他后面做项目开始到现在也成长很多，他真的是实力很强的大佬！

不过我的设计初衷是没有考虑到有业务校验用户没有资格购买商品，为什么会有用户没有资格购买商品……这特么什么业务场景，既然没资格买为什么要让他看到秒杀活动？。但是仔细一想，这样根据订单生成结果判定秒杀结果其实是有点问题的。

### 存在的问题

- 假设 100 万人抢 400 茅台，本来全部抢完之后你提醒没抢到的用户秒杀商品已抢完了。但是订单服务那边消费到第 399 和 400 个消息的时候失败了，回滚了订单，回滚了库存到 Redis 。如果是因为业务校验未通过，那我认为是否应该不让用户看见这个活动，或者想办法在抢到秒杀机会之前就提示用户没有参加资格会比较好
- 此时消费到第 399 和 400 消息大约过了 3-5 秒，你把它回滚了。正常用户刚开始看没抢到，可能都走了，这还有可能发生少卖。
- 如果不是因为业务校验的问题，而是代码问题导致的报错，这时回滚了订单，感觉这个用户有点惨啊，明明是系统问题，却让用户背锅......
- 如果该用户由于代码问题被回滚了订单，然后去秒杀商品页面又看到了库存剩余再次秒杀，然后再次失败，再次秒杀，再次失败......如此循环下去，我觉得他的内心是崩溃的......，不过这个概率很小

看到这里大伙可能会觉得，我靠这个博主太不要脸了，就挑别人的刺，不考虑自己的问题

emmm 我怎么会是这种人呢......



### 我的方案存在的问题

> - 需要有人去关注秒杀活动，虽然出错的概率比较小，但是一旦订单服务报错，你得有人去尽快生成/恢复订单，耗费人力。如果恢复了订单，用户最后不支付的话，那这个人力资源相当于白费了呀。。。
> - 未支付就在设计逻辑上算用户秒杀成功，这样可能领导听起来不太能接受，如果先让用户支付，支付完成才算秒杀成功，然后去生成订单，这样领导应该会很赞同......这个看起来没问题，实际实现细节上有没有问题还没有研究过，毕竟天猫、淘宝也是先生成订单才去支付的，等第二版更新。

个人觉得每个人的方案都可能存在一定的局限、问题，毕竟没有完美的方案，只能最后根据实际业务情况或者公司所有同事一起讨论去选用一种更为符合的设计方案，或者在此基础上再做优化。

# 秒杀系统设计要点

秒杀，就像是计划经济的菜市场，过客匆匆，你来我往。熙熙攘攘一阵子，过后只留下冷清寂寞的大街。

且看一个卖鹅的故事。↓↓↓

就在昨天。天刚蒙蒙亮，大概是”早晨五六点钟“，几个程序员顶着蓬松的头发，下班结伴而行。这个时候，街上的路灯还没有灭的干脆。几个锻炼的老大爷，叉着腰，身体前倾，弯成一张弓。

所以，胡同岔口里一个卖鹅的小贩，就显得特别的显眼。就见一大群鹅被关在诺大的笼子里，扑棱着翅膀。有几只精力旺盛的，伸长脖子呱呱叫着，小贩听得心烦，就用手中的树枝敲它们的脑袋。

小贩歪了歪嘴，又用眼角余光扫了下手机，已经五点六十了。就在这时，四面八方就围上来一群大妈，就像是从地底冒出来一样。刚开始还悠然的靠拢，等看到笼子果然有一群鹅，就捏着手里的小包，争先恐后的小跑起来。

**这来势汹汹的阵势，吓了大家一跳，程序员们站住不动了。**大爷的腰也不弯了，就连那些聒噪的鹅，也不叫了。

很快就有大妈帮小贩打开了笼子，不容分说，扯住一只鹅的脖子就拖了出来。接着就有另外一只手扯住了另一只鹅的翅膀。一下子人喊鹅嘶，吵吵嚷嚷，下起了鹅毛大雪。不一会儿，所有的鹅就都在大妈们手里了。但也有更多没得到鹅的大妈，用手绢在一旁抹着悔恨嫉妒的泪水。

王大妈最高兴了，她手大，抓了三只，其中两只倒霉的鹅被她握在一只手里，脖子拧成一根麻花。也有被捏死的鹅，犯了鹅命的大妈就不想要了，但有更多的大妈根本就不嫌弃。

**小贩长吁一口气，招数确实有效，就搞了个秒杀，这群犯了瘟病的鹅，瞬间被低价处理了。**



## 秒杀难点

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207142119905.png" alt="image-20220714211904840" style="zoom:67%;" />

**1、流量超出承载范围**
秒杀，一般归作`突发流量`，平常一天的请求量，可能集中在几秒之内就能完成。秒杀资源的稀缺，也会造成资源成为热点，发生多人争抢的局面。想象一下小长假的高速公路收费站，就能够了解到一无所得的参与者有多火大。

**2、资源冲突**
如果采用传统的数据库进行数据存储，对同一资源的争抢，就会面临严重的锁冲突问题。一般是通过一个前置的，速度更快的存储顶在前面，这就涉及到源库和目标库的数据同步问题。

从商品资源的上架，到秒杀的完成，会经历一个短暂的混沌状态，出现数据不一致的情况。在请求量非常集中的情况下，还会产生并发问题，个体的行为和结果，是不可预测的。

**3、难度高**
秒杀对基础设施和技术的要求也是比较高的，从接入层到缓存到存储层，以及安全方面的考虑，需要多个组件的参与，而且每个组件都需要进行优化。

总之，吵吵闹闹一场，最终会归于平静。为了秒杀而准备的硬件资源，不能就放在那里闲置了吧，所以一般还会有一个资源释放阶段，这是后话，我们不做过多关注。

## 业务三阶段

一般的，秒杀业务会分为三个阶段。其中，抢购阶段，就是我们常说的秒杀业务。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207142119951.png" alt="image-20220714211949891" style="zoom:67%;" />

**1、准备阶段**
在准备阶段，除了硬件和软件系统的准备，一般会有一个活动上的预热，互联网运营会将类似电线杆上小广告的东西，广而发之。从前，有个客户搞了个秒杀活动，100个库存99个人参与，99个人有90个内部员工，尴尬呵呵。

如果有自己的app，通过通知、订阅，会达到比较好的效果。如果涉及的商品多，参与人数巨大，会对数据进行预处理，进行提前预热。一切准备妥当，就可以抽根烟，等着倒计时了。

**2、抢购**
俗话说，台上一分钟，台下十年功。秒杀开始，会有大量的瞬间请求涌入，该到了上台表演的时候了。这个阶段，我们的每个系统和模块，都会迅速轮转起来，任何一个点考虑不周，都会造成本次秒杀活动的失败，所以关键组件要保证极高可用。

**3、结束清算**
上面也说过，秒杀会有一个短暂的混沌态。清算阶段，就要完成数据的最终一致性，落库动作可能会持续不少时间。可能有的用户，在付款的那一刻，后悔了，商品要重新归位回仓。回仓后的商品一般会再次售卖，比如火车票，30分钟后可以再抢一次；有的商品就可以被锁定下架，永远消失了。

## 制约原理

这里，我们大体说一下秒杀系统在技术方面的基本制约原理，详细的描述和代码，我们在后面的章节里进行说明。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.6.30/202207142120112.png" alt="image-20220714212033015" style="zoom: 60%;" />

### 数据预热

有的系统进行秒杀的，可能就那么几件商品，手工录入都玩得转。对于平台类型，或者用户量巨大的app，秒杀的商品就不再那么简单。

中间，会进行一些数据的合并，或者二维展开，也就是准备秒杀的数据。这些数据进行处理之后，会提前进入到秒杀系统进行数据预热。

秒杀阶段进行的是否顺利，得看数据准备的是否合理。

### 请求承载

这是请求的最外层，属于接入层。做的好的系统，能够在接入层就屏蔽大部分请求，极大的减轻后端服务的压力。

**连接数承载**
对于接入层来说，首先一个挑战就是连接数。一般互联网的接入层，就是lvs+nginx。这里会涉及到对操作系统的优化，以及对于nginx本身的优化。

**并发承载**
对于落到某台机器上的请求，依然会存在并发高的问题。线程池使用要合理，怎么去进行过滤，合并等，有一定挑战。

**负载均衡**
请求要能真正的做到均衡，不能产生热点问题。比如nginx的ip_hash，虽然能一定程度上规避分布式session问题，但请求会不均衡。

**重试？**
秒杀业务不要配置重试，会加剧系统负载。请求失败？那就再来一次。

**系统隔离**
秒杀业务占用的系统资源，和正常运行的系统严重不对等。如果有条件，秒杀系统的硬件和服务环境，要与正常业务系统进行一定程度的隔离。要提前评估对其他服务的压力，避免影响正常业务。

**CDN**
对于html，js，css，图片等内容，占用了大量的带宽。如果将这些资源都放在自己的服务器上，流量到来时会迅速占满带宽，造成正常的秒杀请求无法完成。CDN可以有效解决这个问题。剩下的请求，就是真正的秒杀业务。

**减小请求包**
对网络请求包，要进行大量优化。可以开gzip压缩，资源本身也进行压缩，去掉请求包中的无用信息，对网络报文进行精简。

### 请求拦截

秒杀系统一个非常大的原则，就是要把尽量多的无效请求，拦截在外部。请求拦截，可以分为上游拦截和业务拦截。

**上游拦截**
拦截方面，存在一个全局的设置。当系统判断以及达到瓶颈阶段，就可以通过全局限流方式进行服务降级，对于一些次级服务，要进行熔断处理。对于前端来说，也是需要进行一些优化的。比如浏览器缓存，防重入验证等，能够拦截数量可观的请求。

**业务拦截**
除了一些全局的限制，对于大部分请求来说，和用户是息息相关的。一个用户，可能会频繁的刷新，或者绕过前端，直接使用软件调用后端接口。这些用户的非法请求，也要进行拦截。

同时，用户对资源的争夺，也不应该无限等待。比如100个库存的商品，第1w个请求到来的时候，就不需要再排队等待了，直接返回秒杀完毕就ok了。

排队方面，会用到jvm内排队，也会用到外部的消息队列，mq，进行请求的缓冲。

### 数据缓存

缓存，可能是秒杀系统中最重要的一个组件了。从前端缓存，到jvm缓存，再到分布式缓存，都会对系统性能产生数量级的提升。值得注意的是，由于秒杀系统严重依赖缓存系统，所以缓存系统需要做高可用。

缓存的读操作，要考虑数据的加载和同步。写请求，就要考虑数据的合并与并发写入，数据的一致性等。虽然缓存的速度比起DB来，快了很多很多，但它的性能总是有瓶颈的，相关代码要着重优化。

### 安全

技术的门槛越来越低，二年级的小学生都开课教swift了，写个秒杀插件什么的，不费吹灰之力。秒杀系统的安全性比较重要，应该说和钱打交道的系统，都是容易出问题的。你要是想薅羊毛，认准营销、秒杀业务，准没错。

要尽量提高作弊门槛，比如url动态化，从入口就隔绝了大部分攻击；验证码，只会增加攻击者的成本。有些安全性级别较高的，还会增加风控规则，比如同一ip请求过多封禁、账号注册日期三天之内不允许参与、秒杀的门槛必须是金牌会员等。

我曾经经历过一次，对方本来是一个算加减乘除的验证码，脚本都写好了。结果秒杀前5分钟，验证码12306附体，xjjdog直接放弃了。

### 躲在幕后的DB

在整个秒杀系统中，传统的DB，只能灰溜溜的躲在幕后（小流量除外）。我要是DB，也会躲在后面瑟瑟发抖。

DB的数据，要提前载入到秒杀系统中进行运算，秒杀完毕，还要把狼藉的数据进行落地与清算。在笔者见过的不少秒杀场景中，甚至不需要DB的参与，真是艺高人胆大。

这就引申出另外一个问题。假如缓存系统出现问题，请求要不要穿透呢？我的建议是，不需要。非正常的请求，会瞬间压垮DB，产生更加严重的数据错乱问题，假如没有做隔离，后果会更狂野。与其错了，不如认怂，乖乖的复盘写故障报告吧。

## End

秒杀，夺宝，p2p，是互联网创造的，钱袋子三大杀手。

我要说一些隐秘的事情。前不久，我的这群鹅本来好好的，结果混进一只长了瘟病的鸡，没几天就病恹恹的不行了，要是扔了怪可惜的。这卖鹅的时间线，也搞的十分紧凑。

就在昨天，我就放出了有一批廉价鹅要处理的消息。为了让更多的大妈相信，我按照市面价格打了个五折，其实打一折都能出手（抖音上那种鹅不敢卖）。**5点多我就给几只快不成的鹅，注射了兴奋剂，希望它们能多撑一会，还拿了根树枝敲它们的脑袋进行确认。****不是我自信，这种场景，就是死鹅也卖得出去。**但死的多了，毕竟不好。为了限制拥挤的人流，我特意把笼子口的铁丝角给漏出来，不少大妈划破了手都没把鹅抓到，我也搞不清她们是不幸，还是幸运。

是谁首先创造的秒杀？真是天才。和饥饿营销一样，收的是智商税吧。哈哈哈~

# 面霸篇：秒杀系统如何设计⭐⭐

[面霸篇：秒杀系统如何设计 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzkzMDI1NjcyOQ==&mid=2247491158&idx=1&sn=5ad3081c25dace2743b63de87d2f798f&chksm=c27c5c60f50bd57632d30ae083322e47b3b0ab2af973e5111b3d0b0346d45b7fe67af0a2ee83&mpshare=1&scene=23&srcid=0813JXqSdpGqnGLUywN0CXLj&sharer_sharetime=1660375024536&sharer_shareid=29b8a04db1dbd975e3bf4e9f47e7ac67#rd)

## 前言

高并发下如何设计秒杀系统？这是一个高频面试题。这个问题看似简单，但是里面的水很深，它考查的是高并发场景下，从前端到后端多方面的知识。

秒杀一般出现在商城的`促销活动`中，指定了一定数量（比如：10个）的商品（比如：手机），以极低的价格（比如：0.1元），让大量用户参与活动，但只有极少数用户能够购买成功。这类活动商家绝大部分是不赚钱的，说白了是找个噱头宣传自己。

虽说秒杀只是一个促销活动，但对技术要求不低。下面给大家总结一下设计秒杀系统需要注意的9个细节。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131739368.png" alt="image-20220813173915263" style="zoom:50%;" />

## 1 瞬时高并发

一般在`秒杀时间点`（比如：12点）前几分钟，用户并发量才真正突增，达到秒杀时间点时，并发量会达到顶峰。

但由于这类活动是大量用户抢少量商品的场景，必定会出现`狼多肉少`的情况，所以其实绝大部分用户秒杀会失败，只有极少部分用户能够成功。

正常情况下，大部分用户会收到商品已经抢完的提醒，收到该提醒后，他们大概率不会在那个活动页面停留了，如此一来，用户并发量又会急剧下降。所以这个峰值持续的时间其实是非常短的，这样就会出现瞬时高并发的情况，下面用一张图直观的感受一下流量的变化：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131739115.png" alt="image-20220813173934050" style="zoom:67%;" />

像这种瞬时高并发的场景，传统的系统很难应对，我们需要设计一套全新的系统。可以从以下几个方面入手：

1. 页面静态化
2. CDN加速
3. 缓存
4. mq异步处理
5. 限流
6. 分布式锁

## 2. 页面静态化

活动页面是用户流量的第一入口，所以是并发量最大的地方。

如果这些流量都能直接访问服务端，恐怕服务端会因为承受不住这么大的压力，而直接挂掉。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131739846.png" alt="image-20220813173947737" style="zoom:50%;" />

活动页面绝大多数内容是固定的，比如：商品名称、商品描述、图片等。为了减少不必要的服务端请求，通常情况下，会对活动页面做`静态化`处理。用户浏览商品等常规操作，并不会请求到服务端。只有到了秒杀时间点，并且用户主动点了秒杀按钮才允许访问服务端。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131740798.png" alt="image-20220813174002697" style="zoom:67%;" />

这样能过滤大部分无效请求。

但只做页面静态化还不够，因为用户分布在全国各地，有些人在北京，有些人在成都，有些人在深圳，地域相差很远，网速各不相同。

如何才能让用户最快访问到活动页面呢？

这就需要使用CDN，它的全称是Content Delivery Network，即内容分发网络。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131740588.png" alt="image-20220813174016451" style="zoom:67%;" />

使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。

## 3 秒杀按钮

大部分用户怕错过`秒杀时间点`，一般会提前进入活动页面。此时看到的`秒杀按钮`是置灰，不可点击的。只有到了秒杀时间点那一时刻，秒杀按钮才会自动点亮，变成可点击的。

但此时很多用户已经迫不及待了，通过不停刷新页面，争取在第一时间看到秒杀按钮的点亮。

从前面得知，该活动页面是静态的。那么我们在静态页面中如何控制秒杀按钮，只在秒杀时间点时才点亮呢？

没错，使用js文件控制。

为了性能考虑，一般会将css、js和图片等静态资源文件提前缓存到CDN上，让用户能够就近访问秒杀页面。

看到这里，有些聪明的小伙伴，可能会问：CDN上的js文件是如何更新的？

秒杀开始之前，js标志为false，还有另外一个随机参数。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131741882.png" alt="image-20220813174159754" style="zoom:67%;" />

当秒杀开始的时候系统会生成一个新的js文件，此时标志为true，并且随机参数生成一个新值，然后同步给CDN。由于有了这个随机参数，CDN不会缓存数据，每次都能从CDN中获取最新的js代码。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131742395.png" alt="image-20220813174214266" style="zoom:67%;" />

此外，前端还可以加一个定时器，控制比如：10秒之内，只允许发起一次请求。如果用户点击了一次秒杀按钮，则在10秒之内置灰，不允许再次点击，等到过了时间限制，又允许重新点击该按钮。

## 4 读多写少

在秒杀的过程中，系统一般会先查一下库存是否足够，如果足够才允许下单，写数据库。如果不够，则直接返回该商品已经抢完。

由于大量用户抢少量商品，只有极少部分用户能够抢成功，所以绝大部分用户在秒杀时，库存其实是不足的，系统会直接返回该商品已经抢完。

这是非常典型的：`读多写少` 的场景。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131742435.png" alt="image-20220813174232339" style="zoom:50%;" />

如果有数十万的请求过来，同时通过数据库查缓存是否足够，此时数据库可能会挂掉。因为数据库的连接资源非常有限，比如：mysql，无法同时支持这么多的连接。

而应该改用缓存，比如：redis。

即便用了redis，也需要部署多个节点。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131742610.png" alt="image-20220813174250496" style="zoom:50%;" />

## 5 缓存问题

通常情况下，我们需要在redis中保存商品信息，里面包含：商品id、商品名称、规格属性、库存等信息，同时数据库中也要有相关信息，毕竟缓存并不完全可靠。

用户在点击秒杀按钮，请求秒杀接口的过程中，需要传入的商品id参数，然后服务端需要校验该商品是否合法。

大致流程如下图所示：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131743267.png" alt="image-20220813174305181" style="zoom:50%;" />

根据商品id，先从缓存中查询商品，如果商品存在，则参与秒杀。如果不存在，则需要从数据库中查询商品，如果存在，则将商品信息放入缓存，然后参与秒杀。如果商品不存在，则直接提示失败。

这个过程表面上看起来是OK的，但是如果深入分析一下会发现一些问题。

### 5.1 缓存击穿

比如商品A第一次秒杀时，缓存中是没有数据的，但数据库中有。虽说上面有如果从数据库中查到数据，则放入缓存的逻辑。

然而，在高并发下，同一时刻会有大量的请求，都在秒杀同一件商品，这些请求同时去查缓存中没有数据，然后又同时访问数据库。结果悲剧了，数据库可能扛不住压力，直接挂掉。

如何解决这个问题呢？

这就需要加锁，最好使用分布式锁。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131743961.png" alt="image-20220813174320875" style="zoom:67%;" />

当然，针对这种情况，最好在项目启动之前，先把缓存进行`预热`。即事先把所有的商品，同步到缓存中，这样商品基本都能直接从缓存中获取到，就不会出现缓存击穿的问题了。

是不是上面加锁这一步可以不需要了？

表面上看起来，确实可以不需要。但如果缓存中设置的过期时间不对，缓存提前过期了，或者缓存被不小心删除了，如果不加速同样可能出现缓存击穿。

其实这里加锁，相当于买了一份保险。

### 5.2 缓存穿透

如果有大量的请求传入的商品id，在缓存中和数据库中都不存在，这些请求不就每次都会穿透过缓存，而直接访问数据库了。

由于前面已经加了锁，所以即使这里的并发量很大，也不会导致数据库直接挂掉。

但很显然这些请求的处理性能并不好，有没有更好的解决方案？

这时可以想到`布隆过滤器`。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131743888.png" alt="image-20220813174357802" style="zoom:50%;" />

系统根据商品id，先从布隆过滤器中查询该id是否存在，如果存在则允许从缓存中查询数据，如果不存在，则直接返回失败。

虽说该方案可以解决缓存穿透问题，但是又会引出另外一个问题：布隆过滤器中的数据如何更缓存中的数据保持一致？

这就要求，如果缓存中数据有更新，则要及时同步到布隆过滤器中。如果数据同步失败了，还需要增加重试机制，而且跨数据源，能保证数据的实时一致性吗？

显然是不行的。

所以布隆过滤器绝大部分使用在缓存数据更新很少的场景中。

如果缓存数据更新非常频繁，又该如何处理呢？

这时，就需要把不存在的商品id也缓存起来。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131744219.png" alt="image-20220813174415131" style="zoom: 50%;" />

下次，再有该商品id的请求过来，则也能从缓存中查到数据，只不过该数据比较特殊，表示商品不存在。需要特别注意的是，这种特殊缓存设置的超时时间应该尽量短一点。

## 6 库存问题

对于库存问题看似简单，实则里面还是有些东西。

真正的秒杀商品的场景，不是说扣完库存，就完事了，如果用户在一段时间内，还没完成支付，扣减的库存是要加回去的。

所以，在这里引出了一个`预扣库存`的概念，预扣库存的主要流程如下：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131745360.png" alt="image-20220813174519260" style="zoom:50%;" />

扣减库存中除了上面说到的`预扣库存`和`回退库存`之外，还需要特别注意的是库存不足和库存超卖问题。

### 6.1 数据库扣减库存

使用数据库扣减库存，是最简单的实现方案了，假设扣减库存的sql如下：

```sql
update product set stock=stock-1 where id=123;
```

这种写法对于扣减库存是没有问题的，但如何控制库存不足的情况下，不让用户操作呢？

这就需要在update之前，先查一下库存是否足够了。

伪代码如下：

```java
int stock = mapper.getStockById(123);
if(stock > 0) {
  int count = mapper.updateStock(123);
  if(count > 0) {
    addOrder(123);
  }
}
```

大家有没有发现这段代码的问题？

没错，查询操作和更新操作不是原子性的，会导致在并发的场景下，出现库存超卖的情况。

有人可能会说，这样好办，加把锁，不就搞定了，比如使用synchronized关键字。

确实，可以，但是性能不够好。

还有更优雅的处理方案，即基于数据库的乐观锁，这样会少一次数据库查询，而且能够天然的保证数据操作的原子性。

只需将上面的sql稍微调整一下：

```sql
update product set stock=stock-1 where id=product and stock > 0;
```

在sql最后加上：`stock > 0`，就能保证不会出现超卖的情况。

但需要频繁访问数据库，我们都知道数据库连接是非常昂贵的资源。在高并发的场景下，可能会造成系统雪崩。而且，容易出现多个请求，同时竞争行锁的情况，造成相互等待，从而出现死锁的问题。

### 6.2 redis扣减库存

redis的`incr`方法是原子性的，可以用该方法扣减库存。伪代码如下：

```java
 boolean exist = redisClient.query(productId,userId);
  if(exist) {
    return -1;
  }
  int stock = redisClient.queryStock(productId);
  if(stock <=0) {
    return 0;
  }
  redisClient.incrby(productId, -1);
  redisClient.add(productId,userId);
return 1;
```

代码流程如下：

1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。
2. 查询库存，如果库存小于等于0，则直接返回0，表示库存不足。
3. 如果库存充足，则扣减库存，然后将本次秒杀记录保存起来。然后返回1，表示成功。

估计很多小伙伴，一开始都会按这样的思路写代码。但如果仔细想想会发现，这段代码有问题。

有什么问题呢？

如果在高并发下，有多个请求同时查询库存，当时都大于0。由于查询库存和更新库存非原则操作，则会出现库存为负数的情况，即`库存超卖`。

当然有人可能会说，加个`synchronized`不就解决问题？

调整后代码如下：

```java
   boolean exist = redisClient.query(productId,userId);
   if(exist) {
    return -1;
   }
   synchronized(this) {
       int stock = redisClient.queryStock(productId);
       if(stock <=0) {
         return 0;
       }
       redisClient.incrby(productId, -1);
       redisClient.add(productId,userId);
   }

return 1;
```

加`synchronized`确实能解决库存为负数问题，但是这样会导致接口性能急剧下降，每次查询都需要竞争同一把锁，显然不太合理。

为了解决上面的问题，代码优化如下：

```java
boolean exist = redisClient.query(productId,userId);
if(exist) {
  return -1;
}
if(redisClient.incrby(productId, -1)<0) {
  return 0;
}
redisClient.add(productId,userId);
return 1;
```

该代码主要流程如下：

1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。
2. 扣减库存，判断返回值是否小于0，如果小于0，则直接返回0，表示库存不足。
3. 如果扣减库存后，返回值大于或等于0，则将本次秒杀记录保存起来。然后返回1，表示成功。

该方案咋一看，好像没问题。

但如果在高并发场景中，有多个请求同时扣减库存，大多数请求的incrby操作之后，结果都会小于0。

虽说，库存出现负数，不会出现`超卖的问题`。但由于这里是预减库存，如果负数值负的太多的话，后面万一要回退库存时，就会导致库存不准。

那么，有没有更好的方案呢？

### 6.3 lua脚本扣减库存

我们都知道lua脚本，是能够保证原子性的，它跟redis一起配合使用，能够完美解决上面的问题。

lua脚本有段非常经典的代码：

```lua
  StringBuilder lua = new StringBuilder();
  lua.append("if (redis.call('exists', KEYS[1]) == 1) then");
  lua.append("    local stock = tonumber(redis.call('get', KEYS[1]));");
  lua.append("    if (stock == -1) then");
  lua.append("        return 1;");
  lua.append("    end;");
  lua.append("    if (stock > 0) then");
  lua.append("        redis.call('incrby', KEYS[1], -1);");
  lua.append("        return stock;");
  lua.append("    end;");
  lua.append("    return 0;");
  lua.append("end;");
  lua.append("return -1;");
```

该代码的主要流程如下：

1. 先判断商品id是否存在，如果不存在则直接返回。
2. 获取该商品id的库存，判断库存如果是-1，则直接返回，表示不限制库存。
3. 如果库存大于0，则扣减库存。
4. 如果库存等于0，是直接返回，表示库存不足。

## 7 分布式锁

之前我提到过，在秒杀的时候，需要先从缓存中查商品是否存在，如果不存在，则会从数据库中查商品。如果数据库中，则将该商品放入缓存中，然后返回。如果数据库中没有，则直接返回失败。

大家试想一下，如果在高并发下，有大量的请求都去查一个缓存中不存在的商品，这些请求都会直接打到数据库。数据库由于承受不住压力，而直接挂掉。

那么如何解决这个问题呢？

这就需要用redis分布式锁了。

### 7.1 setNx加锁

使用redis的分布式锁，首先想到的是`setNx`命令。

```java
if (jedis.setnx(lockKey, val) == 1) {
   jedis.expire(lockKey, timeout);
}
```

用该命令其实可以加锁，但和后面的设置超时时间是分开的，并非原子操作。

假如加锁成功了，但是设置超时时间失败了，该lockKey就变成永不失效的了。在高并发场景中，该问题会导致非常严重的后果。

那么，有没有保证原子性的加锁命令呢？

### 7.2 set加锁

使用redis的set命令，它可以指定多个参数。

```java
String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
if ("OK".equals(result)) {
    return true;
}
return false;
```

其中：

- lockKey：锁的标识
- requestId：请求id
- NX：只在键不存在时，才对键进行设置操作。
- PX：设置键的过期时间为 millisecond 毫秒。
- expireTime：过期时间

由于该命令只有一步，所以它是原子操作。

### 7.3 释放锁

接下来，有些朋友可能会问：在加锁时，既然已经有了lockKey锁标识，为什么要需要记录requestId呢？

答：requestId是在释放锁的时候用的。

```java
if (jedis.get(lockKey).equals(requestId)) {
    jedis.del(lockKey);
    return true;
}
return false;
```

在释放锁的时候，只能释放自己加的锁，不允许释放别人加的锁。

这里为什么要用requestId，用userId不行吗？

答：如果用userId的话，假设本次请求流程走完了，准备删除锁。此时，巧合锁到了过期时间失效了。而另外一个请求，巧合使用的相同userId加锁，会成功。而本次请求删除锁的时候，删除的其实是别人的锁了。

当然使用lua脚本也能避免该问题：

```java
if redis.call('get', KEYS[1]) == ARGV[1] then 
 return redis.call('del', KEYS[1]) 
else 
  return 0 
end
```

它能保证查询锁是否存在和删除锁是原子操作。

### 7.4 自旋锁

上面的加锁方法看起来好像没有问题，但如果你仔细想想，如果有1万的请求同时去竞争那把锁，可能只有一个请求是成功的，其余的9999个请求都会失败。

在秒杀场景下，会有什么问题？

答：每1万个请求，有1个成功。再1万个请求，有1个成功。如此下去，直到库存不足。这就变成均匀分布的秒杀了，跟我们想象中的不一样。

如何解决这个问题呢？

答：使用自旋锁。

```java
try {
  Long start = System.currentTimeMillis();
  while(true) {
      String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
     if ("OK".equals(result)) {
        return true;
     }
     
     long time = System.currentTimeMillis() - start;
      if (time>=timeout) {
          return false;
      }
      try {
          Thread.sleep(50);
      } catch (InterruptedException e) {
          e.printStackTrace();
      }
  }
 
} finally{
    unlock(lockKey,requestId);
}  
return false;
```

在规定的时间，比如500毫秒内，自旋不断尝试加锁，如果成功则直接返回。如果失败，则休眠50毫秒，再发起新一轮的尝试。如果到了超时时间，还未加锁成功，则直接返回失败。

### 7.5 redisson

除了上面的问题之外，使用redis分布式锁，还有锁竞争问题、续期问题、锁重入问题、多个redis实例加锁问题等。

这些问题使用redisson可以解决，由于篇幅的原因，在这里先保留一点悬念，有疑问的私聊给我。后面会出一个专题介绍分布式锁，敬请期待。

## 8 mq异步处理

我们都知道在真实的秒杀场景中，有三个核心流程：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131748885.png" alt="image-20220813174806814" style="zoom:67%;" />

而这三个核心流程中，真正并发量大的是秒杀功能，下单和支付功能实际并发量很小。所以，我们在设计秒杀系统时，有必要把下单和支付功能从秒杀的主流程中拆分出来，特别是下单功能要做成mq异步处理的。而支付功能，比如支付宝支付，是业务场景本身保证的异步。

于是，秒杀后下单的流程变成如下：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131748273.png" alt="image-20220813174821205" style="zoom:67%;" />

如果使用mq，需要关注以下几个问题：

### 8.1 消息丢失问题

秒杀成功了，往mq发送下单消息的时候，有可能会失败。原因有很多，比如：网络问题、broker挂了、mq服务端磁盘问题等。这些情况，都可能会造成消息丢失。

那么，如何防止消息丢失呢？

答：加一张消息发送表。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131748744.png" alt="image-20220813174838641" style="zoom:67%;" />

在生产者发送mq消息之前，先把该条消息写入消息发送表，初始状态是待处理，然后再发送mq消息。消费者消费消息时，处理完业务逻辑之后，再回调生产者的一个接口，修改消息状态为已处理。

如果生产者把消息写入消息发送表之后，再发送mq消息到mq服务端的过程中失败了，造成了消息丢失。

这时候，要如何处理呢？

答：使用job，增加重试机制。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131748163.png" alt="image-20220813174855099" style="zoom:67%;" />

用job每隔一段时间去查询消息发送表中状态为待处理的数据，然后重新发送mq消息。

### 8.2 重复消费问题

本来消费者消费消息时，在ack应答的时候，如果网络超时，本身就可能会消费重复的消息。但由于消息发送者增加了重试机制，会导致消费者重复消息的概率增大。

那么，如何解决重复消息问题呢？

答：加一张消息处理表。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131749083.png" alt="image-20220813174910979" style="zoom:50%;" />

消费者读到消息之后，先判断一下消息处理表，是否存在该消息，如果存在，表示是重复消费，则直接返回。如果不存在，则进行下单操作，接着将该消息写入消息处理表中，再返回。

有个比较关键的点是：下单和写消息处理表，要放在同一个事务中，保证原子操作。

### 8.3 垃圾消息问题

这套方案表面上看起来没有问题，但如果出现了消息消费失败的情况。比如：由于某些原因，消息消费者下单一直失败，一直不能回调状态变更接口，这样job会不停的重试发消息。最后，会产生大量的垃圾消息。

那么，如何解决这个问题呢？

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131749018.png" alt="image-20220813174937944" style="zoom:67%;" />

每次在job重试时，需要先判断一下消息发送表中该消息的发送次数是否达到最大限制，如果达到了，则直接返回。如果没有达到，则将次数加1，然后发送消息。

这样如果出现异常，只会产生少量的垃圾消息，不会影响到正常的业务。

### 8.4 延迟消费问题

通常情况下，如果用户秒杀成功了，下单之后，在15分钟之内还未完成支付的话，该订单会被自动取消，回退库存。

那么，在15分钟内未完成支付，订单被自动取消的功能，要如何实现呢？

我们首先想到的可能是job，因为它比较简单。

但job有个问题，需要每隔一段时间处理一次，实时性不太好。

还有更好的方案？

答：使用延迟队列。

我们都知道rocketmq，自带了延迟队列的功能。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131749999.png" alt="image-20220813174955916" style="zoom:67%;" />

下单时消息生产者会先生成订单，此时状态为待支付，然后会向延迟队列中发一条消息。达到了延迟时间，消息消费者读取消息之后，会查询该订单的状态是否为待支付。如果是待支付状态，则会更新订单状态为取消状态。如果不是待支付状态，说明该订单已经支付过了，则直接返回。

还有个关键点，用户完成支付之后，会修改订单状态为已支付。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131750249.png" alt="image-20220813175013172" style="zoom:50%;" />

## 9 如何限流？

通过秒杀活动，如果我们运气爆棚，可能会用非常低的价格买到不错的商品（这种概率堪比买福利彩票中大奖）。

但有些高手，并不会像我们一样老老实实，通过秒杀页面点击秒杀按钮，抢购商品。他们可能在自己的服务器上，模拟正常用户登录系统，跳过秒杀页面，直接调用秒杀接口。

如果是我们手动操作，一般情况下，一秒钟只能点击一次秒杀按钮。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131750731.png" alt="image-20220813175040615" style="zoom:67%;" />

但是如果是服务器，一秒钟可以请求成上千接口。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131750379.png" alt="image-20220813175055277" style="zoom:50%;" />

这种差距实在太明显了，如果不做任何限制，绝大部分商品可能是被机器抢到，而非正常的用户，有点不太公平。

所以，我们有必要识别这些非法请求，做一些限制。那么，我们该如何现在这些非法请求呢？

目前有两种常用的限流方式：

1. 基于nginx限流
2. 基于redis限流

### 9.1 对同一用户限流

为了防止某个用户，请求接口次数过于频繁，可以只针对该用户做限制。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131751018.png" alt="image-20220813175126918" style="zoom:50%;" />

限制同一个用户id，比如每分钟只能请求5次接口。

### 9.2 对同一ip限流

有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这种nginx就没法识别了。

这时需要加同一ip限流功能。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131751408.png" alt="image-20220813175144310" style="zoom:50%;" />

限制同一个ip，比如每分钟只能请求5次接口。

但这种限流方式可能会有误杀的情况，比如同一个公司或网吧的出口ip是相同的，如果里面有多个正常用户同时发起请求，有些用户可能会被限制住。

### 9.3 对接口限流

别以为限制了用户和ip就万事大吉，有些高手甚至可以使用代理，每次都请求都换一个ip。

这时可以限制请求的接口总次数。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131755978.png" alt="image-20220813175520877" style="zoom:50%;" />

在高并发场景下，这种限制对于系统的稳定性是非常有必要的。但可能由于有些非法请求次数太多，达到了该接口的请求上限，而影响其他的正常用户访问该接口。看起来有点得不偿失。

### 9.4 加验证码

相对于上面三种方式，加验证码的方式可能更精准一些，同样能限制用户的访问频次，但好处是不会存在误杀的情况。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.8.30/202208131755175.png" alt="image-20220813175543071" style="zoom:50%;" />

通常情况下，用户在请求之前，需要先输入验证码。用户发起请求之后，服务端会去校验该验证码是否正确。只有正确才允许进行下一步操作，否则直接返回，并且提示验证码错误。

此外，验证码一般是一次性的，同一个验证码只允许使用一次，不允许重复使用。

普通验证码，由于生成的数字或者图案比较简单，可能会被破解。优点是生成速度比较快，缺点是有安全隐患。

还有一个验证码叫做：`移动滑块`，它生成速度比较慢，但比较安全，是目前各大互联网公司的首选。

### 9.5 提高业务门槛

上面说的加验证码虽然可以限制非法用户请求，但是有些影响用户体验。用户点击秒杀按钮前，还要先输入验证码，流程显得有点繁琐，秒杀功能的流程不是应该越简单越好吗？

其实，有时候达到某个目的，不一定非要通过技术手段，通过业务手段也一样。

12306刚开始的时候，全国人民都在同一时刻抢火车票，由于并发量太大，系统经常挂。后来，重构优化之后，将购买周期放长了，可以提前20天购买火车票，并且可以在9点、10、11点、12点等整点购买火车票。调整业务之后（当然技术也有很多调整），将之前集中的请求，分散开了，一下子降低了用户并发量。

回到这里，我们通过提高业务门槛，比如只有会员才能参与秒杀活动，普通注册用户没有权限。或者，只有等级到达3级以上的普通用户，才有资格参加该活动。

这样简单的提高一点门槛，即使是黄牛党也束手无策，他们总不可能为了参加一次秒杀活动，还另外花钱充值会员吧？



# 图解 | 聊聊「秒杀」

## 需求分析

> “秒杀”这个词在电商行业中出现的频率较高，如京东或者淘宝平台的各种“秒杀”活动，最典型的就是“双11抢购”。

> “秒杀”是指在有限的时间内对有限的商品数量进行抢购的一种行为，这是商家以“低价量少”的商品来获取用户的一种营销手段。 

### 1 功能性需求

其实，整个秒杀的业务场景并不复杂，可即查看参与秒杀的商品信息，加上购买和支付的动作，如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171102561.png" alt="image-20221217110208464" style="zoom:50%;" />

### 2 最大挑战

**秒杀业务最大的挑战在于3点：**

> - **瞬时：**持续时间极短，对于热门且具备极强竞争力的商品通常只有一秒。
> - **流量巨大：**因为价格低廉，商品性价比高，而且正常买是需要很高的价格，所以才会吸引大量的用户来争抢。
> - **数量有限：**因为商品的低价且性价比高，所以只有很有限的商品数量参与秒杀。

同时，在保证高并发流量承接的前提下，为了增强用户的体验和活动规则的公平性，以及防止遭到恶意破坏等，特此增加如下需求：

> （1）用户在秒杀页面无需一直刷新“抢购”按钮，待秒杀活动开始时，按钮自动点亮。
>
> （2）在公平以及防止恶意破坏的原则下，在下单之前增加验证码的录入，或者答题的相关环节。
>
> （3）库存不能出现问题，即不多扣也不少扣。
>
> （4）整个秒杀活动过程持续10分钟。

### 性能指标预估

通过秒杀的需求描述可得出，当前秒杀活动主要需要预估三块的性能指标：存储容量、并发量、网络带宽。

#### 1 存储容量

> 由于是秒杀活动，且参与的商品基本都是低价高性价比的，数量是非常有限的。所以，在订单存储上基本不用去过多考虑。

#### 2 并发量

> 针对5000万用户平均每人访问2次，则并发量为每秒16.7万左右（5000w*2/10*60）,在预留一部分，可以预估到每秒25万左右（也可以进行double下）。

#### 3 网络带宽

> 在带宽方面，需要进行相关优化，采取数据传输越少越好，假设单条传输在0.5KB，则根据并发量预估网络带宽为：977Mb左右（25w*0.5KB=122MB*8bit=977Mb）。

### 非功能性需求

做任何系统都要考虑非功能性需求，特别是公司的核心系统，**当前秒杀业务系统非功能性需求主要体现在如下几点：**

> - **高可用**，在秒杀活动的整个持续期间内，都能对用户提供服务。
> - **高性能**，让每个用户都能感受到极快的秒杀响应，不能出现大批量用户延迟较高的现象。
> - **可扩展**，当流量比预期更高时，有平滑扩展的策略（也有部分产品设计成友好的拒绝策略）。



## 概要设计

通过对秒杀业务的本身认知以及上面提到的秒杀业务需求，**本次秒杀系统需要着重设计如下几点：**

> 动静分离：如何保证用户在不刷新页面的情况下，依然能进行秒杀相关数据的获取且不会耽误秒杀活动的开始。
>
> 流量分层，针对巨大流量，如何进行有效的防控，以免造成后台服务的不堪重负，以及如何避免前端页面的卡死。
>
> 高可用：如何确保后台持续提供服务。
>
> 扣减库存：如何有效扣减库存。

### 1 动静分离

> 动静分离是指，将静态页面与动态页面（或者静态数据与动态数据）解耦分离，用不同系统承载对应流量。这样可以提升整个服务访问性能和可维护性。

> 商品秒杀页面的静态数据以及动态数据，均是不同的地方提供，如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171110524.png" alt="image-20221217111028461" style="zoom:80%;" /> 

静态数据是指，页面中几乎不怎么变化的数据（即不依据用户的Cookie、基本信息、地域，及时间等各种属性来生成的数据），例如：

> - CSS和JavaScript中的静态文件。
> - 活动页中的HTML静态文件。
> - 图片等相关资源文件。
> - 其他与用户信息无关的静态数据。

> 对于这种分离出来的静态数据可以进行缓存。在缓存之后，这些静态数据的访问效率就提高了，系统也更快了。可以使用代理服务器进行静态数据的缓存。

> 动态数据是指，依据当前用户属性动态生成的数据，在浏览淘宝首页时，每个用户所看到的商品都是不一样的，这就是淘宝的“千人千面”——针对不同用户做不同的推荐；在百度搜索中是依据不同用户的输入条件，以及用户的习惯给出不同的结果页。这其中的数据就是动态数据。

### 2 流量分层

> 在“秒杀”业务中，商品价格具有强大的吸引力，所以会受到很多用户的关注，但是商品数量是有限的。所以，在千万的用户中可能只有100人能得到商品，对于系统来说，有90%以上的流量属于无效流量。

> “秒杀”业务希望有大量的用户来关注“秒杀”活动，但是在用户真正下单时又不能将这些流量全部放过，所以，需要设计一套高效的流量管控方案，来有效地控制请求流量，过滤掉没必要的流量。

> 对于瞬时流量洪峰可以采用倒三角的分层级逐层控制方式，共分为CDN、反向代理（Nginx）、后端服务及DB这四个层级。接下来，就来看看每一层级是怎么控制流量的，如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171126130.png" alt="image-20221217112613050" style="zoom:50%;" />

### 3 高可用

> 要想在整个“秒杀”活动持续期间内，依然能对用户提供良好的体验，则秒杀系统架构在设计时不能设计成单节点的架构。

> 单节点是所有系统设计中的大忌，因为单节点系统意味着系统的不稳定性较高，可能会出现不可用的情况，会给企业带来直接的损失。在系统设计（特别是“秒杀”这类对高并发要求极高的系统）时，必须保证系统的高可用，如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171126326.png" alt="image-20221217112650248" style="zoom:50%;" />



### 4 扣减库存

> 对于“秒杀”活动，通常，公司是不允许商品超卖（即下单成功的数量不能大于商品存存数量）的。一旦超卖，则会给公司造成损失。如果被恶意流量利用，则损失是巨大的。

> 库存对于电商平台来说是一个重要的业务指标，所以在技术上需要合理设计扣减库存，不能出现“超卖”现象。通常，扣减库存常有以下3种方式：

> - 下单扣库存：在用户下单后就扣减库存。
> - 支付扣库存：用户付完款后再扣减库存。
> - 预扣库存：在用户下完订单后，系统会为其锁定库存一段时间，在超过锁定时间后会自动释放锁定的库存。

### 5 系统架构设计⭐

根据上面讨论，针对当前秒杀架构如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171131491.png" alt="image-20221217113058922" style="zoom:50%;" />



**如上架构比较简洁，主要分为以下5层。**

> - 用户层：用户端的展现部分，主要涉及商品的相关信息及当前“秒杀”活动的信息。
> - CDN层：缓存“秒杀”活动的静态资源文件。
> - 负载均衡层：拦截请求及分发路由等。
> - 服务层：“秒杀”活动的具体交易的相关逻辑处理。
> - 基础设施层：数据存储、大数据计算及消息推送相关操作。

其部署架构图如下：

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171132519.png" alt="image-20221217113243446" style="zoom:80%;" />

## 详细设计

### 1 动静分离设计

实施动静分离架构可以采用“分而治之”的办法，即将动态数据和静态数据解耦，分别使用各自的架构系统来承载对应的流量：

> - 对于静态数据，推荐缩短用户请求路径，因为路径越短，访问速度也就越快。另外，即尽可能将静态数据缓存起来。
> - 对于动态数据，一般用户端需要和服务端进行交互才能获取，所以，请求路径较长，访问速度会慢一点。下图展示了动静分离方案。

> 静态数据访问速度很快，而动态数据访问速度较慢。那么试想下，可以将需要动态获取的数据给提前生成好，然后使用静态页面加速技术来访问吗？如果这样可以，那动态数据访问的速度就变快了。

> 这样是可以的，需要用到比较流行的“页面静态化”技术。页面静态化技术是指，直接缓存HTTP连接，而不仅是缓存数据。如下图所示，代理服务器根据请求的URL直接将HTTP对应的响应头及响应消息体返回，流程简洁且高效。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171114079.png" alt="image-20221217111442005" style="zoom:67%;" />

### 2 流量分层设计

> 流量分层主要体现在对于CDN层、反向代理层、后端服务层以及数据层流量进行控制。

#### 1 CDN层流量控制

由动静分离技术可以想到：应尽量将尽可能多的数据提前生成，然后将其放入CDN节点缓存中（因为CDN层在物理架构上离用户比较近）。

所以，如果绝大部分的流量都在这一层获取数据，则到达后端的流量会减少很多，如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171136462.png" alt="image-20221217113630407" style="zoom:50%;" />

#### 2 反向代理层流量控制

在动静分离方案中，讲到通过“页面静态化技术”加速动态数据的获取，即提前将动态数据生成好，然后对其进行静态化处理。

所以，这里就可以依据页面静态化加速技术，通过后端服务Job的方式定时提前生成前端需要静态的数据；然后，将其发送到内容分发服务上；最后，分发服务会将这些静态化页面数据分发到所有的反向代理服务器上，如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171136970.png" alt="image-20221217113608918" style="zoom:80%;" />

在“秒杀”业务中，活动详情页上有一个倒计时的模块，用户可以看到当前“秒杀”活动还剩余多少时间开始。

这种逻辑简单的功能可以直接使用Nginx来实现：利用nginx-lua插件，使用lua脚本获取当前Nginx服务器的时间进行计算倒计时。另外，商品库存数据也可以通过Nginx直接访问分布式缓存来获取，如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171135474.png" alt="image-20221217113550414" style="zoom:80%;" />

“秒杀”业务中的商品价格很低，对于用户有很大的吸引力，所以可能会有人利用“秒杀器”进行不公平竞争，且有可能存在竞争对手恶意刷请求的情况。

如果存在这样的情况，那本次活动就是有风险的，万一被恶意流量独占了库存，则会导致正常用户不能抢购商品，也有可能这种恶意的请求会对后端系统造成严重冲击，甚至造成后端系统瘫痪。

对于这种恶意请求，最好有一套机制能提前感知，并将恶意请求提前封存。可以在Nginx层中控制；也可以在Nginx中配置用户的访问频率（例如每分钟只能访问10次）；还可以使用Lua脚本编写一些简单业务逻辑的接口，例如，通过调用接口直接封掉指定IP地址或UserAgent的请求。

#### 3 后端服务层流量控制

对于服务层的流量控制，有以下几点建议：

> - 在程序开发上，代码独立，不要与平台其他项目一起。
> - 在部署时，应用独立部署，分散流量，避免不合适的流量影响主体业务。
> - 使用独立域名，或者按照一定的URL规则在反向代理层进行路由。
> - 做好系统保护和限流，进一步减少不必要的流量。

> 当“到达系统中的请求数”明显大于“系统能够处理的最大请求数”时，可以直接拒绝这些多余的请求，直接返回“秒杀”活动结束的信息。例如，活动开始时的商品库存是100，目前库存只剩50了，如果“每台服务器待处理的请求数”已经超过“商品总库存数（100）”了，则可以直接终止掉多余的请求。

#### 4 数据库层流量控制

对于请求到数据中的流量，写入的流量就是真正下单成功的流量，即需要扣减库存的动作。有如下建议：

> - 如果不是临时的活动，则建议使用独立的数据库作为“秒杀”活动的数据库。
> - 将数据库配置成读写分离。
> - 尝试去除行锁。

对于数据库行锁的优化，可以通过将商品进行拆分来实现——增加ID，如下图所示。对于单一的“秒杀”活动这会得到显著效果。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171134217.png" alt="image-20221217113453143" style="zoom: 50%;" />

从流量分层控制方案可看出，瞬时流量就像被漏斗过滤了似的，应尽量将数据和请求量一层一层地过滤掉。这种流量分层控制核心思想：在不同的层级中尽可能地过滤掉无效的请求，到达“倒三角”最末端的请求才是有效的请求。

#### 5 高可用

> 在系统设计时想要做到高可用，避免单节点的一个小妙招：将服务无状态化。如果无法完全无状态化（如存储系统），则可以通过冗余多个备份节点的方案来避免单节点。

> 由于篇幅原因，高可用此处就不再赘述，大家可以查看**《高并发系统实战派》**一书里面针对高并发系统的真实设计案例，毫无保留的分享出了企业级高并发系统实战。

### 3 扣减库存设计

> 由于在“秒杀”场景中商品一般优惠力度很大，对用户很具有吸引力，所以，在这种场景中使用“下单扣库存”方式更为合适。

> 在“秒杀”场景中，大部分用户抱着“抢到就是赚到”的想法，基本都会去付款的，但如果真有竞争对手恶意下单不付款，那我们该怎么办？前面在流量管控中已经说到，可以对请求日志进行实时分析，让风控系统选择出恶意用户，然后将其封停。

> 在“秒杀”场景中，通过流量分层控制可以分层管控大量的“读”请求。但是，依然会有很大的流量进入真正的下单逻辑。对于这么大的流量，除前面说的数据库隔离外，还需要进一步优化库存，否则数据库读/写依然是系统的瓶颈。

接下来看看如何优化大流量“秒杀”场景中的库存数量扣减操作。

#### 1 利用缓存技术

> 在“秒杀”场景中，如果只是一个扣减库存数量这样的简单流程，则可以先将库存数量直接放在缓存中，然后用分布式缓存（如Redis）的超高性能去应对这种瞬时流量洪峰下的系统挑战。

> 使用缓存是存在一定风险的，比如，缓存节点出现了异常，那库存数量该怎么算？

> 使用缓存，不仅要考虑分布式缓存高可用（如何设计可以查看我的新书“高并发系统实战派”），还要考虑各种限流容错机制，以确保分布式缓存对外提供服务。

#### 2 异步处理技术

> 如果是复杂的扣减库存（如涉及商品信息本身或牵连其他系统），则建议使用数据库进行库存数量的扣减，可以使用异步的方式来应对这种高并发的库存的更新。

> ①在用户下单时，不立刻生成订单，而是将所有订单依次放入队列。
>
> ②下单模块依据自身的处理速度，从队列中依次获取订单进行“下单扣库存”操作。
>
> ③在订单生成成功后，用户即可进行支付操作了。

> 这种方式是针对“秒杀”场景的，依据“先到先得”原则来保证公平公正，所有用户都可以抢购，然后等待订单处理，最后生成订单（如果库存不足，则生成订单失败）。

这样的逻辑，对用户来说体验不是很差。具体排队逻辑如下图所示。

<img src="https://edu-8673.oss-cn-beijing.aliyuncs.com/img2022.12.30/202212171124698.png" alt="image-20221217112432646" style="zoom:80%;" />



## 搭建千万级流量秒杀系统需要哪些技术

前面介绍了千万级流量“秒杀”系统的基本架构、“秒杀”系统的设计原则、如何做动静分离方案和流量控制，以及扣减库存方面内容。这些都是设计高并发“秒杀”系统必须要考虑的。 

“秒杀”系统的流程并不复杂——只是一个“下单扣库存”的动作，但由于其独特的业务特点，所以在进行系统设计时不能大意。对于瞬时流量洪峰的高并发“秒杀”系统，我们需要什么技术呢？下面来总结一下。

### 1 数据的静态化的技术

> 用来应对高并发读的请求，主要涉及以下内容，这些在**《高并发系统实战派》**一书中详细分享了真实使用场景已经技术方案：各层级缓存的处理（即多级缓存的技术）  分布式缓存技术

### 2 负载均衡反向代理技术

> - LVS
> - Nginx

### 3 异步处理技术

> - 消息队列技术
> - 排队系统技术

### 4 系统架构设计技术

> - 系统模块化划分
> - 微服务架构思想

### 5 系统监控技术

> - 日志监控
> - 服务监控



# 如何设计秒杀系统

秒杀系统的设计是高级职位面试中非常高频的一道题目，它可以较好地考察候选人的知识体系情况。对于我们来说，学习秒杀系统的设计，能够让我们学以致用，设计系统的时候考虑得更加全面。今天就带你一起来看看怎么设计一个秒杀系统！

<img src="https://mmbiz.qpic.cn/mmbiz_png/AVWicyZuuClH38oJYSMwnsM8LtcCsMfyEHIWJ15LgIbuduKK6oBZRIpuOpb9EeRLgNb0AfAeIiauJG2via5eCkOwA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

> 活动一般出现在电商的促销活动中，一般是指定了很少数量的商品，以极低的价格，让大量的用户参与，从而造成大量用户在极短的时间内参与活动，进而造成系统在极短的时间内有极高的流量。系统设计的目的是使系统能够稳定地支撑活动的进行，因此其稳定性、高可用是我们考虑的第一位。

> 要知道如何进行秒杀系统的优化，那我们需要先对请求的整个流程有个全局的认识。**一般来说，秒杀活动请求以公网为划分点，可以分为：前端部分、后端部分。** 前端部分指的是从用户端到进入后端服务前的部分，包括了移动端的处理、DNS 解析、公网的数据传递等。

> 后端部分指的是经公网进入了后端的服务器网络里，包括了前置的负载均衡（Nginx 等）、应用服务器、数据库层等。秒杀活动的整个流程可以用下图来表示。

![图片](https://mmbiz.qpic.cn/mmbiz_png/AVWicyZuuClH38oJYSMwnsM8LtcCsMfyET1k58MJzSHdYtoXMOq12ib8ice3vPJC2WauMTa8oicOSrGxpQTQ5FibbRg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)the-process-of-network-request

> 我们要去设计一个秒杀系统，那自然也是从这两大部分来进行优化。整体思路是尽量将流量挡在前面，让尽量少的流量留到后端部分。因为越往后端，我们的处理逻辑就越重，其处理能力也越弱。

## 前端优化

对于前端部分来说，常见的优化手段有：页面静态化 + CDN、请求频率限制。

### 页面静态化 + CDN

> 一般来说，活动页面是流量最大的地方。活动页面上绝大部分内容都是固定的，比如：商品描述、图片等。这时候没有必要每次都去请求服务端，而是将这些静态的内容放到 CDN 上。

每次打开页面的时候，直接去请求 CDN 服务器，能极大地减少后端的请求流量。加入了 CDN 之后，其请求过程如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/AVWicyZuuClH38oJYSMwnsM8LtcCsMfyEITjRtrb2qOnBxKCDutyxLibeG2YjtC71IuzF2mZpPhbuDtWSyWgqKJQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

CDN 优化静态数据

> 所谓的 CDN 就是内容分发网络，它由非常多台分布在世界各地的缓存服务器组成。每次用户请求特定域名的时候，会转发到对应 CDN 的 DNS 解析服务器，随后会返回一台离用户地理位置最近的一台 CDN 服务器。随后，用户直接请求这台 CDN 服务器获取数据，从而极大地减少了长途网络传输的时间，并且也减少了后端服务器的压力。

> **因此，对于秒杀活动设计来说，我们可以将所有可以静态化的内容全部静态化，然后将其配置在 CDN 服务器上。这样既提高了用户打开页面的时间，又减少了后端服务器的压力。**

### 请求频率限制

请求频率限制，指的是根据业务的特点，在前端做一些流量拦截，减少后端服务器的压力。常见的拦截方式有：

> 1. 设定一个请求概率，只允许 30% 的概率向后端发送接口请求。
> 2. 设定一个请求频率，例如 10 秒钟只能请求 1 次，随后按钮置灰。

> 通过这种方式，我们可以减少很大一部分流量。但在具体实现的时候，可能需要考虑安全问题，预防某些用户直接调用后台接口，绕过前端的频率检查。

> 常见的方法是在频率检查时生成一个参数，随后请求后端服务时携带上该参数。没有该参数的请求，都视为非法请求，直接拒绝该请求。

## 后端优化

无论我们做多大的努力，始终还是会有不少流量会来到后端服务器这里。一般来说，后端的优化有如下几种方式：

> 1. 增加缓存层 + 预热数据
> 2. MQ 异步处理
> 3. 限流、熔断、兜底
> 4. 业务侧优化

### 增加缓存层 + 预热数据

> 如果我们所有数据都去读取数据库，数据库可能无法承受较大的流量，此时一个常见的优化就是增加缓存层。

> 当我们需要查询数据库之前，我们先去查询缓存，这样可以减少绝大部分的数据库请求，减轻数据库压力。如果在缓存中找不到数据，我们再去请求数据库，随后再将数据缓存到缓存中。

> 在引入缓存层的时候，我们需要考虑缓存击穿、缓存穿透的可能性，在写相关代码的时候就要做好这些优化。另外，我们在秒杀活动开始之前，可以手动将热点数据加载到缓存中，从而避免秒杀时去请求数据库。

### MQ 异步处理

> 我们知道秒杀活动一般涉及抢购、下单、支付、发货等阶段，而抢购与后续的几个阶段是可以异步执行的。为了避免对下单、支付、发货等阶段产生影响，我们可以将抢购阶段与后续阶段用 MQ 进行解耦处理。当用户抢购成功后，往消息队列中丢入一台消息，随后再由订单系统消费进行下单处理。

> 通过各系统之间的解耦处理，我们可以将原本同步的处理方式变为异步处理，从而大大的减少了请求的处理时间，提高了系统的并发处理能力。其次，也能避免系统之间相互影响，提高了整体系统的稳定性。

### 限流、熔断、降级

> 虽然我们做了非常多的优化措施，但还是可能存在请求超量的可能性，那怎么办呢？

> 我们可以在每个业务系统做限流操作，从而避免因为请求太多，导致整个系统都无法工作。当并发请求在正常范围内时，我们正常处理请求。当超过设置的限流阈值时，我们则直接拒绝该请求，提示用户抢购失败。

> 如果没有限流操作，那么系统直接崩溃了，一个请求都处理不了。而通过限流这种方式，系统至少还可以保持正常工作，而不至于一个请求都处理不了。而超量的需求，本来就处理不了，因此提示失败也是情理之中。

除了限流之外，不同的系统还可以采用熔断、降级的服务治理措施。

> 熔断指的是请求的错误次数超过阈值时，不再到用后端服务，直接返回失败。同时每隔一定时间放几个请求去重试后端服务，看看是否正常。如果正常则关闭熔断状态，如果失败则继续快速失败。**熔断的目的是避免因下游短暂的异常，导致上游不断重试，最终造成下游有太多请求，最终压垮下游系统。**

> 降级指的是当服务失败或异常后，返回指定的默认信息。**降级的目的是保证有基本的信息，当下游异常时，与其返回空信息，不如返回一个有业务含义的默认信息，可以提高用户体验。**

### 业务侧优化

> 一般来说，经过上述的整体优化之后，系统已经能够比较稳当地应对秒杀活动了。如果此时还是流量比较大，那么或许应该从业务侧去进行优化了。

> 例如 12306 刚开始的时候，购买时间都在同一时刻，这导致同一时刻并发量太大，系统经常支撑不住。后来 12306 将购票周期放长，可以提前 20 天购买火车票。通过业务侧的优化，我们将本来在 1 个小时的抢购分摊到了 20 天，服务器压力一下子降低了 480 倍！

> **张小龙也说过：如果公司最厉害的程序员来实现业务都觉得复杂，那很可能就是业务确实不合理，这时候应该从业务侧进行优化。**

> 例如一个存储了 10 亿条记录的消息记录表，业务侧既想查询速度快，又想进行 1 年数据范围的数据查询，这无论如何都是无法实现的。这时候就需要从业务需求侧进行优化，否则是无法两全其美的。

> 对于这个场景，一个合理的实现方式是：要实现 1 年数据范围的查询，那么只能根据消息 ID 进行，因为这样可以使用上索引。而要根据时间范围进行查询，只能缩短查询时间到 3 天内，这样也可以满足业务需求。

> **因此从业务侧进行优化，是一个四两拨千斤的办法，可以极大地降低技术侧实现的难度。**

## 秒杀优化总结

设计一个秒杀系统，整体而言可以从前端与后端进行优化。

**对于前端优化而言，可以从「页面静态化 + CDN」、请求频率限制进行优化。**

> 其中「页面静态化 + CDN」指的是将不变的静态数据固定下来，然后放入 CDN 服务器，从而降低用户请求的响应速度，降低服务器的并发压力。请求频率限制，则是通过抢购概率与抢购频率限制，降低后端服务器的服务压力。

**对于后端优化而言，一般有「增加缓存层 + 预热数据」、「MQ 异步处理」、「限流、熔断、降级」、业务侧优化这 4 种优化方式。**

> 其中「增加缓存层 + 预热数据」指的是将热点数据存入缓存，并在活动开始前提前加载到缓存中，降低数据库层的读取压力。「MQ 异步处理」指的是对于非必要的业务逻辑，通过 MQ 进行异步处理，降低请求处理延时，同时提高业务系统整体稳定性。

> 「限流、熔断、降级」是对于整体微服务的保护，其中限流指的是对请求进行限制，当超过限流阈值时，直接拒绝请求，保护系统本身；熔断指的是保护下游系统，当请求下游系统连续错误超过阈值时，自动不去请求下游系统，避免因重试流量过大击垮下游系统。

> 降级指的是当请求失败时，自动返回默认数据，提高用户体验。业务侧优化，则是指从业务层面去进行逻辑优化，从而降低技术复杂度，使得业务与技术复杂度达到一个平衡的状态，有利于更好地实现秒杀系统的高可用与高并发。

> 上面说到的 6 个优化思路，是设计秒杀系统常见的优化思路。**但在实际业务场景中，除了要保障正常的功能设计之外，还还考虑防刷、安全、黑产等问题**，此时可能需要多考虑一些其他优化，例如：黄牛利用抢购工具抢购，导致正常用户无法抢到商品等。

> 这时候可能需要考虑增加验证码，用 App 设备指纹等风控措施。**此外，对于秒杀系统而言，做好业务指标和系统指标的埋点监控也是非常重要的。**

# 我劝你别去阿里了，秒杀都搞不定

最近有读者在询问阿里面试的一些技巧，我随便问了他几个问题，他答得很一般，主要包括海量数据处理、线上问题排查、秒杀系统设计。尤其是秒杀系统设计，他的答案确实让人不敢恭维。



如果连秒杀系统都不会，或者不熟练，那去阿里面试，基本就等同于浪费时间。如果面试不通过，人才库也有不通过的描述，会影响以后的面试。所以，我建议准备充分，珍惜阿里面试机会。



之前讨论过关于秒杀的内容，下面，我们来一起来看看秒杀场景的优化版，欢迎沟通和交流。



## 秒杀业务分析

**正常电子商务流程**

```
（1）查询商品；
（2）创建订单；
（3）扣减库存；
（4）更新订单；
（5）付款；
（6）卖家发货
```

**秒杀业务的特性**

```
（1）低廉价格；
（2）大幅推广；
（3）瞬时售空；
（4）一般是定时上架；
（5）时间短、瞬时并发量高；
```

## 秒杀技术挑战

> 假设某网站秒杀活动只推出一件商品，预计会吸引1万人参加活动，也就说最大并发请求数是10000，秒杀系统需要面对的技术挑战有：

### 对现有网站业务造成冲击

> 秒杀活动只是网站营销的一个附加活动，这个活动具有时间短，并发访问量大的特点，如果和网站原有应用部署在一起，必然会对现有业务造成冲击，稍有不慎可能导致整个网站瘫痪。

> **解决方案**：将秒杀系统独立部署，甚至`使用独立域名，使其与网站完全隔离`。

### 高并发下的应用、数据库负载

> 用户在秒杀开始前，通过不停刷新浏览器页面以保证不会错过秒杀，这些请求如果按照一般的网站应用架构，访问应用服务器、连接数据库，会对应用服务器和数据库服务器造成负载压力。

> **解决方案**：重新设计秒杀商品页面，不使用网站原来的商品详细页面，`页面内容静态化，用户请求不需要经过应用服务`。

### 突然增加的网络及服务器带宽

> 假设商品页面大小200K（主要是商品图片大小），那么需要的网络和服务器带宽是2G（200K×10000），这些网络带宽是因为秒杀活动新增的，超过网站平时使用的带宽。

> **解决方案**：因为秒杀新增的网络带宽，必须和运营商重新购买或者租借。为了减轻网站服务器的压力，**`需要将秒杀商品页面缓存在CDN，同样需要和CDN服务商临时租借新增的出口带宽`**。

### 直接下单

> 秒杀的游戏规则是到了秒杀才能开始对商品下单购买，在此时间点之前，只能浏览商品信息，不能下单。而下单页面也是一个普通的URL，如果得到这个URL，不用等到秒杀开始就可以下单了。

> **解决方案**：为了避免用户直接访问下单页面URL，需要将改URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。是在`下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到`

### 如何控制秒杀商品页面购买按钮的点亮

> 购买按钮只有在秒杀开始的时候才能点亮，在此之前是灰色的。如果该页面是动态生成的，当然可以在服务器端构造响应页面输出，控制该按钮是灰色还 是点亮，但是为了减轻服务器端负载压力，更好地利用CDN、反向代理等性能优化手段，该页面被设计为静态页面，缓存在CDN、反向代理服务器上，甚至用户浏览器上。秒杀开始时，用户刷新页面，请求根本不会到达应用服务器。

> **解决方案**：使用JavaScript脚本控制，`在秒杀商品静态页面中加入一个JavaScript文件引用`，该JavaScript文件中包含 秒杀开始标志为否；当秒杀开始的时候生成一个新的JavaScript文件（文件名保持不变，只是内容不一样），更新秒杀开始标志为是，`加入下单页面的URL及随机数参数（这个随机数只会产生一个，即所有人看到的URL都是同一个，服务器端可以用redis这种分布式缓存服务器来保存随机数）`，并被用户浏览器加载，控制秒杀商品页面的展示。`这个JavaScript文件的加载可以加上随机版本号（例如xx.js?v=32353823），这样就不会被浏览器、CDN和反向代理服务器缓存`。

> 这个JavaScript文件非常小，即使每次浏览器刷新都访问JavaScript文件服务器也不会对服务器集群和网络带宽造成太大压力。

### 如何只允许第一个提交的订单被发送到订单子系统

> 由于最终能够成功秒杀到商品的用户只有一个，因此需要在用户提交订单时，检查是否已经有订单提交。如果已经有订单提交成功，则需要更新 JavaScript文件，更新秒杀开始标志为否，购买按钮变灰。事实上，由于最终能够成功提交订单的用户只有一个，为了减轻下单页面服务器的负载压力， 可以控制进入下单页面的入口，只有少数用户能进入下单页面，其他用户直接进入秒杀结束页面。

> **解决方案**：假设下单服务器集群有10台服务器，每台服务器只接受最多10个下单请求。在还没有人提交订单成功之前，如果一台服务器已经有十单了，而有的一单都没处理，可能出现的用户体验不佳的场景是用户第一次点击购买按钮进入已结束页面，再刷新一下页面，有可能被一单都没有处理的服务器处理，进入了填写订单的页面，`可以考虑通过cookie的方式来应对，符合一致性原则`。当然可以`采用最少连接的负载均衡算法`，出现上述情况的概率大大降低。

### 如何进行下单前置检查

> **下单服务器检查本机已处理的下单请求数目：**如果超过10条，直接返回已结束页面给用户；如果未超过10条，则用户可进入填写订单及确认页面；

> **检查全局已提交订单数目：**已超过秒杀商品总数，返回已结束页面给用户；未超过秒杀商品总数，提交到子订单系统；

### 秒杀一般是定时上架

该功能实现方式很多。不过目前比较好的方式是：提前设定好商品的上架时间，用户可以在前台看到该商品，但是无法点击“立即购买”的按钮。但是需要考虑的是，`有人可以绕过前端的限制，直接通过URL的方式发起购买`，这就需要在前台商品页面，以及bug页面到后端的数据库，都要进行时钟同步。越在后端控制，安全性越高。

定时秒杀的话，就要避免卖家在秒杀前对商品做编辑带来的不可预期的影响。这种特殊的变更需要多方面评估。一般禁止编辑，如需变更，可以走数据订正多的流程。

### 减库存的操作

有两种选择，一种是`拍下减库存` 另外一种是`付款减库存`；目前采用的`“拍下减库存”`的方式，拍下就是一瞬间的事，对用户体验会好些。

### 库存会带来“超卖”的问题：售出数量多于库存数量

由于库存并发更新的问题，导致在实际库存已经不足的情况下，库存依然在减，导致卖家的商品卖得件数超过秒杀的预期。方案：`采用乐观锁`

```
update auction_auctions set
quantity = #inQuantity#
where auction_id = #itemId# and quantity = #dbQuantity#
```

**还有一种方式，会更好些，叫做尝试扣减库存，扣减库存成功才会进行下单逻辑：**

```
update auction_auctions set 
quantity = quantity-#count# 
where auction_id = #itemId# and quantity >= #count# 
```

### 秒杀器的应对

秒杀器一般下单个购买及其迅速，根据购买记录可以甄别出一部分。可以通过校验码达到一定的方法，这就要求校验码足够安全，不被破解，采用的方式有：`秒杀专用验证码，电视公布验证码，秒杀答题`。

## 秒杀架构原则

### 尽量将请求拦截在系统上游

> 传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小【一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0】。

### 读多写少的常用多使用缓存

> 这是一个典型的**`读多写少`**的应用场景【一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%】，**`非常适合使用缓存`**。

## 秒杀架构设计

> 秒杀系统为秒杀而设计，不同于一般的网购行为，参与秒杀活动的用户更关心的是如何能快速刷新商品页面，在秒杀开始的时候抢先进入下单页面，而不是商品详情等用户体验细节，因此秒杀系统的页面设计应尽可能简单。商品页面中的购买按钮只有在秒杀活动开始的时候才变亮，在此之前及秒杀商品卖出后，该按钮都是灰色的，不可以点击。

> 下单表单也尽可能简单，购买数量只能是一个且不可以修改，送货地址和付款方式都使用用户默认设置，没有默认也可以不填，允许等订单提交后修改；只有第一个提交的订单发送给网站的订单子系统，其余用户提交订单后只能看到秒杀结束页面。

> 要做一个这样的秒杀系统，业务会分为两个阶段，**`第一个阶段是秒杀开始前某个时间到秒杀开始`**， 这个阶段可以称之为**`准备阶段`**，用户在准备阶段等待秒杀；**`第二个阶段就是秒杀开始到所有参与秒杀的用户获得秒杀结果`**， 这个就称为**`秒杀阶段`**吧。

### 前端层设计

首先要有一个展示秒杀商品的页面， 在这个页面上做一个秒杀活动开始的倒计时， `在准备阶段内用户会陆续打开这个秒杀的页面， 并且可能不停的刷新页面`。这里需要考虑两个问题：

**第一个是秒杀页面的展示**

我们知道一个html页面还是比较大的，`即使做了压缩，http头和内容的大小也可能高达数十K，加上其他的css， js，图片等资源`，如果同时有几千万人参与一个商品的抢购，一般机房带宽也就只有1G~10G，`网络带宽就极有可能成为瓶颈`，所以这个页面上`各类静态资源首先应分开存放，然后放到cdn节点上分散压力`，由于CDN节点遍布全国各地，能缓冲掉绝大部分的压力，而且还比机房带宽便宜~

**第二个是倒计时**

出于性能原因这个一般由js调用客户端本地时间，就有可能出现客户端时钟与服务器时钟不一致，另外服务器之间也是有可能出现时钟不一致。`客户端与服务器时钟不一致可以采用客户端定时和服务器同步时间`，这里考虑一下性能问题，`用于同步时间的接口由于不涉及到后端逻辑，只需要将当前web服务器的时间发送给客户端就可以了，因此速度很快`，就我以前测试的结果来看，一台标准的web服务器2W+QPS不会有问题，如果100W人同时刷，100W QPS也只需要50台web，一台硬件LB就可以了~，并且web服务器群是可以很容易的横向扩展的(LB+DNS轮询)，这个接口可以只返回一小段json格式的数据，而且可以优化一下减少不必要cookie和其他http头的信息，所以数据量不会很大，`一般来说网络不会成为瓶颈，即使成为瓶颈也可以考虑多机房专线连通，加智能DNS的解决方案`；web服务器之间时间不同步可以采用统一时间服务器的方式，`比如每隔1分钟所有参与秒杀活动的web服务器就与时间服务器做一次时间同步`。

**浏览器层请求拦截**

（1）**产品层面**，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求;

（2）**JS层面**，限制用户在x秒之内只能提交一次请求;

### 站点层设计

前端层的请求拦截，只能拦住小白用户（不过这是99%的用户哟），高端的程序员根本不吃这一套，写个for循环，直接调用你后端的http请求，怎么整？

（1）**`同一个uid，限制访问频度`**，做页面缓存，x秒内到达站点层的请求，均返回同一页面

（2）**`同一个item的查询，例如手机车次`**，做页面缓存，x秒内到达站点层的请求，均返回同一页面

如此限流，又有99%的流量会被拦截在站点层。##4.3 服务层设计## 站点层的请求拦截，只能拦住普通程序员，高级黑客，假设他控制了10w台肉鸡（并且假设买票不需要实名认证），这下uid的限制不行了吧？怎么整？

（1）大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？**`对于写请求，做请求队列，每次只透过有限的写请求去数据层，如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”`**；

（2）**`对于读请求，还用说么？cache来抗`**，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的；

如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。

1. **用户请求分发模块**：使用Nginx或Apache将用户的请求分发到不同的机器上。
2. **用户请求预处理模块**：判断商品是不是还有剩余来决定是不是要处理该请求。
3. **用户请求处理模块**：把通过预处理的请求封装成事务提交给数据库，并返回是否成功。
4. **数据库接口模块**：该模块是数据库的唯一接口，负责与数据库交互，提供RPC接口供查询是否秒杀结束、剩余数量等信息。

**用户请求预处理模块**

经过HTTP服务器的分发后，单个服务器的负载相对低了一些，但总量依然可能很大，如果后台商品已经被秒杀完毕，那么直接给后来的请求返回秒杀失败即可，不必再进一步发送事务了，示例代码可以如下所示：

```java
package seckill;
import org.apache.http.HttpRequest;
/**
 * 预处理阶段，把不必要的请求直接驳回，必要的请求添加到队列中进入下一阶段.
 */
public class PreProcessor {
    // 商品是否还有剩余
    private static boolean reminds = true;
    private static void forbidden() {
        // Do something.
    }
    public static boolean checkReminds() {
        if (reminds) {
            // 远程检测是否还有剩余，该RPC接口应由数据库服务器提供，不必完全严格检查.
            if (!RPC.checkReminds()) {
                reminds = false;
            }
        }
        return reminds;
    }
    /**
     * 每一个HTTP请求都要经过该预处理.
     */
    public static void preProcess(HttpRequest request) {
        if (checkReminds()) {
            // 一个并发的队列
            RequestQueue.queue.add(request);
        } else {
            // 如果已经没有商品了，则直接驳回请求即可.
            forbidden();
        }
    }
}
```

**并发队列的选择**

Java的并发包提供了三个常用的并发队列实现，分别是：ConcurrentLinkedQueue 、 LinkedBlockingQueue 和 ArrayBlockingQueue。

ArrayBlockingQueue是`初始容量固定的阻塞队列`，我们可以用来作为数据库模块成功竞拍的队列，比如有10个商品，那么我们就设定一个10大小的数组队列。

ConcurrentLinkedQueue使用的是`CAS原语无锁队列实现，是一个异步队列`，入队的速度很快，出队进行了加锁，性能稍慢。

LinkedBlockingQueue也是`阻塞的队列，入队和出队都用了加锁`，当队空的时候线程会暂时阻塞。

由于我们的系统`入队需求要远大于出队需求`，一般不会出现队空的情况，所以我们可以选择ConcurrentLinkedQueue来作为我们的请求队列实现：

```
package seckill;
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.ConcurrentLinkedQueue;
import org.apache.http.HttpRequest;
public class RequestQueue {
    public static ConcurrentLinkedQueue<HttpRequest> queue = new ConcurrentLinkedQueue<HttpRequest>();
}
```

- **用户请求模块**

```
package seckill;
import org.apache.http.HttpRequest;
public class Processor {
    /**
     * 发送秒杀事务到数据库队列.
     */
    public static void kill(BidInfo info) {
        DB.bids.add(info);
    }
    public static void process() {
        BidInfo info = new BidInfo(RequestQueue.queue.poll());
        if (info != null) {
            kill(info);
        }
    }
}
class BidInfo {
    BidInfo(HttpRequest request) {
        // Do something.
    }
}
```

- **数据库模块**

数据库主要是使用一个ArrayBlockingQueue来暂存有可能成功的用户请求。

```
package seckill;
import java.util.concurrent.ArrayBlockingQueue;
/**
 * DB应该是数据库的唯一接口.
 */
public class DB {
    public static int count = 10;
    public static ArrayBlockingQueue<BidInfo> bids = new ArrayBlockingQueue<BidInfo>(10);
    public static boolean checkReminds() {
        // TODO
        return true;
    }
    // 单线程操作
    public static void bid() {
        BidInfo info = bids.poll();
        while (count-- > 0) {
            // insert into table Bids values(item_id, user_id, bid_date, other)
            // select count(id) from Bids where item_id = ?
            // 如果数据库商品数量大约总数，则标志秒杀已完成，设置标志位reminds = false.
            info = bids.poll();
        }
    }
}
```

### 数据库设计

#### 基本概念

**概念一“单库”**

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVrPNsq4MHcNGZUo2zLpiaeqQlV7XH28JTTqmNMDlj0fw8HaTB5VjlibIA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**概念二“分片”**

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVnZRdvFflqeJQrCXrzeibLgGpZsDUXkgrSVd9bice3tkqOtHfu8Z4dtLw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`分片解决的是“数据量太大”的问题，也就是通常说的“水平切分”`。一旦引入分片，势必有“数据路由”的概念，哪个数据访问哪个库。路由规则通常有3种方法：

1. **范围：range**

优点：简单，容易扩展

缺点：各库压力不均（新号段更活跃）

1. **哈希：hash 【大部分互联网公司采用的方案二：哈希分库，哈希路由】**

优点：简单，数据均衡，负载均匀

缺点：迁移麻烦（2库扩3库数据要迁移）

1. **路由服务：router-config-server**

优点：灵活性强，业务与路由算法解耦

缺点：每次访问数据库前多一次查询

**概念三“分组”**

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVIYBP7dfeyGBvVN7E0eEgArCQMlM1VUXUEL9PZecJ9iacA6yzkECOAgA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

分组解决“可用性”问题，分组通常通过主从复制的方式实现。

**互联网公司数据库实际软件架构是：又分片，又分组（如下图）**

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVUh6uqG15udicJ02g1cGFscjbwUgicpkSIh99QraSAQnfGvHx1ncj1eCA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 设计思路 

数据库软件架构师平时设计些什么东西呢？至少要考虑以下四点：

1. 如何保证数据可用性；
2. 如何提高数据库读性能（大部分应用读多写少，读会先成为瓶颈）；
3. 如何保证一致性；
4. 如何提高扩展性；

**如何保证数据的可用性？**

```
解决可用性问题的思路是=>冗余
```

如何保证站点的可用性？复制站点，冗余站点

如何保证服务的可用性？复制服务，冗余服务

如何保证数据的可用性？复制数据，冗余数据

`数据的冗余，会带来一个副作用=>引发一致性问题（先不说一致性问题，先说可用性）`。

**如何保证数据库“读”高可用？**

```
冗余读库
```

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVfzSQxiaMKG7PEibNQY20qicrtH9g3z1hqYKQSRxiaHYWkLQ0TicAhmgrz5g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

```
冗余读库带来的副作用？读写有延时，可能不一致
```

上面这个图是很多互联网公司mysql的架构，写仍然是单点，不能保证写高可用。

**如何保证数据库“写”高可用？**

```
冗余写库
```

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFV93Dj4qNQR8o6fMLtV2KVRRIuzFM4QwRC7waRxwudoKvpvBwRic5NTog/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`采用双主互备的方式，可以冗余写库带来的副作用？双写同步，数据可能冲突（例如“自增id”同步冲突）`,如何解决同步冲突，有两种常见解决方案：

1. 两个写库使用不同的初始值，相同的步长来增加id：1写库的id为0,2,4,6...；2写库的id为1,3,5,7...；
2. 不使用数据的id，业务层自己生成唯一的id，保证数据不冲突；

实际中没有使用上述两种架构来做读写的“高可用”，`采用的是“双主当主从用”的方式`：

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVdTkhx4dBbo9SHba52cU7HFejgDqSpWXd2Ix98oianGtmQSUflgukmLw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

仍是双主，但`只有一个主提供服务（读+写），另一个主是“shadow-master”，只用来保证高可用，平时不提供服务`。master挂了，shadow-master顶上（vip漂移，对业务层透明，不需要人工介入）。这种方式的好处：

1. 读写没有延时；
2. 读写高可用；

不足：

1. 不能通过加从库的方式扩展读性能；
2. 资源利用率为50%，一台冗余主没有提供服务；

那如何提高读性能呢？进入第二个话题，如何提供读性能。

- **4. 如何扩展读性能**

提高读性能的方式大致有三种，`第一种是建立索引`。这种方式不展开，要提到的一点是，`不同的库可以建立不同的索引`。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVcynRibJlbXccUL7DIHM0Dd9D5ciaia0GTIiasiapLg2TZ5JdAWB8RibH6crQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`写库`不建立索引；

`线上读库`建立线上访问索引，例如uid；

`线下读库`建立线下访问索引，例如time；

`第二种扩充读性能的方式是，增加从库`，这种方法大家用的比较多，但是，存在两个缺点：

1. 从库越多，同步越慢；
2. 同步越慢，数据不一致窗口越大（不一致后面说，还是先说读性能的提高）；

实际中没有采用这种方法提高数据库读性能（没有从库），`采用的是增加缓存`。常见的缓存架构如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFV3frqIVvLwo6wzGUPPjspD4ZLqO70TcNwD7ImVHcRg8Gq2C1LOzA34w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`上游是业务应用，下游是主库，从库（读写分离），缓存`。

实际的玩法：`服务+数据库+缓存一套`

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVZSD2lPluyBDMYlNyvKNC5PhDEBxQbvAhaPndLBp1dBrREIwaX3dPpA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

业务层不直接面向db和cache，`服务层屏蔽了底层db、cache的复杂性`。为什么要引入服务层，今天不展开，采用了“服务+数据库+缓存一套”的方式提供数据访问，`用cache提高读性能`。

不管采用主从的方式扩展读性能，还是缓存的方式扩展读性能，数据都要复制多份（主+从，db+cache），`一定会引发一致性问题`。

- **5. 如何保证一致性？**

主从数据库的一致性，通常有两种解决方案：

**1. 中间件**

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFV4WSg0ib6eezMM9cplst7LxJtZKIPTwdWibBDApm9wrZJEqso1b0tE2bg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

如果某一个key有写操作，在不一致时间窗口内，中间件会将这个key的读操作也路由到主库上。这个方案的缺点是，`数据库中间件的门槛较高`。

**2. 强制读主**

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVSTYTW5gNYnPq7YicL3YWuRdtKyy6zF2oYLsxSnUl0dMoFZOB2yJXWTw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`上面实际用的“双主当主从用”的架构，不存在主从不一致的问题`。

第二类不一致，`是db与缓存间的不一致`：

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFV3frqIVvLwo6wzGUPPjspD4ZLqO70TcNwD7ImVHcRg8Gq2C1LOzA34w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

常见的缓存架构如上，此时**写操作**的顺序是：

（1）淘汰cache；

（2）写数据库；

**读操作**的顺序是：

（1）读cache，如果cache hit则返回；

（2）如果cache miss，则读从库；

（3）读从库后，将数据放回cache；

在一些异常时序情况下，有可能从【从库读到旧数据（同步还没有完成），旧数据入cache后】，数据会长期不一致。`解决办法是“缓存双淘汰”`，写操作时序升级为：

（1）淘汰cache；

（2）写数据库；

（3）在经验“主从同步延时窗口时间”后，再次发起一个异步淘汰cache的请求；

这样，即使有脏数据如cache，一个小的时间窗口之后，脏数据还是会被淘汰。带来的代价是，多引入一次读miss（成本可以忽略）。

除此之外，最佳实践之一是：`建议为所有cache中的item设置一个超时时间`。

- **6. 如何提高数据库的扩展性？**

原来用hash的方式路由，分为2个库，数据量还是太大，要分为3个库，势必需要进行数据迁移，有一个很帅气的“数据库秒级扩容”方案。

**如何秒级扩容？**

首先，`我们不做2库变3库的扩容，我们做2库变4库（库加倍）的扩容（未来4->8->16）`

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVScCiaXEIcXcGs1pTgq39mBATe8qJkOShqXWXZjibAibLc6C3xxBEqxbicg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

服务+数据库是一套（省去了缓存），`数据库采用“双主”的模式`。

**扩容步骤：**

`第一步`，将一个主库提升;

`第二步`，修改配置，2库变4库（原来MOD2，现在配置修改后MOD4），扩容完成；

`原MOD2为偶的部分，现在会MOD4余0或者2；原MOD2为奇的部分，现在会MOD4余1或者3`；数据不需要迁移，同时，双主互相同步，一遍是余0，一边余2，两边数据同步也不会冲突，秒级完成扩容！

最后，要做一些收尾工作：

1. 将旧的双主同步解除；
2. 增加新的双主（双主是保证可用性的，shadow-master平时不提供服务）；
3. 删除多余的数据（余0的主，可以将余2的数据删除掉）；

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVmSUFY8libTxpwd2Mv1JQOPNOGpiaj7UwflLgsDsEn0TY7VClk6H4G8Kg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

这样，秒级别内，我们就完成了2库变4库的扩展。

## 大并发带来的挑战

### 请求接口的合理设计

一个秒杀或者抢购页面，通常分为2个部分，一个是`静态的HTML等内容`，另一个就是`参与秒杀的Web后台请求接口`。

`通常静态HTML等内容，是通过CDN的部署，一般压力不大，核心瓶颈实际上在后台请求接口上`。这个后端接口，必须能够支持高并发请求，同时，非常重要的一点，必须尽可能“快”，在最短的时间里返回用户的请求结果。`为了实现尽可能快这一点，接口的后端存储使用内存级别的操作会更好一点`。仍然直接面向MySQL之类的存储是不合适的，`如果有这种复杂业务的需求，都建议采用异步写入`。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVQ5hQsI4qwKYiaoxJkQZRdibCSCaxnt25G8pdMfdaXko2YibIGtDZ0EaRA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

当然，也有一些秒杀和抢购`采用“滞后反馈”`，就是说秒杀当下不知道结果，一段时间后才可以从页面中看到用户是否秒杀成功。但是，这种属于“偷懒”行为，同时给用户的体验也不好，容易被用户认为是“暗箱操作”。

### 高并发的挑战：一定要“快”

我们通常衡量一个`Web系统的吞吐率的指标是QPS（Query Per Second，每秒处理请求数），解决每秒数万次的高并发场景，这个指标非常关键`。举个例子，我们假设处理一个业务请求平均响应时间为100ms，同时，系统内有20台Apache的Web服务器，配置MaxClients为500个（表示Apache的最大连接数目）。

那么，我们的Web系统的理论峰值QPS为（理想化的计算方式）：

```
20*500/0.1 = 100000 （10万QPS）
```

咦？我们的系统似乎很强大，1秒钟可以处理完10万的请求，5w/s的秒杀似乎是“纸老虎”哈。实际情况，当然没有这么理想。`在高并发的实际场景下，机器都处于高负载的状态，在这个时候平均响应时间会被大大增加`。

`就Web服务器而言，Apache打开了越多的连接进程，CPU需要处理的上下文切换也越多，额外增加了CPU的消耗，然后就直接导致平均响应时间增加`。因此上述的`MaxClient数目，要根据CPU、内存等硬件因素综合考虑，绝对不是越多越好`。可以`通过Apache自带的abench来测试一下`，取一个合适的值。然后，我们`选择内存操作级别的存储的Redis，在高并发的状态下，存储的响应时间至关重要`。网络带宽虽然也是一个因素，不过，这种请求数据包一般比较小，一般很少成为请求的瓶颈。负载均衡成为系统瓶颈的情况比较少，在这里不做讨论哈。

那么问题来了，假设我们的系统，在5w/s的高并发状态下，平均响应时间从100ms变为250ms（实际情况，甚至更多）：

```
20*500/0.25 = 40000 （4万QPS）
```

于是，我们的系统剩下了4w的QPS，面对5w每秒的请求，中间相差了1w。

然后，这才是真正的恶梦开始。举个例子，高速路口，1秒钟来5部车，每秒通过5部车，高速路口运作正常。突然，这个路口1秒钟只能通过4部车，车流量仍然依旧，结果必定出现大塞车。（5条车道忽然变成4条车道的感觉）。

同理，某一个秒内，20*500个可用连接进程都在满负荷工作中，却仍然有1万个新来请求，没有连接进程可用，系统陷入到异常状态也是预期之内。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVtq9bqxyElVkfsX9d2ibgzGG0icV59paKHdq9h5xCg9p2NwC8OEqutLqQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

其实在正常的非高并发的业务场景中，也有类似的情况出现，某个业务请求接口出现问题，响应时间极慢，将整个Web请求响应时间拉得很长，逐渐将Web服务器的可用连接数占满，其他正常的业务请求，无连接进程可用。

更可怕的问题是，是用户的行为特点，系统越是不可用，用户的点击越频繁，`恶性循环最终导致“雪崩”（其中一台Web机器挂了，导致流量分散到其他正常工作的机器上，再导致正常的机器也挂，然后恶性循环）`，将整个Web系统拖垮。

### 重启与过载保护

如果系统发生“雪崩”，贸然重启服务，是无法解决问题的。最常见的现象是，启动起来后，立刻挂掉。这个时候，`最好在入口层将流量拒绝，然后再将重启`。`如果是redis/memcache这种服务也挂了，重启的时候需要注意“预热”，并且很可能需要比较长的时间`。

秒杀和抢购的场景，流量往往是超乎我们系统的准备和想象的。这个时候，过载保护是必要的。`如果检测到系统满负载状态，拒绝请求也是一种保护措施`。在前端设置过滤是最简单的方式，但是，这种做法是被用户“千夫所指”的行为。更合适一点的是，`将过载保护设置在CGI入口层，快速将客户的直接请求返回`。

## 作弊的手段：进攻与防守

秒杀和抢购收到了“海量”的请求，实际上里面的水分是很大的。不少用户，为了“抢“到商品，会使用“刷票工具”等类型的辅助工具，帮助他们发送尽可能多的请求到服务器。还有一部分高级用户，制作强大的自动请求脚本。`这种做法的理由也很简单，就是在参与秒杀和抢购的请求中，自己的请求数目占比越多，成功的概率越高`。

这些都是属于“作弊的手段”，不过，有“进攻”就有“防守”，这是一场没有硝烟的战斗哈。

### 同一个账号，一次性发出多个请求

部分用户通过浏览器的插件或者其他工具，在秒杀开始的时间里，`以自己的账号，一次发送上百甚至更多的请求`。实际上，这样的用户破坏了秒杀和抢购的公平性。

这种请求在某些没有做数据安全处理的系统里，也可能造成另外一种破坏，导致某些判断条件被绕过。例如一个简单的领取逻辑，先判断用户是否有参与记录，如果没有则领取成功，最后写入到参与记录中。这是个非常简单的逻辑，但是，在高并发的场景下，存在深深的漏洞。`多个并发请求通过负载均衡服务器，分配到内网的多台Web服务器，它们首先向存储发送查询请求，然后，在某个请求成功写入参与记录的时间差内，其他的请求获查询到的结果都是“没有参与记录”`。这里，就存在逻辑判断被绕过的风险。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVTv3w9t1NpqaN1FTJiaYxdiar2X03yugc2BWr51du4w2sv5deicJibdM8cg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**应对方案：**

在程序入口处，一个账号只允许接受1个请求，其他请求过滤。不仅解决了同一个账号，发送N个请求的问题，还保证了后续的逻辑流程的安全。`实现方案，可以通过Redis这种内存缓存服务，写入一个标志位（只允许1个请求写成功，结合watch的乐观锁的特性），成功写入的则可以继续参加`。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVAHFlhic0zbxGlqM88xbqywLDaLHDbzLHcn3alQX7vqPHtyCFHThcHlA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

或者，自己实现一个服务，将同一个账号的请求放入一个队列中，处理完一个，再处理下一个。

### 多个账号，一次性发送多个请求

很多公司的账号注册功能，在发展早期几乎是没有限制的，很容易就可以注册很多个账号。因此，`也导致了出现了一些特殊的工作室，通过编写自动注册脚本，积累了一大批“僵尸账号”，数量庞大，几万甚至几十万的账号不等，专门做各种刷的行为（这就是微博中的“僵尸粉“的来源）`。举个例子，例如微博中有转发抽奖的活动，如果我们使用几万个“僵尸号”去混进去转发，这样就可以大大提升我们中奖的概率。

这种账号，使用在秒杀和抢购里，也是同一个道理。例如，iPhone官网的抢购，火车票黄牛党。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVpCzghZZCMnbh2RvVGh1lQANOegrM4jyaWOIMrV5gysftXWVHq5Y4Mg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**应对方案：**

这种场景，可以`通过检测指定机器IP请求频率就可以解决，如果发现某个IP请求频率很高，可以给它弹出一个验证码或者直接禁止它的请求`：

1. `弹出验证码，最核心的追求，就是分辨出真实用户`。因此，大家可能经常发现，网站弹出的验证码，有些是“鬼神乱舞”的样子，有时让我们根本无法看清。他们这样做的原因，其实也是为了让验证码的图片不被轻易识别，因为强大的“自动脚本”可以通过图片识别里面的字符，然后让脚本自动填写验证码。实际上，有一些非常创新的验证码，效果会比较好，例如给你一个简单问题让你回答，或者让你完成某些简单操作（例如百度贴吧的验证码）。
2. `直接禁止IP，实际上是有些粗暴的，因为有些真实用户的网络场景恰好是同一出口IP的，可能会有“误伤“`。但是这一个做法简单高效，根据实际场景使用可以获得很好的效果。

### 多个账号，不同IP发送不同请求

所谓道高一尺，魔高一丈。有进攻，就会有防守，永不休止。`这些“工作室”，发现你对单机IP请求频率有控制之后，他们也针对这种场景，想出了他们的“新进攻方案”，就是不断改变IP`。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVv3q75ib1f17xfmcianQ5sUdpqX6HiceaRXFO6c6nnSIFYtGVBMnncoc4g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

有同学会好奇，这些随机IP服务怎么来的。`有一些是某些机构自己占据一批独立IP，然后做成一个随机代理IP的服务，有偿提供给这些“工作室”使用`。还有一些更为黑暗一点的，就是`通过木马黑掉普通用户的电脑，这个木马也不破坏用户电脑的正常运作，只做一件事情，就是转发IP包，普通用户的电脑被变成了IP代理出口`。通过这种做法，黑客就拿到了大量的独立IP，然后搭建为随机IP服务，就是为了挣钱。

**应对方案：**

说实话，这种场景下的请求，和真实用户的行为，已经基本相同了，想做分辨很困难。再做进一步的限制很容易“误伤“真实用户，这个时候，`通常只能通过设置业务门槛高来限制这种请求了，或者通过账号行为的”数据挖掘“来提前清理掉它们`。

僵尸账号也还是有一些共同特征的，例如`账号很可能属于同一个号码段甚至是连号的，活跃度不高，等级低，资料不全等等`。根据这些特点，适当设置参与门槛，例如限制参与秒杀的账号等级。`通过这些业务手段，也是可以过滤掉一些僵尸号`。

## 高并发下的数据安全

我们知道在`多线程写入同一个文件的时候，会存现“线程安全”的问题`（多个线程同时运行同一段代码，如果每次运行结果和单线程运行的结果是一样的，结果和预期相同，就是线程安全的）。`如果是MySQL数据库，可以使用它自带的锁机制很好的解决问题，但是，在大规模并发的场景中，是不推荐使用MySQL的`。秒杀和抢购的场景中，还有另外一个问题，就是“超发”，如果在这方面控制不慎，会产生发送过多的情况。我们也曾经听说过，某些电商搞抢购活动，买家成功拍下后，商家却不承认订单有效，拒绝发货。这里的问题，也许并不一定是商家奸诈，而是系统技术层面存在超发风险导致的。

### 超发的原因

假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是99个，然后都通过了这一个余量判断，最终导致超发。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVnMfseOOk4HiaU53RJSTxY2zSpCgRSvszZEetP2iaBYXduibzXNbrZhkMg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在上面的这个图中，就导致了并发用户B也“抢购成功”，多让一个人获得了商品。这种场景，在高并发的情况下非常容易出现。

### 悲观锁思路

解决线程安全的思路很多，可以从“悲观锁”的方向开始讨论。

```
悲观锁，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待。
```

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVWWOkXIpZ45v2gxkoAgBExia9hHwIOibKnzwWCjFOgFqibIA0JIC5Wgzibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

虽然上述的方案的确解决了线程安全的问题，但是，别忘记，`我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，这种请求就会死在那里`。同时，这种请求会很多，`瞬间增大系统的平均响应时间，结果是可用连接数被耗尽，系统陷入异常`。

### FIFO队列思路

那好，那么我们稍微修改一下上面的场景，`我们直接将请求放入队列中的，采用FIFO（First Input First Output，先进先出），这样的话，我们就不会导致某些请求永远获取不到锁`。看到这里，是不是有点强行将多线程变成单线程的感觉哈。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVRzEpia2zv9C9srhSlic5KoYDH2KwPnw44xeUAlzx3OfYEc4ibvXFDUrpg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

然后，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，`高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态`。或者设计一个极大的内存队列，也是一种方案，但是，系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说，队列内的请求会越积累越多，最终Web系统平均响应时候还是会大幅下降，系统还是陷入异常。

### 乐观锁思路

这个时候，我们就可以讨论一下“乐观锁”的思路了。`乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败`。这样的话，我们就不需要考虑队列的问题，不过，`它会增大CPU的计算开销`。但是，综合来说，这是一个比较好的解决方案。

![图片](https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia0ibHKyDrXZceLf5DgibrPyFVBs8PrJ4oMI0PF2mWeL2peYYmicm8NZVZLt1Vv4tQFo8xjRr6WvoibHVg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

有很多软件和服务都“乐观锁”功能的支持，例如`Redis中的watch就是其中之一`。通过这个实现，我们保证了数据的安全。



# 秒杀架构设计必杀技

今天我从 7 个不同的维度，讲讲秒杀系统的架构设计，主要知识点如下：

- Nginx + 前后端分离 + CDN 缓存 + 网关（限流+熔断）
- 集群的路由层 + Redis（缓存热点数据、分布式锁)
- MQ 集群
- 业务处理层
- 数据库层（读写分离、热点隔离)

## 秒杀业务的特点



![图片](https://mmbiz.qpic.cn/mmbiz/OKUeiaP72uRz0oGF9fvHiaCpTG5jfcD9nUppVT1ac1UZ7klxdbia7sJVXiaXAy4qhYCD7sDN8UrjxYtHzzZq2rvfBQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)



- 瞬间大量的刷新页面的操作
- 瞬间大量的抢宝的操作
- 可能有秒杀器的恶性竞争

## 总体思路

### 削峰限流

- 前端+Redis拦截，只有redis扣减成功的请求才能进入到下游
- MQ堆积订单，保护订单处理层的负载，Consumer根据自己的消费能力来取Task，实际上下游的压力就可控了。重点做好路由层和MQ的安全
- 引入答题验证码、请求的随机休眠等措施，削峰填谷

**安全保护**

- 页面和前端要做判断，防止活动未开始就抢单，防止重复点击按钮连续抢单
- 防止秒杀器恶意抢单，IP限流、UserId限流限购、引入答题干扰答题器，并且对答题器答题时间做常理推断
- IP黑名单、UserId黑名单功能
- 过载丢弃：QPS或者CPU等核心指标超过一定限额时，丢弃请求，避免服务器挂掉，保证大部分用户可用

**页面优化，动静分离**

- 秒杀商品的网页内容尽可能做的简单：图片小、js css 体积小数量少，内容尽可能的做到动静分离
- 秒杀的抢宝过程中做成异步刷新抢宝，而不需要用户刷新页面来抢，降低服务器交互的压力
- 可以使用Nginx的动静分离，不通过传统web浏览器获取静态资源
- nginx开启gzip压缩，压缩静态资源，减少传输带宽，提升传输速度
- 或者使用Varnish，把静态资源缓存到内存当中，避免静态资源的获取给服务器造成的压力

**异步处理**

- redis抢单成功后，把后续的业务丢到线程池中异步的处理，提高抢单的响应速度
- 线程池处理时，把任务丢到MQ中，异步的等待各个子系统处理（订单系统、库存系统、支付系统、优惠券系统）
  异步操作有事务问题，本地事务和分布式事务，但是为了提升并发度，最好牺牲一致性。通过定时扫描统计日志，来发现有问题的订单，并且及时处理

**热点分离**

尽量的避免秒杀功能给正常功能带来的影响，比如秒杀把服务器某个功能拖垮了。

分离可以提升系统的容灾性，但是完全的隔离的改造成本太高了，尽量借助中间件的配置，来实现冷热分离。

- 集群节点的分离：nginx配置让秒杀业务走的集群节点和普通业务走的集群不一样。
- MQ的分离：避免秒杀业务把消息队列堆满了，普通业务的交易延迟也特别厉害。
- 数据库的分离：根据实际的秒杀的QPS来选择，热点数据分库以后，增加了分布式事务的问题，以及查询的时候跨库查询性能要差一些（ShardingJDBC有这种功能），所以要权衡以后再决定是否需要分库

- 避免单点：各个环节都要尽力避免
- 降级：临时关闭一些没那么重要的功能，比如秒杀商品的转赠功能、红包的提现功能，待秒杀峰值过了，设置开关，再动态开放这些次要的功能

### Nginx的设计细节

动静分离，不走tomcat获取静态资源

```
 server {
        listen       8088;
    location ~ \.(gif|jpg|jpeg|png|bmp|swf)$ {  
        root    C:/Users/502764158/Desktop/test;  
    } 

    location ~ \.(jsp|do)$ {
            proxy_pass :8082;
        }
    }
 }
```

- gzip压缩，减少静态文件传输的体积，节省带宽，提高渲染速度

```
    gzip on;
    gzip_min_length 1k;
    gzip_buffers 4 16k;
    gzip_comp_level 3;
    gzip_disable "MSIE [1-6]\.";
    gzip_types   text/plain application/x-javascript text/css application/xml text/javascript image/jpeg image/gif image/png;
```

配置集群负载和容灾，设置失效重连的时间，失效后，定期不会再重试挂掉的节点，参数：

- fail_timeout默认为10s
- max_fails默认为1。就是说，只要某个server失效一次，则在接下来的10s内，就不会分发请求到该server上
- proxy_connect_timeout 后端服务器连接的超时时间_发起握手等候响应超时时间

```
    upstream  netitcast.com {  #服务器集群名字   
    server    127.0.0.1:8080;
    server    127.0.0.1:38083;
    server    127.0.0.1:8083;
    } 

 server {
        listen       88;
        server_name  localhost;
    location / {  
            proxy_pass http://netitcast.com;  
            proxy_connect_timeout       1;
            fail_timeout 5;
        } 
    }
```

1. 集成Varnish做静态资源的缓存
2. 集成tengine做过载的保护

### 页面优化细节

**降低交互的压力**

- 尽量把js、css文件放在少数几个里面，减少浏览器和后端交互获取静态资源的次数
- 尽量避免在秒杀商品页面使用大的图片，或者使用过多的图片

**安全控制**

- 时间有效性验证：未到秒杀时间不能进行抢单，并且同时程序后端也要做时间有效性验证，因为网页的时间和各自的系统时间决定，而且秒杀器可以通过绕开校验直接调用抢单
- 异步抢单：通过点击按钮刷新抢宝，而不是刷新页面的方式抢宝（答题验证码等等也是ajax交互）
- 另外，搜索公众号Linux就该这样学后台回复“猴子”，获取一份惊喜礼包。
- redis做IP限流
- redis做UserId限流

### Redis集群的应用

1. 分布式锁（悲观锁）
2. 缓存热点数据（库存）：如果QPS太高的话，另一种方案是通过localcache，分布式状态一致性通过数据库来控制

**分布式悲观锁（参考redis悲观锁的代码）**

- 悲观锁（因为肯定争抢严重）
- Expire时间（抢到锁后，立刻设置过期时间，防止某个线程的异常停摆，导致整个业务的停摆）
- 定时循环和快速反馈（for缓存有超时设置，每次超时后，重新读取一次库存，还有货再进行第二轮的for循环争夺，实现快速反馈，避免没有货了还在持续抢锁）

**异步处理订单**

- redis抢锁成功后，记录抢到锁的用户信息后，就可以直接释放锁，并反馈用户，通过异步的方式来处理订单，提升秒杀的效率，降低无意义的线程等待
- 为了避免异步的数据不同步，需要抢到锁的时候，在redis里面缓存用户信息列表，缓存结束后，触发抢单成功用户信息持久化，并且定时的比对一致性

### 消息队列限流

消息队列削峰限流(RocketMQ自带的Consumer自带线程池和限流措施)，集群。一般都是微服务，订单中心、库存中心、积分中心、用户的商品中心

### 数据库设计

- 拆分事务提高并发度
- 根据业务需求考虑分库：读写分离、热点隔离拆分，但是会引入分布式事务问题，以及跨库操作的难度

要执行的操作：扣减库存、生成新订单、生成待支付订单、扣减优惠券、积分变动

库存表是数据库并发的瓶颈所在，需要在事务控制上做权衡：可以把扣减库存设置成一个独立的事务，其它操作成一个大的事务（订单、优惠券、积分操作），提高并发度，但是要做好额外的check

update 库存表 set 库存=库存-1 where id=** and 库存>1

### 答题验证码的设计

- 可以防止秒杀器的干扰，让更多用户有机会抢到
- 延缓请求，每个人的反应时间不同，把瞬间流量分散开来了

验证码的设计可以分为2种：

- 验证失败重新刷新答题（12306）：服务器交互量大，每错一次交互一次，但是可以大大降低秒杀器答题的可能性，因为没有试错这个功能，答题一直在变
- 验证失败提示失败，但是不刷新答题的算法：要么答题成功，进入下单界面，要么提示打错，继续答题（不刷新答题，无须交互，用js验证结果)。
  这种方案，可以在加载题目的时候一起加载MD5加密的答案，然后后台再校验一遍，实现类似的防止作弊的效果。好处是不需要额外的服务器交互。
  MD加密答案的算法里面要引入 userId PK这些因素进来来确保每次答案都不一样而且没有规律，避免秒杀器统计结果集

答题的验证：除了验证答案的正确性意外，还要统计反应时间，例如12306的难题，正常人类的答题速度最快是1.5s，那么，小于1s的验证可以判定为机器验证

### 注意事项

为了提升并发，需要在事务上做妥协：

> 单机上拆分事务：比如扣减库存表+(生成待支付订单+优惠券扣减+积分变动)是一个大的事务，为了提高并发，可以拆分为2个事务。分库以后引入分布式事务问题,为了保证用户体验，最好还是通过日志分析来人工维护，否则阻塞太严重，并发差。

































